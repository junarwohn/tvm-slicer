fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(64, 3, 3, 3), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 64, 3, 3), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(128, 64, 3, 3), float32], %v_param_14: Tensor[(128), float32], %v_param_15: Tensor[(128), float32], %v_param_16: Tensor[(128), float32], %v_param_17: Tensor[(128), float32], %v_param_18: Tensor[(128), float32], %v_param_19: Tensor[(128, 128, 3, 3), float32], %v_param_20: Tensor[(128), float32], %v_param_21: Tensor[(128), float32], %v_param_22: Tensor[(128), float32], %v_param_23: Tensor[(128), float32], %v_param_24: Tensor[(128), float32], %v_param_25: Tensor[(256, 128, 3, 3), float32], %v_param_26: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(256, 256, 3, 3), float32], %v_param_32: Tensor[(256), float32], %v_param_33: Tensor[(256), float32], %v_param_34: Tensor[(256), float32], %v_param_35: Tensor[(256), float32], %v_param_36: Tensor[(256), float32], %v_param_37: Tensor[(512, 256, 3, 3), float32], %v_param_38: Tensor[(512), float32], %v_param_39: Tensor[(512), float32], %v_param_40: Tensor[(512), float32], %v_param_41: Tensor[(512), float32], %v_param_42: Tensor[(512), float32], %v_param_43: Tensor[(512, 512, 3, 3), float32], %v_param_44: Tensor[(512), float32], %v_param_45: Tensor[(512), float32], %v_param_46: Tensor[(512), float32], %v_param_47: Tensor[(512), float32], %v_param_48: Tensor[(512), float32], %v_param_49: Tensor[(1024, 512, 3, 3), float32], %v_param_50: Tensor[(1024), float32], %v_param_51: Tensor[(1024), float32], %v_param_52: Tensor[(1024), float32], %v_param_53: Tensor[(1024), float32], %v_param_54: Tensor[(1024), float32], %v_param_55: Tensor[(1024, 1024, 3, 3), float32], %v_param_56: Tensor[(1024), float32], %v_param_57: Tensor[(1024), float32], %v_param_58: Tensor[(1024), float32], %v_param_59: Tensor[(1024), float32], %v_param_60: Tensor[(1024), float32], %v_param_61: Tensor[(1024, 512, 3, 3), float32], %v_param_62: Tensor[(512), float32], %v_param_63: Tensor[(512), float32], %v_param_64: Tensor[(512), float32], %v_param_65: Tensor[(512), float32], %v_param_66: Tensor[(512), float32], %v_param_67: Tensor[(512, 1024, 3, 3), float32], %v_param_68: Tensor[(512), float32], %v_param_69: Tensor[(512), float32], %v_param_70: Tensor[(512), float32], %v_param_71: Tensor[(512), float32], %v_param_72: Tensor[(512), float32], %v_param_73: Tensor[(512, 512, 3, 3), float32], %v_param_74: Tensor[(512), float32], %v_param_75: Tensor[(512), float32], %v_param_76: Tensor[(512), float32], %v_param_77: Tensor[(512), float32], %v_param_78: Tensor[(512), float32], %v_param_79: Tensor[(512, 256, 3, 3), float32], %v_param_80: Tensor[(256), float32], %v_param_81: Tensor[(256), float32], %v_param_82: Tensor[(256), float32], %v_param_83: Tensor[(256), float32], %v_param_84: Tensor[(256), float32], %v_param_85: Tensor[(256, 512, 3, 3), float32], %v_param_86: Tensor[(256), float32], %v_param_87: Tensor[(256), float32], %v_param_88: Tensor[(256), float32], %v_param_89: Tensor[(256), float32], %v_param_90: Tensor[(256), float32], %v_param_91: Tensor[(256, 256, 3, 3), float32], %v_param_92: Tensor[(256), float32], %v_param_93: Tensor[(256), float32], %v_param_94: Tensor[(256), float32], %v_param_95: Tensor[(256), float32], %v_param_96: Tensor[(256), float32], %v_param_99: Tensor[(256, 128, 3, 3), float32], %v_param_100: Tensor[(128), float32], %v_param_105: Tensor[(128), float32], %v_param_106: Tensor[(128), float32], %v_param_107: Tensor[(128), float32], %v_param_108: Tensor[(128), float32], %v_param_111: Tensor[(128, 256, 3, 3), float32], %v_param_112: Tensor[(128), float32], %v_param_117: Tensor[(128), float32], %v_param_118: Tensor[(128), float32], %v_param_119: Tensor[(128), float32], %v_param_120: Tensor[(128), float32], %v_param_123: Tensor[(128, 128, 3, 3), float32], %v_param_124: Tensor[(128), float32], %v_param_129: Tensor[(128), float32], %v_param_130: Tensor[(128), float32], %v_param_131: Tensor[(128), float32], %v_param_132: Tensor[(128), float32], %v_param_133: Tensor[(128, 64, 3, 3), float32], %v_param_134: Tensor[(64), float32], %v_param_137: Tensor[(64), float32], %v_param_138: Tensor[(64), float32], %v_param_139: Tensor[(64), float32], %v_param_140: Tensor[(64), float32], %v_param_97: Tensor[(32, 64, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32), float32], %v_param_104: Tensor[(32), float32], %v_param_109: Tensor[(16, 32, 3, 3), float32], %v_param_110: Tensor[(16), float32], %v_param_113: Tensor[(16), float32], %v_param_114: Tensor[(16), float32], %v_param_115: Tensor[(16), float32], %v_param_116: Tensor[(16), float32], %v_param_121: Tensor[(16, 64, 3, 3), float32], %v_param_122: Tensor[(64), float32], %v_param_125: Tensor[(64), float32], %v_param_126: Tensor[(64), float32], %v_param_127: Tensor[(64), float32], %v_param_128: Tensor[(64), float32], %v_param_135: Tensor[(64, 128, 3, 3), float32], %v_param_136: Tensor[(128), float32], %v_param_141: Tensor[(128), float32], %v_param_142: Tensor[(128), float32], %v_param_143: Tensor[(128), float32], %v_param_144: Tensor[(128), float32], %v_param_145: Tensor[(64, 192, 3, 3), float32], %v_param_146: Tensor[(64), float32], %v_param_147: Tensor[(64), float32], %v_param_148: Tensor[(64), float32], %v_param_149: Tensor[(64), float32], %v_param_150: Tensor[(64), float32], %v_param_151: Tensor[(64, 64, 3, 3), float32], %v_param_152: Tensor[(64), float32], %v_param_153: Tensor[(64), float32], %v_param_154: Tensor[(64), float32], %v_param_155: Tensor[(64), float32], %v_param_156: Tensor[(64), float32], %v_param_157: Tensor[(1, 64, 3, 3), float32], %v_param_158: Tensor[(1), float32]) {
  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %1 = nn.bias_add(%0, %v_param_2);
  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);
  %3 = %2.0;
  %4 = nn.leaky_relu(%3, alpha=0.2f);
  %5 = multiply(%4, 8f);
  %6 = round(%5);
  %7 = clip(%6, a_min=-127f, a_max=127f);
  %8 = cast(%7, dtype="int8");
  %9 = annotation.stop_fusion(%8);
  %10 = cast(%9, dtype="float32");
  %11 = divide(%10, 8f);
  %12 = nn.conv2d(%11, %v_param_7, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %13 = nn.bias_add(%12, %v_param_8);
  %14 = nn.batch_norm(%13, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);
  %15 = %14.0;
  %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %17 = multiply(%16, 8f);
  %18 = round(%17);
  %19 = clip(%18, a_min=-127f, a_max=127f);
  %20 = cast(%19, dtype="int8");
  %21 = annotation.stop_fusion(%20);
  %22 = cast(%21, dtype="float32");
  %23 = divide(%22, 8f);
  %24 = nn.conv2d(%23, %v_param_13, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %25 = nn.bias_add(%24, %v_param_14);
  %26 = nn.batch_norm(%25, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);
  %27 = %26.0;
  %28 = nn.leaky_relu(%27, alpha=0.2f);
  %29 = multiply(%28, 8f);
  %30 = round(%29);
  %31 = clip(%30, a_min=-127f, a_max=127f);
  %32 = cast(%31, dtype="int8");
  %33 = annotation.stop_fusion(%32);
  %34 = cast(%33, dtype="float32");
  %35 = divide(%34, 8f);
  %36 = nn.conv2d(%35, %v_param_19, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %37 = nn.bias_add(%36, %v_param_20);
  %38 = nn.batch_norm(%37, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);
  %39 = %38.0;
  %40 = multiply(%39, 8f);
  %41 = round(%40);
  %42 = clip(%41, a_min=-127f, a_max=127f);
  %43 = cast(%42, dtype="int8");
  %44 = annotation.stop_fusion(%43);
  %45 = cast(%44, dtype="float32");
  %46 = divide(%45, 8f);
  %47 = nn.max_pool2d(%46, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %48 = multiply(%47, 8f);
  %49 = round(%48);
  %50 = clip(%49, a_min=-127f, a_max=127f);
  %51 = cast(%50, dtype="int8");
  %52 = annotation.stop_fusion(%51);
  %53 = cast(%52, dtype="float32");
  %54 = divide(%53, 8f);
  %55 = nn.conv2d(%54, %v_param_25, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %56 = nn.bias_add(%55, %v_param_26);
  %57 = nn.batch_norm(%56, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);
  %58 = %57.0;
  %59 = nn.leaky_relu(%58, alpha=0.2f);
  %60 = multiply(%59, 8f);
  %61 = round(%60);
  %62 = clip(%61, a_min=-127f, a_max=127f);
  %63 = cast(%62, dtype="int8");
  %64 = annotation.stop_fusion(%63);
  %65 = cast(%64, dtype="float32");
  %66 = divide(%65, 8f);
  %67 = nn.conv2d(%66, %v_param_31, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %68 = nn.bias_add(%67, %v_param_32);
  %69 = nn.batch_norm(%68, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);
  %70 = %69.0;
  %71 = multiply(%70, 8f);
  %72 = round(%71);
  %73 = clip(%72, a_min=-127f, a_max=127f);
  %74 = cast(%73, dtype="int8");
  %75 = annotation.stop_fusion(%74);
  %76 = cast(%75, dtype="float32");
  %77 = divide(%76, 8f);
  %78 = nn.max_pool2d(%77, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %79 = multiply(%78, 8f);
  %80 = round(%79);
  %81 = clip(%80, a_min=-127f, a_max=127f);
  %82 = cast(%81, dtype="int8");
  %83 = annotation.stop_fusion(%82);
  %84 = cast(%83, dtype="float32");
  %85 = divide(%84, 8f);
  %86 = nn.conv2d(%85, %v_param_37, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %87 = nn.bias_add(%86, %v_param_38);
  %88 = nn.batch_norm(%87, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);
  %89 = %88.0;
  %90 = nn.leaky_relu(%89, alpha=0.2f);
  %91 = multiply(%90, 8f);
  %92 = round(%91);
  %93 = clip(%92, a_min=-127f, a_max=127f);
  %94 = cast(%93, dtype="int8");
  %95 = annotation.stop_fusion(%94);
  %96 = cast(%95, dtype="float32");
  %97 = divide(%96, 8f);
  %98 = nn.conv2d(%97, %v_param_43, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %99 = nn.bias_add(%98, %v_param_44);
  %100 = nn.batch_norm(%99, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);
  %101 = %100.0;
  %102 = multiply(%101, 8f);
  %103 = round(%102);
  %104 = clip(%103, a_min=-127f, a_max=127f);
  %105 = cast(%104, dtype="int8");
  %106 = annotation.stop_fusion(%105);
  %107 = cast(%106, dtype="float32");
  %108 = divide(%107, 8f);
  %109 = nn.max_pool2d(%108, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %110 = multiply(%109, 8f);
  %111 = round(%110);
  %112 = clip(%111, a_min=-127f, a_max=127f);
  %113 = cast(%112, dtype="int8");
  %114 = annotation.stop_fusion(%113);
  %115 = cast(%114, dtype="float32");
  %116 = divide(%115, 8f);
  %117 = nn.conv2d(%116, %v_param_49, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]);
  %118 = nn.bias_add(%117, %v_param_50);
  %119 = nn.batch_norm(%118, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);
  %120 = %119.0;
  %121 = nn.leaky_relu(%120, alpha=0.2f);
  %122 = multiply(%121, 8f);
  %123 = round(%122);
  %124 = clip(%123, a_min=-127f, a_max=127f);
  %125 = cast(%124, dtype="int8");
  %126 = annotation.stop_fusion(%125);
  %127 = cast(%126, dtype="float32");
  %128 = divide(%127, 8f);
  %129 = nn.conv2d(%128, %v_param_55, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]);
  %130 = nn.bias_add(%129, %v_param_56);
  %131 = nn.batch_norm(%130, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);
  %132 = %131.0;
  %133 = nn.conv2d_transpose(%132, %v_param_61, channels=512, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %134 = nn.bias_add(%133, %v_param_62);
  %135 = nn.batch_norm(%134, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);
  %136 = %135.0;
  %137 = nn.leaky_relu(%136, alpha=0.2f);
  %138 = multiply(%137, 8f);
  %139 = round(%138);
  %140 = clip(%139, a_min=-127f, a_max=127f);
  %141 = cast(%140, dtype="int8");
  %142 = annotation.stop_fusion(%141);
  %143 = cast(%142, dtype="float32");
  %144 = divide(%143, 8f);
  %145 = (%144, %108);
  %146 = concatenate(%145, axis=1);
  %147 = multiply(%146, 8f);
  %148 = round(%147);
  %149 = clip(%148, a_min=-127f, a_max=127f);
  %150 = cast(%149, dtype="int8");
  %151 = annotation.stop_fusion(%150);
  %152 = cast(%151, dtype="float32");
  %153 = divide(%152, 8f);
  %154 = nn.conv2d(%153, %v_param_67, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %155 = nn.bias_add(%154, %v_param_68);
  %156 = nn.batch_norm(%155, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);
  %157 = %156.0;
  %158 = nn.leaky_relu(%157, alpha=0.2f);
  %159 = multiply(%158, 8f);
  %160 = round(%159);
  %161 = clip(%160, a_min=-127f, a_max=127f);
  %162 = cast(%161, dtype="int8");
  %163 = annotation.stop_fusion(%162);
  %164 = cast(%163, dtype="float32");
  %165 = divide(%164, 8f);
  %166 = nn.conv2d(%165, %v_param_73, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %167 = nn.bias_add(%166, %v_param_74);
  %168 = nn.batch_norm(%167, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);
  %169 = %168.0;
  %170 = nn.conv2d_transpose(%169, %v_param_79, channels=256, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %171 = nn.bias_add(%170, %v_param_80);
  %172 = nn.batch_norm(%171, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);
  %173 = %172.0;
  %174 = nn.leaky_relu(%173, alpha=0.2f);
  %175 = multiply(%174, 8f);
  %176 = round(%175);
  %177 = clip(%176, a_min=-127f, a_max=127f);
  %178 = cast(%177, dtype="int8");
  %179 = annotation.stop_fusion(%178);
  %180 = cast(%179, dtype="float32");
  %181 = divide(%180, 8f);
  %182 = (%181, %77);
  %183 = concatenate(%182, axis=1);
  %184 = multiply(%183, 8f);
  %185 = round(%184);
  %186 = clip(%185, a_min=-127f, a_max=127f);
  %187 = cast(%186, dtype="int8");
  %188 = annotation.stop_fusion(%187);
  %189 = cast(%188, dtype="float32");
  %190 = divide(%189, 8f);
  %191 = nn.conv2d(%190, %v_param_85, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %192 = nn.bias_add(%191, %v_param_86);
  %193 = nn.batch_norm(%192, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);
  %194 = %193.0;
  %195 = nn.leaky_relu(%194, alpha=0.2f);
  %196 = multiply(%195, 8f);
  %197 = round(%196);
  %198 = clip(%197, a_min=-127f, a_max=127f);
  %199 = cast(%198, dtype="int8");
  %200 = annotation.stop_fusion(%199);
  %201 = cast(%200, dtype="float32");
  %202 = divide(%201, 8f);
  %203 = nn.conv2d(%202, %v_param_91, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %204 = nn.bias_add(%203, %v_param_92);
  %205 = nn.batch_norm(%204, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);
  %206 = %205.0;
  %207 = nn.conv2d_transpose(%206, %v_param_99, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %208 = nn.bias_add(%207, %v_param_100);
  %209 = nn.batch_norm(%208, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);
  %210 = %209.0;
  %211 = nn.leaky_relu(%210, alpha=0.2f);
  %212 = multiply(%211, 8f);
  %213 = round(%212);
  %214 = clip(%213, a_min=-127f, a_max=127f);
  %215 = cast(%214, dtype="int8");
  %216 = annotation.stop_fusion(%215);
  %217 = cast(%216, dtype="float32");
  %218 = divide(%217, 8f);
  %219 = (%218, %46);
  %220 = concatenate(%219, axis=1);
  %221 = multiply(%220, 8f);
  %222 = round(%221);
  %223 = clip(%222, a_min=-127f, a_max=127f);
  %224 = cast(%223, dtype="int8");
  %225 = annotation.stop_fusion(%224);
  %226 = cast(%225, dtype="float32");
  %227 = divide(%226, 8f);
  %228 = nn.conv2d(%227, %v_param_111, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %229 = nn.bias_add(%228, %v_param_112);
  %230 = nn.batch_norm(%229, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);
  %231 = %230.0;
  %232 = nn.leaky_relu(%231, alpha=0.2f);
  %233 = multiply(%232, 8f);
  %234 = round(%233);
  %235 = clip(%234, a_min=-127f, a_max=127f);
  %236 = cast(%235, dtype="int8");
  %237 = annotation.stop_fusion(%236);
  %238 = cast(%237, dtype="float32");
  %239 = divide(%238, 8f);
  %240 = nn.conv2d(%239, %v_param_123, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %241 = nn.bias_add(%240, %v_param_124);
  %242 = nn.batch_norm(%241, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);
  %243 = %242.0;
  %244 = nn.conv2d_transpose(%243, %v_param_133, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %245 = nn.bias_add(%244, %v_param_134);
  %246 = nn.batch_norm(%245, %v_param_137, %v_param_138, %v_param_139, %v_param_140, epsilon=0.001f);
  %247 = %246.0;
  %248 = nn.leaky_relu(%247, alpha=0.2f);
  %249 = multiply(%248, 8f);
  %250 = round(%249);
  %251 = clip(%250, a_min=-127f, a_max=127f);
  %252 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %253 = multiply(%252, 8f);
  %254 = round(%253);
  %255 = clip(%254, a_min=-127f, a_max=127f);
  %256 = cast(%255, dtype="int8");
  %257 = annotation.stop_fusion(%256);
  %258 = cast(%257, dtype="float32");
  %259 = divide(%258, 8f);
  %260 = nn.conv2d(%259, %v_param_97, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);
  %261 = nn.bias_add(%260, %v_param_98);
  %262 = nn.batch_norm(%261, %v_param_101, %v_param_102, %v_param_103, %v_param_104, epsilon=0.001f);
  %263 = %262.0;
  %264 = nn.leaky_relu(%263, alpha=0.2f);
  %265 = multiply(%264, 8f);
  %266 = round(%265);
  %267 = clip(%266, a_min=-127f, a_max=127f);
  %268 = cast(%267, dtype="int8");
  %269 = annotation.stop_fusion(%268);
  %270 = cast(%269, dtype="float32");
  %271 = divide(%270, 8f);
  %272 = nn.max_pool2d(%271, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %273 = multiply(%272, 8f);
  %274 = round(%273);
  %275 = clip(%274, a_min=-127f, a_max=127f);
  %276 = cast(%275, dtype="int8");
  %277 = annotation.stop_fusion(%276);
  %278 = cast(%277, dtype="float32");
  %279 = divide(%278, 8f);
  %280 = nn.conv2d(%279, %v_param_109, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);
  %281 = nn.bias_add(%280, %v_param_110);
  %282 = nn.batch_norm(%281, %v_param_113, %v_param_114, %v_param_115, %v_param_116, epsilon=0.001f);
  %283 = %282.0;
  %284 = nn.leaky_relu(%283, alpha=0.2f);
  %285 = multiply(%284, 8f);
  %286 = round(%285);
  %287 = clip(%286, a_min=-127f, a_max=127f);
  %288 = cast(%287, dtype="int8");
  %289 = annotation.stop_fusion(%288);
  %290 = cast(%289, dtype="float32");
  %291 = divide(%290, 8f);
  %292 = nn.conv2d_transpose(%291, %v_param_121, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %293 = nn.bias_add(%292, %v_param_122);
  %294 = nn.batch_norm(%293, %v_param_125, %v_param_126, %v_param_127, %v_param_128, epsilon=0.001f);
  %295 = %294.0;
  %296 = nn.leaky_relu(%295, alpha=0.2f);
  %297 = multiply(%296, 8f);
  %298 = round(%297);
  %299 = clip(%298, a_min=-127f, a_max=127f);
  %300 = cast(%299, dtype="int8");
  %301 = annotation.stop_fusion(%300);
  %302 = cast(%301, dtype="float32");
  %303 = divide(%302, 8f);
  %304 = nn.conv2d_transpose(%303, %v_param_135, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %305 = nn.bias_add(%304, %v_param_136);
  %306 = nn.batch_norm(%305, %v_param_141, %v_param_142, %v_param_143, %v_param_144, epsilon=0.001f);
  %307 = %306.0;
  %308 = nn.leaky_relu(%307, alpha=0.2f);
  %309 = multiply(%308, 8f);
  %310 = round(%309);
  %311 = clip(%310, a_min=-127f, a_max=127f);
  %312 = cast(%251, dtype="int8");
  %313 = annotation.stop_fusion(%312);
  %314 = cast(%313, dtype="float32");
  %315 = cast(%311, dtype="int8");
  %316 = annotation.stop_fusion(%315);
  %317 = cast(%316, dtype="float32");
  %318 = divide(%314, 8f);
  %319 = divide(%317, 8f);
  %320 = (%318, %319);
  %321 = concatenate(%320, axis=1);
  %322 = multiply(%321, 8f);
  %323 = round(%322);
  %324 = clip(%323, a_min=-127f, a_max=127f);
  %325 = cast(%324, dtype="int8");
  %326 = annotation.stop_fusion(%325);
  %327 = cast(%326, dtype="float32");
  %328 = divide(%327, 8f);
  %329 = nn.conv2d(%328, %v_param_145, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %330 = nn.bias_add(%329, %v_param_146);
  %331 = nn.batch_norm(%330, %v_param_147, %v_param_148, %v_param_149, %v_param_150, epsilon=0.001f);
  %332 = %331.0;
  %333 = nn.leaky_relu(%332, alpha=0.2f);
  %334 = multiply(%333, 8f);
  %335 = round(%334);
  %336 = clip(%335, a_min=-127f, a_max=127f);
  %337 = cast(%336, dtype="int8");
  %338 = annotation.stop_fusion(%337);
  %339 = cast(%338, dtype="float32");
  %340 = divide(%339, 8f);
  %341 = nn.conv2d(%340, %v_param_151, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %342 = nn.bias_add(%341, %v_param_152);
  %343 = nn.batch_norm(%342, %v_param_153, %v_param_154, %v_param_155, %v_param_156, epsilon=0.001f);
  %344 = %343.0;
  %345 = nn.conv2d(%344, %v_param_157, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);
  %346 = nn.bias_add(%345, %v_param_158);
  %347 = sigmoid(%346);
  (%8, %20, %32, %43, %51, %63, %74, %82, %94, %105, %113, %125, %141, %150, %162, %178, %187, %199, %215, %224, %236, %312, %256, %268, %276, %288, %300, %315, %325, %337, %347)
}
