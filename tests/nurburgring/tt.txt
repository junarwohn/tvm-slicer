fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {
  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);
  %1 = nn.bias_add(%0, %v_param_2);
  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);
  %3 = %2.0;
  %4 = nn.leaky_relu(%3, alpha=0.2f);
  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);
  %6 = nn.bias_add(%5, %v_param_8);
  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);
  %8 = %7.0;
  %9 = multiply(%8, 8f);
  %10 = round(%9);
  %11 = clip(%10, a_min=-127f, a_max=127f);
  %12 = cast(%11, dtype="int8");
  %13 = annotation.stop_fusion(%12);
  %14 = cast(%13, dtype="float32");
  %15 = divide(%14, 8f);
  %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %17 = nn.conv2d(%16, %v_param_13, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);
  %18 = nn.bias_add(%17, %v_param_14);
  %19 = nn.batch_norm(%18, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);
  %20 = %19.0;
  %21 = nn.leaky_relu(%20, alpha=0.2f);
  %22 = nn.conv2d(%21, %v_param_19, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);
  %23 = nn.bias_add(%22, %v_param_20);
  %24 = nn.batch_norm(%23, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);
  %25 = %24.0;
  %26 = multiply(%25, 8f);
  %27 = round(%26);
  %28 = clip(%27, a_min=-127f, a_max=127f);
  %29 = cast(%28, dtype="int8");
  %30 = annotation.stop_fusion(%29);
  %31 = cast(%30, dtype="float32");
  %32 = divide(%31, 8f);
  %33 = nn.max_pool2d(%32, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %34 = nn.conv2d(%33, %v_param_25, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %35 = nn.bias_add(%34, %v_param_26);
  %36 = nn.batch_norm(%35, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);
  %37 = %36.0;
  %38 = nn.leaky_relu(%37, alpha=0.2f);
  %39 = nn.conv2d(%38, %v_param_31, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %40 = nn.bias_add(%39, %v_param_32);
  %41 = nn.batch_norm(%40, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);
  %42 = %41.0;
  %43 = multiply(%42, 8f);
  %44 = round(%43);
  %45 = clip(%44, a_min=-127f, a_max=127f);
  %46 = cast(%45, dtype="int8");
  %47 = annotation.stop_fusion(%46);
  %48 = cast(%47, dtype="float32");
  %49 = divide(%48, 8f);
  %50 = nn.max_pool2d(%49, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %51 = nn.conv2d(%50, %v_param_37, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %52 = nn.bias_add(%51, %v_param_38);
  %53 = nn.batch_norm(%52, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);
  %54 = %53.0;
  %55 = nn.leaky_relu(%54, alpha=0.2f);
  %56 = nn.conv2d(%55, %v_param_43, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %57 = nn.bias_add(%56, %v_param_44);
  %58 = nn.batch_norm(%57, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);
  %59 = %58.0;
  %60 = multiply(%59, 8f);
  %61 = round(%60);
  %62 = clip(%61, a_min=-127f, a_max=127f);
  %63 = cast(%62, dtype="int8");
  %64 = annotation.stop_fusion(%63);
  %65 = cast(%64, dtype="float32");
  %66 = divide(%65, 8f);
  %67 = nn.max_pool2d(%66, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %68 = nn.conv2d(%67, %v_param_49, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %69 = nn.bias_add(%68, %v_param_50);
  %70 = nn.batch_norm(%69, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);
  %71 = %70.0;
  %72 = nn.leaky_relu(%71, alpha=0.2f);
  %73 = nn.conv2d(%72, %v_param_55, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %74 = nn.bias_add(%73, %v_param_56);
  %75 = nn.batch_norm(%74, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);
  %76 = %75.0;
  %77 = nn.conv2d_transpose(%76, %v_param_61, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %78 = nn.bias_add(%77, %v_param_62);
  %79 = nn.batch_norm(%78, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);
  %80 = %79.0;
  %81 = nn.leaky_relu(%80, alpha=0.2f);
  %82 = (%81, %66);
  %83 = concatenate(%82, axis=1);
  %84 = nn.conv2d(%83, %v_param_67, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %85 = nn.bias_add(%84, %v_param_68);
  %86 = nn.batch_norm(%85, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);
  %87 = %86.0;
  %88 = nn.leaky_relu(%87, alpha=0.2f);
  %89 = nn.conv2d(%88, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %90 = nn.bias_add(%89, %v_param_74);
  %91 = nn.batch_norm(%90, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);
  %92 = %91.0;
  %93 = nn.conv2d_transpose(%92, %v_param_79, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %94 = nn.bias_add(%93, %v_param_80);
  %95 = nn.batch_norm(%94, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);
  %96 = %95.0;
  %97 = nn.leaky_relu(%96, alpha=0.2f);
  %98 = (%97, %49);
  %99 = concatenate(%98, axis=1);
  %100 = nn.conv2d(%99, %v_param_85, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %101 = nn.bias_add(%100, %v_param_86);
  %102 = nn.batch_norm(%101, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);
  %103 = %102.0;
  %104 = nn.leaky_relu(%103, alpha=0.2f);
  %105 = nn.conv2d(%104, %v_param_91, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %106 = nn.bias_add(%105, %v_param_92);
  %107 = nn.batch_norm(%106, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);
  %108 = %107.0;
  %109 = nn.conv2d_transpose(%108, %v_param_97, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %110 = nn.bias_add(%109, %v_param_98);
  %111 = nn.batch_norm(%110, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);
  %112 = %111.0;
  %113 = nn.leaky_relu(%112, alpha=0.2f);
  %114 = (%113, %32);
  %115 = concatenate(%114, axis=1);
  %116 = nn.conv2d(%115, %v_param_103, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);
  %117 = nn.bias_add(%116, %v_param_104);
  %118 = nn.batch_norm(%117, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);
  %119 = %118.0;
  %120 = nn.leaky_relu(%119, alpha=0.2f);
  %121 = nn.conv2d(%120, %v_param_109, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);
  %122 = nn.bias_add(%121, %v_param_110);
  %123 = nn.batch_norm(%122, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);
  %124 = %123.0;
  %125 = nn.conv2d_transpose(%124, %v_param_115, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW");
  %126 = nn.bias_add(%125, %v_param_116);
  %127 = nn.batch_norm(%126, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);
  %128 = %127.0;
  %129 = nn.leaky_relu(%128, alpha=0.2f);
  %130 = (%129, %15);
  %131 = concatenate(%130, axis=1);
  %132 = nn.conv2d(%131, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);
  %133 = nn.bias_add(%132, %v_param_122);
  %134 = nn.batch_norm(%133, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);
  %135 = %134.0;
  %136 = nn.leaky_relu(%135, alpha=0.2f);
  %137 = nn.conv2d(%136, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);
  %138 = nn.bias_add(%137, %v_param_128);
  %139 = nn.batch_norm(%138, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);
  %140 = %139.0;
  %141 = nn.conv2d(%140, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);
  %142 = nn.bias_add(%141, %v_param_134);
  %143 = sigmoid(%142);
  (%13, %30, %47, %64, %143)
}
