{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.dataflow_pattern import rewrite\n",
    "from tvm.relay.dataflow_pattern import *\n",
    "import numpy as np\n",
    "from test_model import Model\n",
    "from tvm.relay import transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = is_op(\"nn.relu\")(is_op(\"nn.conv2d\")(wildcard(), wildcard()))\n",
    "\n",
    "# # A graph.\n",
    "# x = relay.var('input')\n",
    "# w = relay.var('weight')\n",
    "# conv2d = relay.op.nn.conv2d(x, w)\n",
    "# relu = relay.op.nn.relu(conv2d)\n",
    "# print('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pattern.partition(relu, {'Composite': 'one_layer'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = Model(3, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cuda'\n",
    "dev = tvm.cuda()\n",
    "img_size = 256\n",
    "input_data = np.random.normal(0,1,(1,img_size,img_size,3)).astype(np.float32)\n",
    "# tvm result\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "\n",
    "shape_dict = {\"input_1\": input_data.shape}\n",
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
       "  %3 = %2.0;\n",
       "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
       "  %5 = nn.conv2d(%4, %v_param_7, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %6 = nn.bias_add(%5, %v_param_8);\n",
       "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
       "  %7.0\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.op.annotation import compiler_begin, compiler_end\n",
    "\n",
    "def test_extern_ccompiler_single_op():\n",
    "    @transform.function_pass(opt_level=0)\n",
    "    class MyAnnotator:\n",
    "        def transform_function(self, func, mod, dev):\n",
    "            class Annotator(tvm.relay.ExprMutator):\n",
    "                def visit_call(self, call):\n",
    "                    new_args = []\n",
    "                    for arg in call.args:\n",
    "                        ann = compiler_begin(self.visit(arg), \"ccompiler\")\n",
    "                        new_args.append(ann)\n",
    "                    new_call = relay.Call(call.op, new_args)\n",
    "                    return compiler_end(new_call, \"ccompiler\")\n",
    "\n",
    "            return Annotator().visit(func)\n",
    "\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    z = x + y\n",
    "    z = z + relay.const(9.0)\n",
    "    z = z + relay.const(9.0)\n",
    "    f = relay.Function([x, y], z)\n",
    "    x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = MyAnnotator()(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    # print(mod)\n",
    "    # print(\"---------------\")\n",
    "    # print({\"x\": x_data, \"y\": y_data}, (8, 8), x_data + y_data)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = test_extern_ccompiler_single_op()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.ir.module.IRModule"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule.from_expr(mm['tvmgen_default_ccompiler_main_0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @tvmgen_default_ccompiler_main_0(%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
       "  add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  5: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  4: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  3: tvm::relay::backend::RelayBuildModule::OptimizeImpl(tvm::IRModule)\n  2: tvm::relay::backend::BindParamsInModule(tvm::IRModule, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::NDArray, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tvm::runtime::NDArray> > > const&)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     lib \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mbuild(mod, target, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:438\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    437\u001b[0m     bld_mod \u001b[39m=\u001b[39m BuildModule()\n\u001b[0;32m--> 438\u001b[0m     graph_json, runtime_mod, params \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39;49mbuild(\n\u001b[1;32m    439\u001b[0m         mod\u001b[39m=\u001b[39;49mir_mod,\n\u001b[1;32m    440\u001b[0m         target\u001b[39m=\u001b[39;49mraw_targets,\n\u001b[1;32m    441\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    442\u001b[0m         executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m    443\u001b[0m         runtime\u001b[39m=\u001b[39;49mruntime,\n\u001b[1;32m    444\u001b[0m         workspace_memory_pools\u001b[39m=\u001b[39;49mworkspace_memory_pools,\n\u001b[1;32m    445\u001b[0m         constant_memory_pools\u001b[39m=\u001b[39;49mconstant_memory_pools,\n\u001b[1;32m    446\u001b[0m         mod_name\u001b[39m=\u001b[39;49mmod_name,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m     func_metadata \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_function_metadata()\n\u001b[1;32m    449\u001b[0m     devices \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[39mor\u001b[39;00m is_meta_schedule_enabled() \u001b[39mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[39m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[39m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  5: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  4: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  3: tvm::relay::backend::RelayBuildModule::OptimizeImpl(tvm::IRModule)\n  2: tvm::relay::backend::BindParamsInModule(tvm::IRModule, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::NDArray, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tvm::runtime::NDArray> > > const&)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "<class 'tvm.ir.expr.GlobalVar'> has no attribute params",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m z \u001b[39m=\u001b[39m mm\u001b[39m.\u001b[39mget_global_vars()[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m f \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mFunction(z\u001b[39m.\u001b[39;49mparams, z\u001b[39m.\u001b[39mbody)\n\u001b[1;32m      3\u001b[0m mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mIRModule()\n\u001b[1;32m      4\u001b[0m mod[\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m f\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/runtime/object.py:67\u001b[0m, in \u001b[0;36mObject.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_node_api\u001b[39m.\u001b[39mNodeGetAttr(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)), name)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: <class 'tvm.ir.expr.GlobalVar'> has no attribute params"
     ]
    }
   ],
   "source": [
    "z = mm.get_global_vars()[0]\n",
    "f = relay.Function(z.params, z.body)\n",
    "mod = tvm.IRModule()\n",
    "mod['main'] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvmgen_default_ccompiler_main_4\n",
      "tvmgen_default_ccompiler_main_0\n",
      "tvmgen_default_ccompiler_main_2\n",
      "main\n"
     ]
    }
   ],
   "source": [
    "for func in mm.functions:\n",
    "    print(func.astext().split('\\n')[-1].split('@')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "z = mm['tvmgen_default_ccompiler_main_0'](x,y)\n",
    "f = relay.Function([x, y], z)\n",
    "mod1 = tvm.IRModule()\n",
    "mod1['main'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.function.Function"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  3: TVMFuncCall\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  0: tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.IRModule(0: Map<GlobalVar, BaseFunc>, 1: Map<GlobalTypeVar, relay.TypeData>) -> IRModule: error while converting argument 0: [21:29:35] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected Map[GlobalVar, BaseFunc], but got relay.Function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m z\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mglobal_symbol \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m z \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mwith_attr(\u001b[39m\"\u001b[39m\u001b[39mglobal_symbol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39;49mIRModule(z)\n\u001b[1;32m      5\u001b[0m \u001b[39m# mod['main'] = z\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:62\u001b[0m, in \u001b[0;36mIRModule.__init__\u001b[0;34m(self, functions, type_definitions)\u001b[0m\n\u001b[1;32m     60\u001b[0m         mapped_type_defs[k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     61\u001b[0m     type_definitions \u001b[39m=\u001b[39m mapped_type_defs\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__init_handle_by_constructor__(_ffi_api\u001b[39m.\u001b[39;49mIRModule, functions, type_definitions)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/object.py:136\u001b[0m, in \u001b[0;36mObjectBase.__init_handle_by_constructor__\u001b[0;34m(self, fconstructor, *args)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m# assign handle first to avoid error raising\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m handle \u001b[39m=\u001b[39m __init_by_constructor__(fconstructor, args)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, ObjectHandle):\n\u001b[1;32m    138\u001b[0m     handle \u001b[39m=\u001b[39m ObjectHandle(handle)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:260\u001b[0m, in \u001b[0;36m__init_handle_by_constructor__\u001b[0;34m(fconstructor, args)\u001b[0m\n\u001b[1;32m    248\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    250\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    251\u001b[0m         fconstructor\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    259\u001b[0m ):\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    261\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    262\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  3: TVMFuncCall\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  0: tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.IRModule(0: Map<GlobalVar, BaseFunc>, 1: Map<GlobalTypeVar, relay.TypeData>) -> IRModule: error while converting argument 0: [21:29:35] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected Map[GlobalVar, BaseFunc], but got relay.Function\n"
     ]
    }
   ],
   "source": [
    "z = mm['tvmgen_default_ccompiler_main_0']\n",
    "z.attrs.global_symbol = 'main'\n",
    "z = z.with_attr(\"global_symbol\", \"main\")\n",
    "mod = tvm.IRModule(z)\n",
    "# mod['main'] = z\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func0 = func0.with_attr(\"global_symbol\", \"main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%x: Tensor[(8, 8), float32], %y: Tensor[(8, 8), float32]) {\n",
       "  %0 = fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
       "    add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
       "  } /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */;\n",
       "  %0(%x, %y)\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = mm['tvmgen_default_ccompiler_main_0']\n",
    "f = relay.Function(z.params, z.body)\n",
    "mod = tvm.IRModule()\n",
    "mod['main'] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphExecutorFactoryModule' object has no attribute 'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lib\u001b[39m.\u001b[39;49mbody\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphExecutorFactoryModule' object has no attribute 'body'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */) {\n",
       "  add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
       "}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod2, target, params=params)\n",
    "    # lib = relay.build(mod2, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
      "  add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
      "} /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(mm['tvmgen_default_ccompiler_main_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%x: Tensor[(8, 8), float32], %y: Tensor[(8, 8), float32]) {\n",
      "  %0 = fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
      "    add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
      "  } /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */;\n",
      "  %0(%x, %y)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "    # lib = relay.build(mod2, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.relay.backend.executor_factory.GraphExecutorFactoryModule at 0x7fe15c70dd00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(type(legion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mm['main']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = type(mm['tvmgen_default_ccompiler_main_0'])\n",
    "# mod = tvm.IRModule()\n",
    "# mod[\"main\"] = mm['tvmgen_default_ccompiler_main_0']\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legion = mm['tvmgen_default_ccompiler_main_0']\n",
    "# mod2 = tvm.IRModule()\n",
    "# mod2[\"main\"] = legion\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n",
    "    lib = relay.build(mm, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  8: TVMFuncCall\n  7: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  6: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  5: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::relay::backend::GraphExecutorCodegenModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::backend::GraphExecutorCodegen::Codegen(tvm::IRModule, tvm::relay::Function, tvm::runtime::String)\n  2: tvm::relay::tec::UpdateMainWorkspaceSize(tvm::IRModule const&, tvm::CompilationConfig const&, tvm::runtime::Map<tvm::RelayExpr, tvm::relay::backend::StorageInfo, void, void>)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m mod2[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m legion\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39m# lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     lib \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mbuild(mod2, target, params\u001b[39m=\u001b[39;49mparams,mod_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtvmgen_default_ccompiler_main_0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:438\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    437\u001b[0m     bld_mod \u001b[39m=\u001b[39m BuildModule()\n\u001b[0;32m--> 438\u001b[0m     graph_json, runtime_mod, params \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39;49mbuild(\n\u001b[1;32m    439\u001b[0m         mod\u001b[39m=\u001b[39;49mir_mod,\n\u001b[1;32m    440\u001b[0m         target\u001b[39m=\u001b[39;49mraw_targets,\n\u001b[1;32m    441\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    442\u001b[0m         executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m    443\u001b[0m         runtime\u001b[39m=\u001b[39;49mruntime,\n\u001b[1;32m    444\u001b[0m         workspace_memory_pools\u001b[39m=\u001b[39;49mworkspace_memory_pools,\n\u001b[1;32m    445\u001b[0m         constant_memory_pools\u001b[39m=\u001b[39;49mconstant_memory_pools,\n\u001b[1;32m    446\u001b[0m         mod_name\u001b[39m=\u001b[39;49mmod_name,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m     func_metadata \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_function_metadata()\n\u001b[1;32m    449\u001b[0m     devices \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[39mor\u001b[39;00m is_meta_schedule_enabled() \u001b[39mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[39m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[39m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  8: TVMFuncCall\n  7: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  6: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  5: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::relay::backend::GraphExecutorCodegenModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::backend::GraphExecutorCodegen::Codegen(tvm::IRModule, tvm::relay::Function, tvm::runtime::String)\n  2: tvm::relay::tec::UpdateMainWorkspaceSize(tvm::IRModule const&, tvm::CompilationConfig const&, tvm::runtime::Map<tvm::RelayExpr, tvm::relay::backend::StorageInfo, void, void>)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]"
     ]
    }
   ],
   "source": [
    "# legion = mm['tvmgen_default_ccompiler_main_0']\n",
    "# mod2 = tvm.IRModule()\n",
    "# mod2[\"main\"] = legion\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n",
    "    lib = relay.build(mm, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mm, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/workspace/tvm-v0.9.0/python/tvm/driver/build_module.py:267: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mm, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.relay.backend.executor_factory.GraphExecutorFactoryModule at 0x7fe15b392190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.runtime.packed_func.PackedFunc at 0x7fdc8dacd240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib['get_graph_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_json_raw = lib['get_graph_json']()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "import json\n",
    "def show_graph(json_data, file_name=None):\n",
    "    if type(json_data) == str:\n",
    "        json_data = json.loads(json_data)\n",
    "    A = pgv.AGraph(directed=True)\n",
    "    for node_idx, node in enumerate(json_data['nodes']):\n",
    "        for src in node['inputs']:\n",
    "            # if args.show_size == 1:\n",
    "            if 1 == 1:\n",
    "                src_size = 1\n",
    "                for i in json_data['attrs']['shape'][1][src[0]]:\n",
    "                    src_size = src_size * i\n",
    "                \n",
    "                dst_size = 1\n",
    "                for i in json_data['attrs']['shape'][1][node_idx]:\n",
    "                    dst_size = dst_size * i\n",
    "                # print(src[0], json_data['nodes'][src[0]]['name'], src_size)\n",
    "\n",
    "                A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]) + \"[{}]\".format(src_size), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]) + \"[{}]\".format(dst_size))\n",
    "            else:\n",
    "                A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]))\n",
    "    if file_name:\n",
    "        A.draw(file_name + '.png', format='png', prog='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph_json_raw, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
