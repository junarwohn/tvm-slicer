keras.engine.functional
def @main(%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {
  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %2 = nn.batch_norm(%1, meta[relay.Constant][2] /* ty=Tensor[(64), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64), float32] */, meta[relay.Constant][4] /* ty=Tensor[(64), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %3 = %2.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %4 = nn.leaky_relu(%3, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %5 = multiply(%4, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %6 = round(%5) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %7 = clip(%6, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %8 = cast(%7, dtype="int8") /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %9 = annotation.stop_fusion(%8) /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %10 = cast(%9, dtype="float32") /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %11 = divide(%10, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %12 = nn.conv2d(%11, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %13 = nn.bias_add(%12, meta[relay.Constant][7] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %14 = nn.batch_norm(%13, meta[relay.Constant][8] /* ty=Tensor[(64), float32] */, meta[relay.Constant][9] /* ty=Tensor[(64), float32] */, meta[relay.Constant][10] /* ty=Tensor[(64), float32] */, meta[relay.Constant][11] /* ty=Tensor[(64), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %15 = %14.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %16 = multiply(%15, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %17 = round(%16) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %18 = clip(%17, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %19 = cast(%18, dtype="int8") /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %20 = annotation.stop_fusion(%19) /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %21 = cast(%20, dtype="float32") /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %22 = divide(%21, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %23 = nn.max_pool2d(%22, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %24 = multiply(%23, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %25 = round(%24) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %26 = clip(%25, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %27 = cast(%26, dtype="int8") /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */;
  annotation.stop_fusion(%27) /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */
}


-=---------------------------------
def @main(%data_n_0: Tensor[(1, 64, 128i64, 128i64), int8] /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */, %x_38: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */) {
  %0 = cast(%data_n_0, dtype="float32") /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %1 = divide(%0, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;
  %2 = nn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(128, 64, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %3 = nn.bias_add(%2, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %4 = nn.batch_norm(%3, meta[relay.Constant][2] /* ty=Tensor[(128), float32] */, meta[relay.Constant][3] /* ty=Tensor[(128), float32] */, meta[relay.Constant][4] /* ty=Tensor[(128), float32] */, meta[relay.Constant][5] /* ty=Tensor[(128), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %5 = %4.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %6 = nn.leaky_relu(%5, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %7 = multiply(%6, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %8 = round(%7) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %9 = clip(%8, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %10 = cast(%9, dtype="int8") /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %11 = annotation.stop_fusion(%10) /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %12 = cast(%11, dtype="float32") /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %13 = divide(%12, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %14 = nn.conv2d(%13, meta[relay.Constant][6] /* ty=Tensor[(128, 128, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %15 = nn.bias_add(%14, meta[relay.Constant][7] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %16 = nn.batch_norm(%15, meta[relay.Constant][8] /* ty=Tensor[(128), float32] */, meta[relay.Constant][9] /* ty=Tensor[(128), float32] */, meta[relay.Constant][10] /* ty=Tensor[(128), float32] */, meta[relay.Constant][11] /* ty=Tensor[(128), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %17 = %16.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %18 = multiply(%17, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %19 = round(%18) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %20 = clip(%19, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %21 = cast(%20, dtype="int8") /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %22 = annotation.stop_fusion(%21) /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %23 = cast(%22, dtype="float32") /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %24 = divide(%23, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %25 = nn.max_pool2d(%24, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %26 = multiply(%25, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %27 = round(%26) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %28 = clip(%27, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %29 = cast(%28, dtype="int8") /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */;
  %30 = annotation.stop_fusion(%29) /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */;
  %31 = cast(%30, dtype="float32") /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %32 = divide(%31, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;
  %33 = nn.conv2d(%32, meta[relay.Constant][12] /* ty=Tensor[(256, 128, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %34 = nn.bias_add(%33, meta[relay.Constant][13] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %35 = nn.batch_norm(%34, meta[relay.Constant][14] /* ty=Tensor[(256), float32] */, meta[relay.Constant][15] /* ty=Tensor[(256), float32] */, meta[relay.Constant][16] /* ty=Tensor[(256), float32] */, meta[relay.Constant][17] /* ty=Tensor[(256), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %36 = %35.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %37 = nn.leaky_relu(%36, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %38 = multiply(%37, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %39 = round(%38) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %40 = clip(%39, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %41 = cast(%40, dtype="int8") /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %42 = annotation.stop_fusion(%41) /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %43 = cast(%42, dtype="float32") /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %44 = divide(%43, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %45 = nn.conv2d(%44, meta[relay.Constant][18] /* ty=Tensor[(256, 256, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %46 = nn.bias_add(%45, meta[relay.Constant][19] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %47 = nn.batch_norm(%46, meta[relay.Constant][20] /* ty=Tensor[(256), float32] */, meta[relay.Constant][21] /* ty=Tensor[(256), float32] */, meta[relay.Constant][22] /* ty=Tensor[(256), float32] */, meta[relay.Constant][23] /* ty=Tensor[(256), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %48 = %47.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %49 = multiply(%48, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %50 = round(%49) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %51 = clip(%50, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %52 = cast(%51, dtype="int8") /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %53 = annotation.stop_fusion(%52) /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %54 = cast(%53, dtype="float32") /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %55 = divide(%54, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %56 = nn.max_pool2d(%55, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %57 = multiply(%56, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %58 = round(%57) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %59 = clip(%58, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %60 = cast(%59, dtype="int8") /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */;
  %61 = annotation.stop_fusion(%60) /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */;
  %62 = cast(%61, dtype="float32") /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %63 = divide(%62, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;
  %64 = nn.conv2d(%63, meta[relay.Constant][24] /* ty=Tensor[(512, 256, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %65 = nn.bias_add(%64, meta[relay.Constant][25] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %66 = nn.batch_norm(%65, meta[relay.Constant][26] /* ty=Tensor[(512), float32] */, meta[relay.Constant][27] /* ty=Tensor[(512), float32] */, meta[relay.Constant][28] /* ty=Tensor[(512), float32] */, meta[relay.Constant][29] /* ty=Tensor[(512), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %67 = %66.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %68 = nn.leaky_relu(%67, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %69 = multiply(%68, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %70 = round(%69) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %71 = clip(%70, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %72 = cast(%71, dtype="int8") /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %73 = annotation.stop_fusion(%72) /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %74 = cast(%73, dtype="float32") /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %75 = divide(%74, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %76 = nn.conv2d(%75, meta[relay.Constant][30] /* ty=Tensor[(512, 512, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %77 = nn.bias_add(%76, meta[relay.Constant][31] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %78 = nn.batch_norm(%77, meta[relay.Constant][32] /* ty=Tensor[(512), float32] */, meta[relay.Constant][33] /* ty=Tensor[(512), float32] */, meta[relay.Constant][34] /* ty=Tensor[(512), float32] */, meta[relay.Constant][35] /* ty=Tensor[(512), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %79 = %78.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %80 = multiply(%79, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %81 = round(%80) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %82 = clip(%81, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %83 = cast(%82, dtype="int8") /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %84 = annotation.stop_fusion(%83) /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %85 = cast(%84, dtype="float32") /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %86 = divide(%85, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %87 = nn.max_pool2d(%86, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %88 = multiply(%87, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %89 = round(%88) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %90 = clip(%89, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %91 = cast(%90, dtype="int8") /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */;
  %92 = annotation.stop_fusion(%91) /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */;
  %93 = cast(%92, dtype="float32") /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %94 = divide(%93, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;
  %95 = nn.conv2d(%94, meta[relay.Constant][36] /* ty=Tensor[(1024, 512, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %96 = nn.bias_add(%95, meta[relay.Constant][37] /* ty=Tensor[(1024), float32] */) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %97 = nn.batch_norm(%96, meta[relay.Constant][38] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][39] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][40] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][41] /* ty=Tensor[(1024), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %98 = %97.0 /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %99 = nn.leaky_relu(%98, alpha=0.2f) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %100 = multiply(%99, 8f /* ty=float32 */) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %101 = round(%100) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %102 = clip(%101, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %103 = cast(%102, dtype="int8") /* ty=Tensor[(1, 1024, 16, 16), int8] */;
  %104 = annotation.stop_fusion(%103) /* ty=Tensor[(1, 1024, 16, 16), int8] */;
  %105 = cast(%104, dtype="float32") /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %106 = divide(%105, 8f /* ty=float32 */) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %107 = nn.conv2d(%106, meta[relay.Constant][42] /* ty=Tensor[(1024, 1024, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %108 = nn.bias_add(%107, meta[relay.Constant][43] /* ty=Tensor[(1024), float32] */) /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %109 = nn.batch_norm(%108, meta[relay.Constant][44] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][45] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][46] /* ty=Tensor[(1024), float32] */, meta[relay.Constant][47] /* ty=Tensor[(1024), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %110 = %109.0 /* ty=Tensor[(1, 1024, 16, 16), float32] */;
  %111 = nn.conv2d_transpose(%110, meta[relay.Constant][48] /* ty=Tensor[(1024, 512, 3, 3), float32] */, channels=512, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW") /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %112 = nn.bias_add(%111, meta[relay.Constant][49] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %113 = nn.batch_norm(%112, meta[relay.Constant][50] /* ty=Tensor[(512), float32] */, meta[relay.Constant][51] /* ty=Tensor[(512), float32] */, meta[relay.Constant][52] /* ty=Tensor[(512), float32] */, meta[relay.Constant][53] /* ty=Tensor[(512), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %114 = %113.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %115 = nn.leaky_relu(%114, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %116 = multiply(%115, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %117 = round(%116) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %118 = clip(%117, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %119 = cast(%118, dtype="int8") /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %120 = annotation.stop_fusion(%119) /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %121 = cast(%120, dtype="float32") /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %122 = divide(%121, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %123 = (%122, %86) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(1, 512, 32, 32), float32]) */;
  %124 = concatenate(%123, axis=1) /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %125 = multiply(%124, 8f /* ty=float32 */) /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %126 = round(%125) /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %127 = clip(%126, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %128 = cast(%127, dtype="int8") /* ty=Tensor[(1, 1024, 32, 32), int8] */;
  %129 = annotation.stop_fusion(%128) /* ty=Tensor[(1, 1024, 32, 32), int8] */;
  %130 = cast(%129, dtype="float32") /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %131 = divide(%130, 8f /* ty=float32 */) /* ty=Tensor[(1, 1024, 32, 32), float32] */;
  %132 = nn.conv2d(%131, meta[relay.Constant][54] /* ty=Tensor[(512, 1024, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %133 = nn.bias_add(%132, meta[relay.Constant][55] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %134 = nn.batch_norm(%133, meta[relay.Constant][56] /* ty=Tensor[(512), float32] */, meta[relay.Constant][57] /* ty=Tensor[(512), float32] */, meta[relay.Constant][58] /* ty=Tensor[(512), float32] */, meta[relay.Constant][59] /* ty=Tensor[(512), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %135 = %134.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %136 = nn.leaky_relu(%135, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %137 = multiply(%136, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %138 = round(%137) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %139 = clip(%138, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %140 = cast(%139, dtype="int8") /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %141 = annotation.stop_fusion(%140) /* ty=Tensor[(1, 512, 32, 32), int8] */;
  %142 = cast(%141, dtype="float32") /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %143 = divide(%142, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %144 = nn.conv2d(%143, meta[relay.Constant][60] /* ty=Tensor[(512, 512, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %145 = nn.bias_add(%144, meta[relay.Constant][61] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %146 = nn.batch_norm(%145, meta[relay.Constant][62] /* ty=Tensor[(512), float32] */, meta[relay.Constant][63] /* ty=Tensor[(512), float32] */, meta[relay.Constant][64] /* ty=Tensor[(512), float32] */, meta[relay.Constant][65] /* ty=Tensor[(512), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %147 = %146.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;
  %148 = nn.conv2d_transpose(%147, meta[relay.Constant][66] /* ty=Tensor[(512, 256, 3, 3), float32] */, channels=256, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW") /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %149 = nn.bias_add(%148, meta[relay.Constant][67] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %150 = nn.batch_norm(%149, meta[relay.Constant][68] /* ty=Tensor[(256), float32] */, meta[relay.Constant][69] /* ty=Tensor[(256), float32] */, meta[relay.Constant][70] /* ty=Tensor[(256), float32] */, meta[relay.Constant][71] /* ty=Tensor[(256), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %151 = %150.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %152 = nn.leaky_relu(%151, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %153 = multiply(%152, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %154 = round(%153) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %155 = clip(%154, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %156 = cast(%155, dtype="int8") /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %157 = annotation.stop_fusion(%156) /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %158 = cast(%157, dtype="float32") /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %159 = divide(%158, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %160 = (%159, %55) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(1, 256, 64, 64), float32]) */;
  %161 = concatenate(%160, axis=1) /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %162 = multiply(%161, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %163 = round(%162) /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %164 = clip(%163, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %165 = cast(%164, dtype="int8") /* ty=Tensor[(1, 512, 64, 64), int8] */;
  %166 = annotation.stop_fusion(%165) /* ty=Tensor[(1, 512, 64, 64), int8] */;
  %167 = cast(%166, dtype="float32") /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %168 = divide(%167, 8f /* ty=float32 */) /* ty=Tensor[(1, 512, 64, 64), float32] */;
  %169 = nn.conv2d(%168, meta[relay.Constant][72] /* ty=Tensor[(256, 512, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %170 = nn.bias_add(%169, meta[relay.Constant][73] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %171 = nn.batch_norm(%170, meta[relay.Constant][74] /* ty=Tensor[(256), float32] */, meta[relay.Constant][75] /* ty=Tensor[(256), float32] */, meta[relay.Constant][76] /* ty=Tensor[(256), float32] */, meta[relay.Constant][77] /* ty=Tensor[(256), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %172 = %171.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %173 = nn.leaky_relu(%172, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %174 = multiply(%173, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %175 = round(%174) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %176 = clip(%175, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %177 = cast(%176, dtype="int8") /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %178 = annotation.stop_fusion(%177) /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %179 = cast(%178, dtype="float32") /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %180 = divide(%179, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %181 = nn.conv2d(%180, meta[relay.Constant][78] /* ty=Tensor[(256, 256, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %182 = nn.bias_add(%181, meta[relay.Constant][79] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %183 = nn.batch_norm(%182, meta[relay.Constant][80] /* ty=Tensor[(256), float32] */, meta[relay.Constant][81] /* ty=Tensor[(256), float32] */, meta[relay.Constant][82] /* ty=Tensor[(256), float32] */, meta[relay.Constant][83] /* ty=Tensor[(256), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %184 = %183.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %185 = nn.conv2d_transpose(%184, meta[relay.Constant][84] /* ty=Tensor[(256, 128, 3, 3), float32] */, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW") /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %186 = nn.bias_add(%185, meta[relay.Constant][85] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %187 = nn.batch_norm(%186, meta[relay.Constant][86] /* ty=Tensor[(128), float32] */, meta[relay.Constant][87] /* ty=Tensor[(128), float32] */, meta[relay.Constant][88] /* ty=Tensor[(128), float32] */, meta[relay.Constant][89] /* ty=Tensor[(128), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %188 = %187.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %189 = nn.leaky_relu(%188, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %190 = multiply(%189, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %191 = round(%190) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %192 = clip(%191, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %193 = cast(%192, dtype="int8") /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %194 = annotation.stop_fusion(%193) /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %195 = cast(%194, dtype="float32") /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %196 = divide(%195, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %197 = (%196, %24) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(1, 128, 128, 128), float32]) */;
  %198 = concatenate(%197, axis=1) /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %199 = multiply(%198, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %200 = round(%199) /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %201 = clip(%200, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %202 = cast(%201, dtype="int8") /* ty=Tensor[(1, 256, 128, 128), int8] */;
  %203 = annotation.stop_fusion(%202) /* ty=Tensor[(1, 256, 128, 128), int8] */;
  %204 = cast(%203, dtype="float32") /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %205 = divide(%204, 8f /* ty=float32 */) /* ty=Tensor[(1, 256, 128, 128), float32] */;
  %206 = nn.conv2d(%205, meta[relay.Constant][90] /* ty=Tensor[(128, 256, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %207 = nn.bias_add(%206, meta[relay.Constant][91] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %208 = nn.batch_norm(%207, meta[relay.Constant][92] /* ty=Tensor[(128), float32] */, meta[relay.Constant][93] /* ty=Tensor[(128), float32] */, meta[relay.Constant][94] /* ty=Tensor[(128), float32] */, meta[relay.Constant][95] /* ty=Tensor[(128), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %209 = %208.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %210 = nn.leaky_relu(%209, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %211 = multiply(%210, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %212 = round(%211) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %213 = clip(%212, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %214 = cast(%213, dtype="int8") /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %215 = annotation.stop_fusion(%214) /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %216 = cast(%215, dtype="float32") /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %217 = divide(%216, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %218 = nn.conv2d(%217, meta[relay.Constant][96] /* ty=Tensor[(128, 128, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %219 = nn.bias_add(%218, meta[relay.Constant][97] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %220 = nn.batch_norm(%219, meta[relay.Constant][98] /* ty=Tensor[(128), float32] */, meta[relay.Constant][99] /* ty=Tensor[(128), float32] */, meta[relay.Constant][100] /* ty=Tensor[(128), float32] */, meta[relay.Constant][101] /* ty=Tensor[(128), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %221 = %220.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %222 = nn.conv2d_transpose(%221, meta[relay.Constant][102] /* ty=Tensor[(128, 64, 3, 3), float32] */, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW") /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %223 = nn.bias_add(%222, meta[relay.Constant][103] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %224 = nn.batch_norm(%223, meta[relay.Constant][104] /* ty=Tensor[(64), float32] */, meta[relay.Constant][105] /* ty=Tensor[(64), float32] */, meta[relay.Constant][106] /* ty=Tensor[(64), float32] */, meta[relay.Constant][107] /* ty=Tensor[(64), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %225 = %224.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %226 = nn.leaky_relu(%225, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %227 = multiply(%226, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %228 = round(%227) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %229 = clip(%228, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %230 = cast(%229, dtype="int8") /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %231 = annotation.stop_fusion(%230) /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %232 = cast(%231, dtype="float32") /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %233 = divide(%232, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %234 = (%233, %x_38) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(1, 64, 256, 256), float32]) */;
  %235 = concatenate(%234, axis=1) /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %236 = multiply(%235, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %237 = round(%236) /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %238 = clip(%237, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %239 = cast(%238, dtype="int8") /* ty=Tensor[(1, 128, 256, 256), int8] */;
  %240 = annotation.stop_fusion(%239) /* ty=Tensor[(1, 128, 256, 256), int8] */;
  %241 = cast(%240, dtype="float32") /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %242 = divide(%241, 8f /* ty=float32 */) /* ty=Tensor[(1, 128, 256, 256), float32] */;
  %243 = nn.conv2d(%242, meta[relay.Constant][108] /* ty=Tensor[(64, 128, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %244 = nn.bias_add(%243, meta[relay.Constant][109] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %245 = nn.batch_norm(%244, meta[relay.Constant][110] /* ty=Tensor[(64), float32] */, meta[relay.Constant][111] /* ty=Tensor[(64), float32] */, meta[relay.Constant][112] /* ty=Tensor[(64), float32] */, meta[relay.Constant][113] /* ty=Tensor[(64), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %246 = %245.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %247 = nn.leaky_relu(%246, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %248 = multiply(%247, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %249 = round(%248) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %250 = clip(%249, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %251 = cast(%250, dtype="int8") /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %252 = annotation.stop_fusion(%251) /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %253 = cast(%252, dtype="float32") /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %254 = divide(%253, 8f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %255 = nn.conv2d(%254, meta[relay.Constant][114] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %256 = nn.bias_add(%255, meta[relay.Constant][115] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %257 = nn.batch_norm(%256, meta[relay.Constant][116] /* ty=Tensor[(64), float32] */, meta[relay.Constant][117] /* ty=Tensor[(64), float32] */, meta[relay.Constant][118] /* ty=Tensor[(64), float32] */, meta[relay.Constant][119] /* ty=Tensor[(64), float32] */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %258 = %257.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %259 = nn.conv2d(%258, meta[relay.Constant][120] /* ty=Tensor[(1, 64, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=1, kernel_size=[3, 3]) /* ty=Tensor[(1, 1, 256, 256), float32] */;
  %260 = nn.bias_add(%259, meta[relay.Constant][121] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */;
  sigmoid(%260) /* ty=Tensor[(1, 1, 256, 256), float32] */
}


-=---------------------------------
[[11, 0, 0]]
[[114, 0, 0]]
