keras.engine.functional
fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(64, 3, 3, 3), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 64, 3, 3), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(128, 64, 3, 3), float32], %v_param_14: Tensor[(128), float32], %v_param_15: Tensor[(128), float32], %v_param_16: Tensor[(128), float32], %v_param_17: Tensor[(128), float32], %v_param_18: Tensor[(128), float32], %v_param_19: Tensor[(128, 128, 3, 3), float32], %v_param_20: Tensor[(128), float32], %v_param_21: Tensor[(128), float32], %v_param_22: Tensor[(128), float32], %v_param_23: Tensor[(128), float32], %v_param_24: Tensor[(128), float32], %v_param_25: Tensor[(256, 128, 3, 3), float32], %v_param_26: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(256, 256, 3, 3), float32], %v_param_32: Tensor[(256), float32], %v_param_33: Tensor[(256), float32], %v_param_34: Tensor[(256), float32], %v_param_35: Tensor[(256), float32], %v_param_36: Tensor[(256), float32], %v_param_37: Tensor[(512, 256, 3, 3), float32], %v_param_38: Tensor[(512), float32], %v_param_39: Tensor[(512), float32], %v_param_40: Tensor[(512), float32], %v_param_41: Tensor[(512), float32], %v_param_42: Tensor[(512), float32], %v_param_43: Tensor[(512, 512, 3, 3), float32], %v_param_44: Tensor[(512), float32], %v_param_45: Tensor[(512), float32], %v_param_46: Tensor[(512), float32], %v_param_47: Tensor[(512), float32], %v_param_48: Tensor[(512), float32], %v_param_49: Tensor[(1024, 512, 3, 3), float32], %v_param_50: Tensor[(1024), float32], %v_param_51: Tensor[(1024), float32], %v_param_52: Tensor[(1024), float32], %v_param_53: Tensor[(1024), float32], %v_param_54: Tensor[(1024), float32], %v_param_55: Tensor[(1024, 1024, 3, 3), float32], %v_param_56: Tensor[(1024), float32], %v_param_57: Tensor[(1024), float32], %v_param_58: Tensor[(1024), float32], %v_param_59: Tensor[(1024), float32], %v_param_60: Tensor[(1024), float32], %v_param_61: Tensor[(1024, 512, 3, 3), float32], %v_param_62: Tensor[(512), float32], %v_param_63: Tensor[(512), float32], %v_param_64: Tensor[(512), float32], %v_param_65: Tensor[(512), float32], %v_param_66: Tensor[(512), float32], %v_param_67: Tensor[(512, 1024, 3, 3), float32], %v_param_68: Tensor[(512), float32], %v_param_69: Tensor[(512), float32], %v_param_70: Tensor[(512), float32], %v_param_71: Tensor[(512), float32], %v_param_72: Tensor[(512), float32], %v_param_73: Tensor[(512, 512, 3, 3), float32], %v_param_74: Tensor[(512), float32], %v_param_75: Tensor[(512), float32], %v_param_76: Tensor[(512), float32], %v_param_77: Tensor[(512), float32], %v_param_78: Tensor[(512), float32], %v_param_79: Tensor[(512, 256, 3, 3), float32], %v_param_80: Tensor[(256), float32], %v_param_81: Tensor[(256), float32], %v_param_82: Tensor[(256), float32], %v_param_83: Tensor[(256), float32], %v_param_84: Tensor[(256), float32], %v_param_85: Tensor[(256, 512, 3, 3), float32], %v_param_86: Tensor[(256), float32], %v_param_87: Tensor[(256), float32], %v_param_88: Tensor[(256), float32], %v_param_89: Tensor[(256), float32], %v_param_90: Tensor[(256), float32], %v_param_91: Tensor[(256, 256, 3, 3), float32], %v_param_92: Tensor[(256), float32], %v_param_93: Tensor[(256), float32], %v_param_94: Tensor[(256), float32], %v_param_95: Tensor[(256), float32], %v_param_96: Tensor[(256), float32], %v_param_97: Tensor[(256, 128, 3, 3), float32], %v_param_98: Tensor[(128), float32], %v_param_99: Tensor[(128), float32], %v_param_100: Tensor[(128), float32], %v_param_101: Tensor[(128), float32], %v_param_102: Tensor[(128), float32], %v_param_103: Tensor[(128, 256, 3, 3), float32], %v_param_104: Tensor[(128), float32], %v_param_105: Tensor[(128), float32], %v_param_106: Tensor[(128), float32], %v_param_107: Tensor[(128), float32], %v_param_108: Tensor[(128), float32], %v_param_109: Tensor[(128, 128, 3, 3), float32], %v_param_110: Tensor[(128), float32], %v_param_111: Tensor[(128), float32], %v_param_112: Tensor[(128), float32], %v_param_113: Tensor[(128), float32], %v_param_114: Tensor[(128), float32], %v_param_115: Tensor[(128, 64, 3, 3), float32], %v_param_116: Tensor[(64), float32], %v_param_117: Tensor[(64), float32], %v_param_118: Tensor[(64), float32], %v_param_119: Tensor[(64), float32], %v_param_120: Tensor[(64), float32], %v_param_121: Tensor[(64, 128, 3, 3), float32], %v_param_122: Tensor[(64), float32], %v_param_123: Tensor[(64), float32], %v_param_124: Tensor[(64), float32], %v_param_125: Tensor[(64), float32], %v_param_126: Tensor[(64), float32], %v_param_127: Tensor[(64, 64, 3, 3), float32], %v_param_128: Tensor[(64), float32], %v_param_129: Tensor[(64), float32], %v_param_130: Tensor[(64), float32], %v_param_131: Tensor[(64), float32], %v_param_132: Tensor[(64), float32], %v_param_133: Tensor[(1, 64, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {
  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);
  %1 = nn.bias_add(%0, %v_param_2);
  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);
  %3 = %2.0;
  %4 = nn.leaky_relu(%3, alpha=0.2f);
  %5 = multiply(%4, 8f);
  %6 = round(%5);
  %7 = clip(%6, a_min=-127f, a_max=127f);
  %8 = cast(%7, dtype="int8");
  %9 = annotation.stop_fusion(%8);
  %10 = cast(%9, dtype="float32");
  %11 = divide(%10, 8f);
  %12 = nn.conv2d(%11, %v_param_7, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);
  %13 = nn.bias_add(%12, %v_param_8);
  %14 = nn.batch_norm(%13, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);
  %15 = %14.0;
  %16 = multiply(%15, 8f);
  %17 = round(%16);
  %18 = clip(%17, a_min=-127f, a_max=127f);
  %19 = cast(%18, dtype="int8");
  %20 = annotation.stop_fusion(%19);
  %21 = cast(%20, dtype="float32");
  %22 = divide(%21, 8f);
  %23 = nn.max_pool2d(%22, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);
  %24 = multiply(%23, 8f);
  %25 = round(%24);
  %26 = clip(%25, a_min=-127f, a_max=127f);
  %27 = cast(%26, dtype="int8");
  %28 = annotation.stop_fusion(%27);
  %29 = cast(%28, dtype="float32");
  %30 = divide(%29, 8f);
  %31 = nn.conv2d(%30, %v_param_13, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]);
  %32 = nn.bias_add(%31, %v_param_14);
  %33 = nn.batch_norm(%32, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);
  %34 = %33.0;
  %35 = nn.leaky_relu(%34, alpha=0.2f);
  %36 = multiply(%35, 8f);
  %37 = round(%36);
  %38 = clip(%37, a_min=-127f, a_max=127f);
  %39 = cast(%38, dtype="int8");
  %40 = annotation.stop_fusion(%39);
  %41 = cast(%40, dtype="float32");
  %42 = divide(%41, 8f);
  %43 = nn.conv2d(%42, %v_param_19, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]);
  %44 = nn.bias_add(%43, %v_param_20);
  %45 = nn.batch_norm(%44, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);
  %46 = %45.0;
  %47 = multiply(%46, 8f);
  %48 = round(%47);
  %49 = clip(%48, a_min=-127f, a_max=127f);
  %50 = cast(%49, dtype="int8");
  %51 = annotation.stop_fusion(%50);
  %52 = cast(%51, dtype="float32");
  %53 = divide(%52, 8f);
  %54 = nn.max_pool2d(%53, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);
  %55 = multiply(%54, 8f);
  %56 = round(%55);
  %57 = clip(%56, a_min=-127f, a_max=127f);
  %58 = cast(%57, dtype="int8");
  %59 = annotation.stop_fusion(%58);
  %60 = cast(%59, dtype="float32");
  %61 = divide(%60, 8f);
  %62 = nn.conv2d(%61, %v_param_25, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]);
  %63 = nn.bias_add(%62, %v_param_26);
  %64 = nn.batch_norm(%63, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);
  %65 = %64.0;
  %66 = nn.leaky_relu(%65, alpha=0.2f);
  %67 = multiply(%66, 8f);
  %68 = round(%67);
  %69 = clip(%68, a_min=-127f, a_max=127f);
  %70 = cast(%69, dtype="int8");
  %71 = annotation.stop_fusion(%70);
  %72 = cast(%71, dtype="float32");
  %73 = divide(%72, 8f);
  %74 = nn.conv2d(%73, %v_param_31, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]);
  %75 = nn.bias_add(%74, %v_param_32);
  %76 = nn.batch_norm(%75, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);
  %77 = %76.0;
  %78 = multiply(%77, 8f);
  %79 = round(%78);
  %80 = clip(%79, a_min=-127f, a_max=127f);
  %81 = cast(%80, dtype="int8");
  %82 = annotation.stop_fusion(%81);
  %83 = cast(%82, dtype="float32");
  %84 = divide(%83, 8f);
  %85 = nn.max_pool2d(%84, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);
  %86 = multiply(%85, 8f);
  %87 = round(%86);
  %88 = clip(%87, a_min=-127f, a_max=127f);
  %89 = cast(%88, dtype="int8");
  %90 = annotation.stop_fusion(%89);
  %91 = cast(%90, dtype="float32");
  %92 = divide(%91, 8f);
  %93 = nn.conv2d(%92, %v_param_37, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]);
  %94 = nn.bias_add(%93, %v_param_38);
  %95 = nn.batch_norm(%94, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);
  %96 = %95.0;
  %97 = nn.leaky_relu(%96, alpha=0.2f);
  %98 = multiply(%97, 8f);
  %99 = round(%98);
  %100 = clip(%99, a_min=-127f, a_max=127f);
  %101 = cast(%100, dtype="int8");
  %102 = annotation.stop_fusion(%101);
  %103 = cast(%102, dtype="float32");
  %104 = divide(%103, 8f);
  %105 = nn.conv2d(%104, %v_param_43, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]);
  %106 = nn.bias_add(%105, %v_param_44);
  %107 = nn.batch_norm(%106, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);
  %108 = %107.0;
  %109 = multiply(%108, 8f);
  %110 = round(%109);
  %111 = clip(%110, a_min=-127f, a_max=127f);
  %112 = cast(%111, dtype="int8");
  %113 = annotation.stop_fusion(%112);
  %114 = cast(%113, dtype="float32");
  %115 = divide(%114, 8f);
  %116 = nn.max_pool2d(%115, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);
  %117 = multiply(%116, 8f);
  %118 = round(%117);
  %119 = clip(%118, a_min=-127f, a_max=127f);
  %120 = cast(%119, dtype="int8");
  %121 = annotation.stop_fusion(%120);
  %122 = cast(%121, dtype="float32");
  %123 = divide(%122, 8f);
  %124 = nn.conv2d(%123, %v_param_49, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]);
  %125 = nn.bias_add(%124, %v_param_50);
  %126 = nn.batch_norm(%125, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);
  %127 = %126.0;
  %128 = nn.leaky_relu(%127, alpha=0.2f);
  %129 = multiply(%128, 8f);
  %130 = round(%129);
  %131 = clip(%130, a_min=-127f, a_max=127f);
  %132 = cast(%131, dtype="int8");
  %133 = annotation.stop_fusion(%132);
  %134 = cast(%133, dtype="float32");
  %135 = divide(%134, 8f);
  %136 = nn.conv2d(%135, %v_param_55, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]);
  %137 = nn.bias_add(%136, %v_param_56);
  %138 = nn.batch_norm(%137, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);
  %139 = %138.0;
  %140 = nn.conv2d_transpose(%139, %v_param_61, channels=512, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW");
  %141 = nn.bias_add(%140, %v_param_62);
  %142 = nn.batch_norm(%141, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);
  %143 = %142.0;
  %144 = nn.leaky_relu(%143, alpha=0.2f);
  %145 = multiply(%144, 8f);
  %146 = round(%145);
  %147 = clip(%146, a_min=-127f, a_max=127f);
  %148 = cast(%147, dtype="int8");
  %149 = annotation.stop_fusion(%148);
  %150 = cast(%149, dtype="float32");
  %151 = divide(%150, 8f);
  %152 = (%151, %115);
  %153 = concatenate(%152, axis=1);
  %154 = multiply(%153, 8f);
  %155 = round(%154);
  %156 = clip(%155, a_min=-127f, a_max=127f);
  %157 = cast(%156, dtype="int8");
  %158 = annotation.stop_fusion(%157);
  %159 = cast(%158, dtype="float32");
  %160 = divide(%159, 8f);
  %161 = nn.conv2d(%160, %v_param_67, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]);
  %162 = nn.bias_add(%161, %v_param_68);
  %163 = nn.batch_norm(%162, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);
  %164 = %163.0;
  %165 = nn.leaky_relu(%164, alpha=0.2f);
  %166 = multiply(%165, 8f);
  %167 = round(%166);
  %168 = clip(%167, a_min=-127f, a_max=127f);
  %169 = cast(%168, dtype="int8");
  %170 = annotation.stop_fusion(%169);
  %171 = cast(%170, dtype="float32");
  %172 = divide(%171, 8f);
  %173 = nn.conv2d(%172, %v_param_73, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]);
  %174 = nn.bias_add(%173, %v_param_74);
  %175 = nn.batch_norm(%174, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);
  %176 = %175.0;
  %177 = nn.conv2d_transpose(%176, %v_param_79, channels=256, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW");
  %178 = nn.bias_add(%177, %v_param_80);
  %179 = nn.batch_norm(%178, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);
  %180 = %179.0;
  %181 = nn.leaky_relu(%180, alpha=0.2f);
  %182 = multiply(%181, 8f);
  %183 = round(%182);
  %184 = clip(%183, a_min=-127f, a_max=127f);
  %185 = cast(%184, dtype="int8");
  %186 = annotation.stop_fusion(%185);
  %187 = cast(%186, dtype="float32");
  %188 = divide(%187, 8f);
  %189 = (%188, %84);
  %190 = concatenate(%189, axis=1);
  %191 = multiply(%190, 8f);
  %192 = round(%191);
  %193 = clip(%192, a_min=-127f, a_max=127f);
  %194 = cast(%193, dtype="int8");
  %195 = annotation.stop_fusion(%194);
  %196 = cast(%195, dtype="float32");
  %197 = divide(%196, 8f);
  %198 = nn.conv2d(%197, %v_param_85, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]);
  %199 = nn.bias_add(%198, %v_param_86);
  %200 = nn.batch_norm(%199, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);
  %201 = %200.0;
  %202 = nn.leaky_relu(%201, alpha=0.2f);
  %203 = multiply(%202, 8f);
  %204 = round(%203);
  %205 = clip(%204, a_min=-127f, a_max=127f);
  %206 = cast(%205, dtype="int8");
  %207 = annotation.stop_fusion(%206);
  %208 = cast(%207, dtype="float32");
  %209 = divide(%208, 8f);
  %210 = nn.conv2d(%209, %v_param_91, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]);
  %211 = nn.bias_add(%210, %v_param_92);
  %212 = nn.batch_norm(%211, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);
  %213 = %212.0;
  %214 = nn.conv2d_transpose(%213, %v_param_97, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW");
  %215 = nn.bias_add(%214, %v_param_98);
  %216 = nn.batch_norm(%215, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);
  %217 = %216.0;
  %218 = nn.leaky_relu(%217, alpha=0.2f);
  %219 = multiply(%218, 8f);
  %220 = round(%219);
  %221 = clip(%220, a_min=-127f, a_max=127f);
  %222 = cast(%221, dtype="int8");
  %223 = annotation.stop_fusion(%222);
  %224 = cast(%223, dtype="float32");
  %225 = divide(%224, 8f);
  %226 = (%225, %53);
  %227 = concatenate(%226, axis=1);
  %228 = multiply(%227, 8f);
  %229 = round(%228);
  %230 = clip(%229, a_min=-127f, a_max=127f);
  %231 = cast(%230, dtype="int8");
  %232 = annotation.stop_fusion(%231);
  %233 = cast(%232, dtype="float32");
  %234 = divide(%233, 8f);
  %235 = nn.conv2d(%234, %v_param_103, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]);
  %236 = nn.bias_add(%235, %v_param_104);
  %237 = nn.batch_norm(%236, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);
  %238 = %237.0;
  %239 = nn.leaky_relu(%238, alpha=0.2f);
  %240 = multiply(%239, 8f);
  %241 = round(%240);
  %242 = clip(%241, a_min=-127f, a_max=127f);
  %243 = cast(%242, dtype="int8");
  %244 = annotation.stop_fusion(%243);
  %245 = cast(%244, dtype="float32");
  %246 = divide(%245, 8f);
  %247 = nn.conv2d(%246, %v_param_109, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]);
  %248 = nn.bias_add(%247, %v_param_110);
  %249 = nn.batch_norm(%248, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);
  %250 = %249.0;
  %251 = nn.conv2d_transpose(%250, %v_param_115, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout="IOHW");
  %252 = nn.bias_add(%251, %v_param_116);
  %253 = nn.batch_norm(%252, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);
  %254 = %253.0;
  %255 = nn.leaky_relu(%254, alpha=0.2f);
  %256 = multiply(%255, 8f);
  %257 = round(%256);
  %258 = clip(%257, a_min=-127f, a_max=127f);
  %259 = cast(%258, dtype="int8");
  %260 = annotation.stop_fusion(%259);
  %261 = cast(%260, dtype="float32");
  %262 = divide(%261, 8f);
  %263 = (%262, %22);
  %264 = concatenate(%263, axis=1);
  %265 = multiply(%264, 8f);
  %266 = round(%265);
  %267 = clip(%266, a_min=-127f, a_max=127f);
  %268 = cast(%267, dtype="int8");
  %269 = annotation.stop_fusion(%268);
  %270 = cast(%269, dtype="float32");
  %271 = divide(%270, 8f);
  %272 = nn.conv2d(%271, %v_param_121, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);
  %273 = nn.bias_add(%272, %v_param_122);
  %274 = nn.batch_norm(%273, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);
  %275 = %274.0;
  %276 = nn.leaky_relu(%275, alpha=0.2f);
  %277 = multiply(%276, 8f);
  %278 = round(%277);
  %279 = clip(%278, a_min=-127f, a_max=127f);
  %280 = cast(%279, dtype="int8");
  %281 = annotation.stop_fusion(%280);
  %282 = cast(%281, dtype="float32");
  %283 = divide(%282, 8f);
  %284 = nn.conv2d(%283, %v_param_127, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);
  %285 = nn.bias_add(%284, %v_param_128);
  %286 = nn.batch_norm(%285, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);
  %287 = %286.0;
  %288 = nn.conv2d(%287, %v_param_133, padding=[1i64, 1i64, 1i64, 1i64], channels=1, kernel_size=[3, 3]);
  %289 = nn.bias_add(%288, %v_param_134);
  %290 = sigmoid(%289);
  (%290, %280, %268, %259, %243, %231, %222, %206, %194, %185, %169, %157, %148, %132, %120, %112, %101, %89, %81, %70, %58, %50, %39, %27, %19, %8)
}
