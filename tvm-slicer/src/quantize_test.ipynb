{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 17:54:07.489463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tvm.relay import testing\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.testing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from tvm import relay\n",
    "from tvm.relay.build_module import bind_params_by_name\n",
    "from tvm.relay.dataflow_pattern import *\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pygraphviz as pgv\n",
    "PATH_MODEL = './model/'\n",
    "def show_graph(json_data, file_name=None):\n",
    "    if type(json_data) == str:\n",
    "        json_data = json.loads(json_data)\n",
    "    A = pgv.AGraph(directed=True)\n",
    "    for node_idx, node in enumerate(json_data['nodes']):\n",
    "        for src in node['inputs']:\n",
    "            A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]))\n",
    "            #A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(shape_size(json_data['attrs']['shape'][1][src[0]])) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]), node['name'] + '[{}]'.format(node_idx) + '{}'.format(shape_size(json_data['attrs']['shape'][1][node_idx])) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]))\n",
    "    if file_name:\n",
    "        A.draw(file_name + '.png', format='png', prog='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = tf.keras.models.load_model('../../tvm-slicer/src/model/{}_{}.h5'.format(\"unet\", 512))\n",
    "\n",
    "input_data = np.random.normal(0,1,(1,512,512,3)).astype(np.float32)\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "shape_dict = {\"input_1\": input_data.shape}\n",
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JunoCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        self.pool_size = is_constant()\n",
    "        self.strides = is_constant()\n",
    "        self.padding = is_constant()\n",
    "        self.padding = [1, 1, 1, 1]\n",
    "        self.pattern = is_tuple([self.var1, self.var2])\n",
    "        # self.pattern = is_op('nn.batch_norm')(wildcard(), wildcard(),wildcard(),wildcard(),wildcard())\n",
    "        self.cnt = 0\n",
    "        self.target = 1\n",
    "        self.target_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var1 = node_map[self.var1][0]\n",
    "        var2 = node_map[self.var2][0]\n",
    "        self.target_node.append(var2)\n",
    "        # return post\n",
    "        # return post\n",
    "        # original = post\n",
    "        if self.cnt != self.target:\n",
    "            self.cnt += 1\n",
    "            return post\n",
    "        else:\n",
    "            self.cnt += 1\n",
    "            cast_to_int8 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.round(\n",
    "                        relay.multiply(var2, relay.const(16.0))\n",
    "                    ), \n",
    "                    a_min=-127.0, a_max=127.0\n",
    "                ),\n",
    "                dtype=\"int8\"\n",
    "            )\n",
    "            cast_to_float32 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.right_shift(\n",
    "                        relay.add(relay.cast(relay.annotation.stop_fusion(cast_to_int8), dtype='int32'), relay.const(512)),\n",
    "                        relay.const(10)),\n",
    "                    a_min=-127.0, a_max=127.0), \n",
    "                dtype=\"float32\"\n",
    "            )\n",
    "            print(type(var1))\n",
    "            print(type(cast_to_float32))\n",
    "            print(type(post))\n",
    "            return relay.op.Tuple([var1, cast_to_float32])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 17:54:18.694850: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-03 17:54:18.697916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-03 17:54:18.813208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:18.816774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-05-03 17:54:18.816881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-03 17:54:18.877416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-03 17:54:18.877633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-03 17:54:18.913317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-03 17:54:18.927286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-03 17:54:18.981497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-03 17:54:18.997065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-03 17:54:18.997277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-03 17:54:18.997486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:18.999020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:19.001854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-03 17:54:19.002730: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-03 17:54:19.004217: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-03 17:54:19.004451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:19.005634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-05-03 17:54:19.005701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-03 17:54:19.005757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-03 17:54:19.005794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-03 17:54:19.005829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-03 17:54:19.005864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-03 17:54:19.005897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-03 17:54:19.005935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-03 17:54:19.005960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-03 17:54:19.006099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:19.007108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:19.007844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-03 17:54:20.941643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-03 17:54:20.941687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-03 17:54:20.941699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-03 17:54:20.944669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:20.945430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:20.946154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 17:54:20.946821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9541 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model_keras = tf.keras.models.load_model('../../tvm-slicer/src/model/{}_{}.h5'.format(\"resnet152\", 224))\n",
    "\n",
    "input_data = np.random.normal(0,1,(1,224,224,3)).astype(np.float32)\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "shape_dict = {\"input_1\": input_data.shape}\n",
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%input_1: Tensor[(1, 3, 224, 224), float32], %v_param_1: Tensor[(64, 3, 7, 7), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_19: Tensor[(256, 64, 1, 1), float32], %v_param_20: Tensor[(256), float32], %v_param_23: Tensor[(256), float32], %v_param_24: Tensor[(256), float32], %v_param_25: Tensor[(256), float32], %v_param_26: Tensor[(256), float32], %v_param_7: Tensor[(64, 64, 1, 1), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(64, 64, 3, 3), float32], %v_param_14: Tensor[(64), float32], %v_param_15: Tensor[(64), float32], %v_param_16: Tensor[(64), float32], %v_param_17: Tensor[(64), float32], %v_param_18: Tensor[(64), float32], %v_param_21: Tensor[(256, 64, 1, 1), float32], %v_param_22: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(64, 256, 1, 1), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(64, 64, 3, 3), float32], %v_param_38: Tensor[(64), float32], %v_param_39: Tensor[(64), float32], %v_param_40: Tensor[(64), float32], %v_param_41: Tensor[(64), float32], %v_param_42: Tensor[(64), float32], %v_param_43: Tensor[(256, 64, 1, 1), float32], %v_param_44: Tensor[(256), float32], %v_param_45: Tensor[(256), float32], %v_param_46: Tensor[(256), float32], %v_param_47: Tensor[(256), float32], %v_param_48: Tensor[(256), float32], %v_param_49: Tensor[(64, 256, 1, 1), float32], %v_param_50: Tensor[(64), float32], %v_param_51: Tensor[(64), float32], %v_param_52: Tensor[(64), float32], %v_param_53: Tensor[(64), float32], %v_param_54: Tensor[(64), float32], %v_param_55: Tensor[(64, 64, 3, 3), float32], %v_param_56: Tensor[(64), float32], %v_param_57: Tensor[(64), float32], %v_param_58: Tensor[(64), float32], %v_param_59: Tensor[(64), float32], %v_param_60: Tensor[(64), float32], %v_param_61: Tensor[(256, 64, 1, 1), float32], %v_param_62: Tensor[(256), float32], %v_param_63: Tensor[(256), float32], %v_param_64: Tensor[(256), float32], %v_param_65: Tensor[(256), float32], %v_param_66: Tensor[(256), float32], %v_param_79: Tensor[(512, 256, 1, 1), float32], %v_param_80: Tensor[(512), float32], %v_param_83: Tensor[(512), float32], %v_param_84: Tensor[(512), float32], %v_param_85: Tensor[(512), float32], %v_param_86: Tensor[(512), float32], %v_param_67: Tensor[(128, 256, 1, 1), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_81: Tensor[(512, 128, 1, 1), float32], %v_param_82: Tensor[(512), float32], %v_param_87: Tensor[(512), float32], %v_param_88: Tensor[(512), float32], %v_param_89: Tensor[(512), float32], %v_param_90: Tensor[(512), float32], %v_param_91: Tensor[(128, 512, 1, 1), float32], %v_param_92: Tensor[(128), float32], %v_param_93: Tensor[(128), float32], %v_param_94: Tensor[(128), float32], %v_param_95: Tensor[(128), float32], %v_param_96: Tensor[(128), float32], %v_param_97: Tensor[(128, 128, 3, 3), float32], %v_param_98: Tensor[(128), float32], %v_param_99: Tensor[(128), float32], %v_param_100: Tensor[(128), float32], %v_param_101: Tensor[(128), float32], %v_param_102: Tensor[(128), float32], %v_param_103: Tensor[(512, 128, 1, 1), float32], %v_param_104: Tensor[(512), float32], %v_param_105: Tensor[(512), float32], %v_param_106: Tensor[(512), float32], %v_param_107: Tensor[(512), float32], %v_param_108: Tensor[(512), float32], %v_param_109: Tensor[(128, 512, 1, 1), float32], %v_param_110: Tensor[(128), float32], %v_param_111: Tensor[(128), float32], %v_param_112: Tensor[(128), float32], %v_param_113: Tensor[(128), float32], %v_param_114: Tensor[(128), float32], %v_param_115: Tensor[(128, 128, 3, 3), float32], %v_param_116: Tensor[(128), float32], %v_param_117: Tensor[(128), float32], %v_param_118: Tensor[(128), float32], %v_param_119: Tensor[(128), float32], %v_param_120: Tensor[(128), float32], %v_param_121: Tensor[(512, 128, 1, 1), float32], %v_param_122: Tensor[(512), float32], %v_param_123: Tensor[(512), float32], %v_param_124: Tensor[(512), float32], %v_param_125: Tensor[(512), float32], %v_param_126: Tensor[(512), float32], %v_param_127: Tensor[(128, 512, 1, 1), float32], %v_param_128: Tensor[(128), float32], %v_param_129: Tensor[(128), float32], %v_param_130: Tensor[(128), float32], %v_param_131: Tensor[(128), float32], %v_param_132: Tensor[(128), float32], %v_param_133: Tensor[(128, 128, 3, 3), float32], %v_param_134: Tensor[(128), float32], %v_param_135: Tensor[(128), float32], %v_param_136: Tensor[(128), float32], %v_param_137: Tensor[(128), float32], %v_param_138: Tensor[(128), float32], %v_param_139: Tensor[(512, 128, 1, 1), float32], %v_param_140: Tensor[(512), float32], %v_param_141: Tensor[(512), float32], %v_param_142: Tensor[(512), float32], %v_param_143: Tensor[(512), float32], %v_param_144: Tensor[(512), float32], %v_param_145: Tensor[(128, 512, 1, 1), float32], %v_param_146: Tensor[(128), float32], %v_param_147: Tensor[(128), float32], %v_param_148: Tensor[(128), float32], %v_param_149: Tensor[(128), float32], %v_param_150: Tensor[(128), float32], %v_param_151: Tensor[(128, 128, 3, 3), float32], %v_param_152: Tensor[(128), float32], %v_param_153: Tensor[(128), float32], %v_param_154: Tensor[(128), float32], %v_param_155: Tensor[(128), float32], %v_param_156: Tensor[(128), float32], %v_param_157: Tensor[(512, 128, 1, 1), float32], %v_param_158: Tensor[(512), float32], %v_param_159: Tensor[(512), float32], %v_param_160: Tensor[(512), float32], %v_param_161: Tensor[(512), float32], %v_param_162: Tensor[(512), float32], %v_param_163: Tensor[(128, 512, 1, 1), float32], %v_param_164: Tensor[(128), float32], %v_param_165: Tensor[(128), float32], %v_param_166: Tensor[(128), float32], %v_param_167: Tensor[(128), float32], %v_param_168: Tensor[(128), float32], %v_param_169: Tensor[(128, 128, 3, 3), float32], %v_param_170: Tensor[(128), float32], %v_param_171: Tensor[(128), float32], %v_param_172: Tensor[(128), float32], %v_param_173: Tensor[(128), float32], %v_param_174: Tensor[(128), float32], %v_param_175: Tensor[(512, 128, 1, 1), float32], %v_param_176: Tensor[(512), float32], %v_param_177: Tensor[(512), float32], %v_param_178: Tensor[(512), float32], %v_param_179: Tensor[(512), float32], %v_param_180: Tensor[(512), float32], %v_param_181: Tensor[(128, 512, 1, 1), float32], %v_param_182: Tensor[(128), float32], %v_param_183: Tensor[(128), float32], %v_param_184: Tensor[(128), float32], %v_param_185: Tensor[(128), float32], %v_param_186: Tensor[(128), float32], %v_param_187: Tensor[(128, 128, 3, 3), float32], %v_param_188: Tensor[(128), float32], %v_param_189: Tensor[(128), float32], %v_param_190: Tensor[(128), float32], %v_param_191: Tensor[(128), float32], %v_param_192: Tensor[(128), float32], %v_param_193: Tensor[(512, 128, 1, 1), float32], %v_param_194: Tensor[(512), float32], %v_param_195: Tensor[(512), float32], %v_param_196: Tensor[(512), float32], %v_param_197: Tensor[(512), float32], %v_param_198: Tensor[(512), float32], %v_param_199: Tensor[(128, 512, 1, 1), float32], %v_param_200: Tensor[(128), float32], %v_param_201: Tensor[(128), float32], %v_param_202: Tensor[(128), float32], %v_param_203: Tensor[(128), float32], %v_param_204: Tensor[(128), float32], %v_param_205: Tensor[(128, 128, 3, 3), float32], %v_param_206: Tensor[(128), float32], %v_param_207: Tensor[(128), float32], %v_param_208: Tensor[(128), float32], %v_param_209: Tensor[(128), float32], %v_param_210: Tensor[(128), float32], %v_param_211: Tensor[(512, 128, 1, 1), float32], %v_param_212: Tensor[(512), float32], %v_param_213: Tensor[(512), float32], %v_param_214: Tensor[(512), float32], %v_param_215: Tensor[(512), float32], %v_param_216: Tensor[(512), float32], %v_param_229: Tensor[(1024, 512, 1, 1), float32], %v_param_230: Tensor[(1024), float32], %v_param_233: Tensor[(1024), float32], %v_param_234: Tensor[(1024), float32], %v_param_235: Tensor[(1024), float32], %v_param_236: Tensor[(1024), float32], %v_param_217: Tensor[(256, 512, 1, 1), float32], %v_param_218: Tensor[(256), float32], %v_param_219: Tensor[(256), float32], %v_param_220: Tensor[(256), float32], %v_param_221: Tensor[(256), float32], %v_param_222: Tensor[(256), float32], %v_param_223: Tensor[(256, 256, 3, 3), float32], %v_param_224: Tensor[(256), float32], %v_param_225: Tensor[(256), float32], %v_param_226: Tensor[(256), float32], %v_param_227: Tensor[(256), float32], %v_param_228: Tensor[(256), float32], %v_param_231: Tensor[(1024, 256, 1, 1), float32], %v_param_232: Tensor[(1024), float32], %v_param_237: Tensor[(1024), float32], %v_param_238: Tensor[(1024), float32], %v_param_239: Tensor[(1024), float32], %v_param_240: Tensor[(1024), float32], %v_param_241: Tensor[(256, 1024, 1, 1), float32], %v_param_242: Tensor[(256), float32], %v_param_243: Tensor[(256), float32], %v_param_244: Tensor[(256), float32], %v_param_245: Tensor[(256), float32], %v_param_246: Tensor[(256), float32], %v_param_247: Tensor[(256, 256, 3, 3), float32], %v_param_248: Tensor[(256), float32], %v_param_249: Tensor[(256), float32], %v_param_250: Tensor[(256), float32], %v_param_251: Tensor[(256), float32], %v_param_252: Tensor[(256), float32], %v_param_253: Tensor[(1024, 256, 1, 1), float32], %v_param_254: Tensor[(1024), float32], %v_param_255: Tensor[(1024), float32], %v_param_256: Tensor[(1024), float32], %v_param_257: Tensor[(1024), float32], %v_param_258: Tensor[(1024), float32], %v_param_259: Tensor[(256, 1024, 1, 1), float32], %v_param_260: Tensor[(256), float32], %v_param_261: Tensor[(256), float32], %v_param_262: Tensor[(256), float32], %v_param_263: Tensor[(256), float32], %v_param_264: Tensor[(256), float32], %v_param_265: Tensor[(256, 256, 3, 3), float32], %v_param_266: Tensor[(256), float32], %v_param_267: Tensor[(256), float32], %v_param_268: Tensor[(256), float32], %v_param_269: Tensor[(256), float32], %v_param_270: Tensor[(256), float32], %v_param_271: Tensor[(1024, 256, 1, 1), float32], %v_param_272: Tensor[(1024), float32], %v_param_273: Tensor[(1024), float32], %v_param_274: Tensor[(1024), float32], %v_param_275: Tensor[(1024), float32], %v_param_276: Tensor[(1024), float32], %v_param_277: Tensor[(256, 1024, 1, 1), float32], %v_param_278: Tensor[(256), float32], %v_param_279: Tensor[(256), float32], %v_param_280: Tensor[(256), float32], %v_param_281: Tensor[(256), float32], %v_param_282: Tensor[(256), float32], %v_param_283: Tensor[(256, 256, 3, 3), float32], %v_param_284: Tensor[(256), float32], %v_param_285: Tensor[(256), float32], %v_param_286: Tensor[(256), float32], %v_param_287: Tensor[(256), float32], %v_param_288: Tensor[(256), float32], %v_param_289: Tensor[(1024, 256, 1, 1), float32], %v_param_290: Tensor[(1024), float32], %v_param_291: Tensor[(1024), float32], %v_param_292: Tensor[(1024), float32], %v_param_293: Tensor[(1024), float32], %v_param_294: Tensor[(1024), float32], %v_param_295: Tensor[(256, 1024, 1, 1), float32], %v_param_296: Tensor[(256), float32], %v_param_297: Tensor[(256), float32], %v_param_298: Tensor[(256), float32], %v_param_299: Tensor[(256), float32], %v_param_300: Tensor[(256), float32], %v_param_301: Tensor[(256, 256, 3, 3), float32], %v_param_302: Tensor[(256), float32], %v_param_303: Tensor[(256), float32], %v_param_304: Tensor[(256), float32], %v_param_305: Tensor[(256), float32], %v_param_306: Tensor[(256), float32], %v_param_307: Tensor[(1024, 256, 1, 1), float32], %v_param_308: Tensor[(1024), float32], %v_param_309: Tensor[(1024), float32], %v_param_310: Tensor[(1024), float32], %v_param_311: Tensor[(1024), float32], %v_param_312: Tensor[(1024), float32], %v_param_313: Tensor[(256, 1024, 1, 1), float32], %v_param_314: Tensor[(256), float32], %v_param_315: Tensor[(256), float32], %v_param_316: Tensor[(256), float32], %v_param_317: Tensor[(256), float32], %v_param_318: Tensor[(256), float32], %v_param_319: Tensor[(256, 256, 3, 3), float32], %v_param_320: Tensor[(256), float32], %v_param_321: Tensor[(256), float32], %v_param_322: Tensor[(256), float32], %v_param_323: Tensor[(256), float32], %v_param_324: Tensor[(256), float32], %v_param_325: Tensor[(1024, 256, 1, 1), float32], %v_param_326: Tensor[(1024), float32], %v_param_327: Tensor[(1024), float32], %v_param_328: Tensor[(1024), float32], %v_param_329: Tensor[(1024), float32], %v_param_330: Tensor[(1024), float32], %v_param_331: Tensor[(256, 1024, 1, 1), float32], %v_param_332: Tensor[(256), float32], %v_param_333: Tensor[(256), float32], %v_param_334: Tensor[(256), float32], %v_param_335: Tensor[(256), float32], %v_param_336: Tensor[(256), float32], %v_param_337: Tensor[(256, 256, 3, 3), float32], %v_param_338: Tensor[(256), float32], %v_param_339: Tensor[(256), float32], %v_param_340: Tensor[(256), float32], %v_param_341: Tensor[(256), float32], %v_param_342: Tensor[(256), float32], %v_param_343: Tensor[(1024, 256, 1, 1), float32], %v_param_344: Tensor[(1024), float32], %v_param_345: Tensor[(1024), float32], %v_param_346: Tensor[(1024), float32], %v_param_347: Tensor[(1024), float32], %v_param_348: Tensor[(1024), float32], %v_param_349: Tensor[(256, 1024, 1, 1), float32], %v_param_350: Tensor[(256), float32], %v_param_351: Tensor[(256), float32], %v_param_352: Tensor[(256), float32], %v_param_353: Tensor[(256), float32], %v_param_354: Tensor[(256), float32], %v_param_355: Tensor[(256, 256, 3, 3), float32], %v_param_356: Tensor[(256), float32], %v_param_357: Tensor[(256), float32], %v_param_358: Tensor[(256), float32], %v_param_359: Tensor[(256), float32], %v_param_360: Tensor[(256), float32], %v_param_361: Tensor[(1024, 256, 1, 1), float32], %v_param_362: Tensor[(1024), float32], %v_param_363: Tensor[(1024), float32], %v_param_364: Tensor[(1024), float32], %v_param_365: Tensor[(1024), float32], %v_param_366: Tensor[(1024), float32], %v_param_367: Tensor[(256, 1024, 1, 1), float32], %v_param_368: Tensor[(256), float32], %v_param_369: Tensor[(256), float32], %v_param_370: Tensor[(256), float32], %v_param_371: Tensor[(256), float32], %v_param_372: Tensor[(256), float32], %v_param_373: Tensor[(256, 256, 3, 3), float32], %v_param_374: Tensor[(256), float32], %v_param_375: Tensor[(256), float32], %v_param_376: Tensor[(256), float32], %v_param_377: Tensor[(256), float32], %v_param_378: Tensor[(256), float32], %v_param_379: Tensor[(1024, 256, 1, 1), float32], %v_param_380: Tensor[(1024), float32], %v_param_381: Tensor[(1024), float32], %v_param_382: Tensor[(1024), float32], %v_param_383: Tensor[(1024), float32], %v_param_384: Tensor[(1024), float32], %v_param_385: Tensor[(256, 1024, 1, 1), float32], %v_param_386: Tensor[(256), float32], %v_param_387: Tensor[(256), float32], %v_param_388: Tensor[(256), float32], %v_param_389: Tensor[(256), float32], %v_param_390: Tensor[(256), float32], %v_param_391: Tensor[(256, 256, 3, 3), float32], %v_param_392: Tensor[(256), float32], %v_param_393: Tensor[(256), float32], %v_param_394: Tensor[(256), float32], %v_param_395: Tensor[(256), float32], %v_param_396: Tensor[(256), float32], %v_param_397: Tensor[(1024, 256, 1, 1), float32], %v_param_398: Tensor[(1024), float32], %v_param_399: Tensor[(1024), float32], %v_param_400: Tensor[(1024), float32], %v_param_401: Tensor[(1024), float32], %v_param_402: Tensor[(1024), float32], %v_param_403: Tensor[(256, 1024, 1, 1), float32], %v_param_404: Tensor[(256), float32], %v_param_405: Tensor[(256), float32], %v_param_406: Tensor[(256), float32], %v_param_407: Tensor[(256), float32], %v_param_408: Tensor[(256), float32], %v_param_409: Tensor[(256, 256, 3, 3), float32], %v_param_410: Tensor[(256), float32], %v_param_411: Tensor[(256), float32], %v_param_412: Tensor[(256), float32], %v_param_413: Tensor[(256), float32], %v_param_414: Tensor[(256), float32], %v_param_415: Tensor[(1024, 256, 1, 1), float32], %v_param_416: Tensor[(1024), float32], %v_param_417: Tensor[(1024), float32], %v_param_418: Tensor[(1024), float32], %v_param_419: Tensor[(1024), float32], %v_param_420: Tensor[(1024), float32], %v_param_421: Tensor[(256, 1024, 1, 1), float32], %v_param_422: Tensor[(256), float32], %v_param_423: Tensor[(256), float32], %v_param_424: Tensor[(256), float32], %v_param_425: Tensor[(256), float32], %v_param_426: Tensor[(256), float32], %v_param_427: Tensor[(256, 256, 3, 3), float32], %v_param_428: Tensor[(256), float32], %v_param_429: Tensor[(256), float32], %v_param_430: Tensor[(256), float32], %v_param_431: Tensor[(256), float32], %v_param_432: Tensor[(256), float32], %v_param_433: Tensor[(1024, 256, 1, 1), float32], %v_param_434: Tensor[(1024), float32], %v_param_435: Tensor[(1024), float32], %v_param_436: Tensor[(1024), float32], %v_param_437: Tensor[(1024), float32], %v_param_438: Tensor[(1024), float32], %v_param_439: Tensor[(256, 1024, 1, 1), float32], %v_param_440: Tensor[(256), float32], %v_param_441: Tensor[(256), float32], %v_param_442: Tensor[(256), float32], %v_param_443: Tensor[(256), float32], %v_param_444: Tensor[(256), float32], %v_param_445: Tensor[(256, 256, 3, 3), float32], %v_param_446: Tensor[(256), float32], %v_param_447: Tensor[(256), float32], %v_param_448: Tensor[(256), float32], %v_param_449: Tensor[(256), float32], %v_param_450: Tensor[(256), float32], %v_param_451: Tensor[(1024, 256, 1, 1), float32], %v_param_452: Tensor[(1024), float32], %v_param_453: Tensor[(1024), float32], %v_param_454: Tensor[(1024), float32], %v_param_455: Tensor[(1024), float32], %v_param_456: Tensor[(1024), float32], %v_param_457: Tensor[(256, 1024, 1, 1), float32], %v_param_458: Tensor[(256), float32], %v_param_459: Tensor[(256), float32], %v_param_460: Tensor[(256), float32], %v_param_461: Tensor[(256), float32], %v_param_462: Tensor[(256), float32], %v_param_463: Tensor[(256, 256, 3, 3), float32], %v_param_464: Tensor[(256), float32], %v_param_465: Tensor[(256), float32], %v_param_466: Tensor[(256), float32], %v_param_467: Tensor[(256), float32], %v_param_468: Tensor[(256), float32], %v_param_469: Tensor[(1024, 256, 1, 1), float32], %v_param_470: Tensor[(1024), float32], %v_param_471: Tensor[(1024), float32], %v_param_472: Tensor[(1024), float32], %v_param_473: Tensor[(1024), float32], %v_param_474: Tensor[(1024), float32], %v_param_475: Tensor[(256, 1024, 1, 1), float32], %v_param_476: Tensor[(256), float32], %v_param_477: Tensor[(256), float32], %v_param_478: Tensor[(256), float32], %v_param_479: Tensor[(256), float32], %v_param_480: Tensor[(256), float32], %v_param_481: Tensor[(256, 256, 3, 3), float32], %v_param_482: Tensor[(256), float32], %v_param_483: Tensor[(256), float32], %v_param_484: Tensor[(256), float32], %v_param_485: Tensor[(256), float32], %v_param_486: Tensor[(256), float32], %v_param_487: Tensor[(1024, 256, 1, 1), float32], %v_param_488: Tensor[(1024), float32], %v_param_489: Tensor[(1024), float32], %v_param_490: Tensor[(1024), float32], %v_param_491: Tensor[(1024), float32], %v_param_492: Tensor[(1024), float32], %v_param_493: Tensor[(256, 1024, 1, 1), float32], %v_param_494: Tensor[(256), float32], %v_param_495: Tensor[(256), float32], %v_param_496: Tensor[(256), float32], %v_param_497: Tensor[(256), float32], %v_param_498: Tensor[(256), float32], %v_param_499: Tensor[(256, 256, 3, 3), float32], %v_param_500: Tensor[(256), float32], %v_param_501: Tensor[(256), float32], %v_param_502: Tensor[(256), float32], %v_param_503: Tensor[(256), float32], %v_param_504: Tensor[(256), float32], %v_param_505: Tensor[(1024, 256, 1, 1), float32], %v_param_506: Tensor[(1024), float32], %v_param_507: Tensor[(1024), float32], %v_param_508: Tensor[(1024), float32], %v_param_509: Tensor[(1024), float32], %v_param_510: Tensor[(1024), float32], %v_param_511: Tensor[(256, 1024, 1, 1), float32], %v_param_512: Tensor[(256), float32], %v_param_513: Tensor[(256), float32], %v_param_514: Tensor[(256), float32], %v_param_515: Tensor[(256), float32], %v_param_516: Tensor[(256), float32], %v_param_517: Tensor[(256, 256, 3, 3), float32], %v_param_518: Tensor[(256), float32], %v_param_519: Tensor[(256), float32], %v_param_520: Tensor[(256), float32], %v_param_521: Tensor[(256), float32], %v_param_522: Tensor[(256), float32], %v_param_523: Tensor[(1024, 256, 1, 1), float32], %v_param_524: Tensor[(1024), float32], %v_param_525: Tensor[(1024), float32], %v_param_526: Tensor[(1024), float32], %v_param_527: Tensor[(1024), float32], %v_param_528: Tensor[(1024), float32], %v_param_529: Tensor[(256, 1024, 1, 1), float32], %v_param_530: Tensor[(256), float32], %v_param_531: Tensor[(256), float32], %v_param_532: Tensor[(256), float32], %v_param_533: Tensor[(256), float32], %v_param_534: Tensor[(256), float32], %v_param_535: Tensor[(256, 256, 3, 3), float32], %v_param_536: Tensor[(256), float32], %v_param_537: Tensor[(256), float32], %v_param_538: Tensor[(256), float32], %v_param_539: Tensor[(256), float32], %v_param_540: Tensor[(256), float32], %v_param_541: Tensor[(1024, 256, 1, 1), float32], %v_param_542: Tensor[(1024), float32], %v_param_543: Tensor[(1024), float32], %v_param_544: Tensor[(1024), float32], %v_param_545: Tensor[(1024), float32], %v_param_546: Tensor[(1024), float32], %v_param_547: Tensor[(256, 1024, 1, 1), float32], %v_param_548: Tensor[(256), float32], %v_param_549: Tensor[(256), float32], %v_param_550: Tensor[(256), float32], %v_param_551: Tensor[(256), float32], %v_param_552: Tensor[(256), float32], %v_param_553: Tensor[(256, 256, 3, 3), float32], %v_param_554: Tensor[(256), float32], %v_param_555: Tensor[(256), float32], %v_param_556: Tensor[(256), float32], %v_param_557: Tensor[(256), float32], %v_param_558: Tensor[(256), float32], %v_param_559: Tensor[(1024, 256, 1, 1), float32], %v_param_560: Tensor[(1024), float32], %v_param_561: Tensor[(1024), float32], %v_param_562: Tensor[(1024), float32], %v_param_563: Tensor[(1024), float32], %v_param_564: Tensor[(1024), float32], %v_param_565: Tensor[(256, 1024, 1, 1), float32], %v_param_566: Tensor[(256), float32], %v_param_567: Tensor[(256), float32], %v_param_568: Tensor[(256), float32], %v_param_569: Tensor[(256), float32], %v_param_570: Tensor[(256), float32], %v_param_571: Tensor[(256, 256, 3, 3), float32], %v_param_572: Tensor[(256), float32], %v_param_573: Tensor[(256), float32], %v_param_574: Tensor[(256), float32], %v_param_575: Tensor[(256), float32], %v_param_576: Tensor[(256), float32], %v_param_577: Tensor[(1024, 256, 1, 1), float32], %v_param_578: Tensor[(1024), float32], %v_param_579: Tensor[(1024), float32], %v_param_580: Tensor[(1024), float32], %v_param_581: Tensor[(1024), float32], %v_param_582: Tensor[(1024), float32], %v_param_583: Tensor[(256, 1024, 1, 1), float32], %v_param_584: Tensor[(256), float32], %v_param_585: Tensor[(256), float32], %v_param_586: Tensor[(256), float32], %v_param_587: Tensor[(256), float32], %v_param_588: Tensor[(256), float32], %v_param_589: Tensor[(256, 256, 3, 3), float32], %v_param_590: Tensor[(256), float32], %v_param_591: Tensor[(256), float32], %v_param_592: Tensor[(256), float32], %v_param_593: Tensor[(256), float32], %v_param_594: Tensor[(256), float32], %v_param_595: Tensor[(1024, 256, 1, 1), float32], %v_param_596: Tensor[(1024), float32], %v_param_597: Tensor[(1024), float32], %v_param_598: Tensor[(1024), float32], %v_param_599: Tensor[(1024), float32], %v_param_600: Tensor[(1024), float32], %v_param_601: Tensor[(256, 1024, 1, 1), float32], %v_param_602: Tensor[(256), float32], %v_param_603: Tensor[(256), float32], %v_param_604: Tensor[(256), float32], %v_param_605: Tensor[(256), float32], %v_param_606: Tensor[(256), float32], %v_param_607: Tensor[(256, 256, 3, 3), float32], %v_param_608: Tensor[(256), float32], %v_param_609: Tensor[(256), float32], %v_param_610: Tensor[(256), float32], %v_param_611: Tensor[(256), float32], %v_param_612: Tensor[(256), float32], %v_param_613: Tensor[(1024, 256, 1, 1), float32], %v_param_614: Tensor[(1024), float32], %v_param_615: Tensor[(1024), float32], %v_param_616: Tensor[(1024), float32], %v_param_617: Tensor[(1024), float32], %v_param_618: Tensor[(1024), float32], %v_param_619: Tensor[(256, 1024, 1, 1), float32], %v_param_620: Tensor[(256), float32], %v_param_621: Tensor[(256), float32], %v_param_622: Tensor[(256), float32], %v_param_623: Tensor[(256), float32], %v_param_624: Tensor[(256), float32], %v_param_625: Tensor[(256, 256, 3, 3), float32], %v_param_626: Tensor[(256), float32], %v_param_627: Tensor[(256), float32], %v_param_628: Tensor[(256), float32], %v_param_629: Tensor[(256), float32], %v_param_630: Tensor[(256), float32], %v_param_631: Tensor[(1024, 256, 1, 1), float32], %v_param_632: Tensor[(1024), float32], %v_param_633: Tensor[(1024), float32], %v_param_634: Tensor[(1024), float32], %v_param_635: Tensor[(1024), float32], %v_param_636: Tensor[(1024), float32], %v_param_637: Tensor[(256, 1024, 1, 1), float32], %v_param_638: Tensor[(256), float32], %v_param_639: Tensor[(256), float32], %v_param_640: Tensor[(256), float32], %v_param_641: Tensor[(256), float32], %v_param_642: Tensor[(256), float32], %v_param_643: Tensor[(256, 256, 3, 3), float32], %v_param_644: Tensor[(256), float32], %v_param_645: Tensor[(256), float32], %v_param_646: Tensor[(256), float32], %v_param_647: Tensor[(256), float32], %v_param_648: Tensor[(256), float32], %v_param_649: Tensor[(1024, 256, 1, 1), float32], %v_param_650: Tensor[(1024), float32], %v_param_651: Tensor[(1024), float32], %v_param_652: Tensor[(1024), float32], %v_param_653: Tensor[(1024), float32], %v_param_654: Tensor[(1024), float32], %v_param_655: Tensor[(256, 1024, 1, 1), float32], %v_param_656: Tensor[(256), float32], %v_param_657: Tensor[(256), float32], %v_param_658: Tensor[(256), float32], %v_param_659: Tensor[(256), float32], %v_param_660: Tensor[(256), float32], %v_param_661: Tensor[(256, 256, 3, 3), float32], %v_param_662: Tensor[(256), float32], %v_param_663: Tensor[(256), float32], %v_param_664: Tensor[(256), float32], %v_param_665: Tensor[(256), float32], %v_param_666: Tensor[(256), float32], %v_param_667: Tensor[(1024, 256, 1, 1), float32], %v_param_668: Tensor[(1024), float32], %v_param_669: Tensor[(1024), float32], %v_param_670: Tensor[(1024), float32], %v_param_671: Tensor[(1024), float32], %v_param_672: Tensor[(1024), float32], %v_param_673: Tensor[(256, 1024, 1, 1), float32], %v_param_674: Tensor[(256), float32], %v_param_675: Tensor[(256), float32], %v_param_676: Tensor[(256), float32], %v_param_677: Tensor[(256), float32], %v_param_678: Tensor[(256), float32], %v_param_679: Tensor[(256, 256, 3, 3), float32], %v_param_680: Tensor[(256), float32], %v_param_681: Tensor[(256), float32], %v_param_682: Tensor[(256), float32], %v_param_683: Tensor[(256), float32], %v_param_684: Tensor[(256), float32], %v_param_685: Tensor[(1024, 256, 1, 1), float32], %v_param_686: Tensor[(1024), float32], %v_param_687: Tensor[(1024), float32], %v_param_688: Tensor[(1024), float32], %v_param_689: Tensor[(1024), float32], %v_param_690: Tensor[(1024), float32], %v_param_691: Tensor[(256, 1024, 1, 1), float32], %v_param_692: Tensor[(256), float32], %v_param_693: Tensor[(256), float32], %v_param_694: Tensor[(256), float32], %v_param_695: Tensor[(256), float32], %v_param_696: Tensor[(256), float32], %v_param_697: Tensor[(256, 256, 3, 3), float32], %v_param_698: Tensor[(256), float32], %v_param_699: Tensor[(256), float32], %v_param_700: Tensor[(256), float32], %v_param_701: Tensor[(256), float32], %v_param_702: Tensor[(256), float32], %v_param_703: Tensor[(1024, 256, 1, 1), float32], %v_param_704: Tensor[(1024), float32], %v_param_705: Tensor[(1024), float32], %v_param_706: Tensor[(1024), float32], %v_param_707: Tensor[(1024), float32], %v_param_708: Tensor[(1024), float32], %v_param_709: Tensor[(256, 1024, 1, 1), float32], %v_param_710: Tensor[(256), float32], %v_param_711: Tensor[(256), float32], %v_param_712: Tensor[(256), float32], %v_param_713: Tensor[(256), float32], %v_param_714: Tensor[(256), float32], %v_param_715: Tensor[(256, 256, 3, 3), float32], %v_param_716: Tensor[(256), float32], %v_param_717: Tensor[(256), float32], %v_param_718: Tensor[(256), float32], %v_param_719: Tensor[(256), float32], %v_param_720: Tensor[(256), float32], %v_param_721: Tensor[(1024, 256, 1, 1), float32], %v_param_722: Tensor[(1024), float32], %v_param_723: Tensor[(1024), float32], %v_param_724: Tensor[(1024), float32], %v_param_725: Tensor[(1024), float32], %v_param_726: Tensor[(1024), float32], %v_param_727: Tensor[(256, 1024, 1, 1), float32], %v_param_728: Tensor[(256), float32], %v_param_729: Tensor[(256), float32], %v_param_730: Tensor[(256), float32], %v_param_731: Tensor[(256), float32], %v_param_732: Tensor[(256), float32], %v_param_733: Tensor[(256, 256, 3, 3), float32], %v_param_734: Tensor[(256), float32], %v_param_735: Tensor[(256), float32], %v_param_736: Tensor[(256), float32], %v_param_737: Tensor[(256), float32], %v_param_738: Tensor[(256), float32], %v_param_739: Tensor[(1024, 256, 1, 1), float32], %v_param_740: Tensor[(1024), float32], %v_param_741: Tensor[(1024), float32], %v_param_742: Tensor[(1024), float32], %v_param_743: Tensor[(1024), float32], %v_param_744: Tensor[(1024), float32], %v_param_745: Tensor[(256, 1024, 1, 1), float32], %v_param_746: Tensor[(256), float32], %v_param_747: Tensor[(256), float32], %v_param_748: Tensor[(256), float32], %v_param_749: Tensor[(256), float32], %v_param_750: Tensor[(256), float32], %v_param_751: Tensor[(256, 256, 3, 3), float32], %v_param_752: Tensor[(256), float32], %v_param_753: Tensor[(256), float32], %v_param_754: Tensor[(256), float32], %v_param_755: Tensor[(256), float32], %v_param_756: Tensor[(256), float32], %v_param_757: Tensor[(1024, 256, 1, 1), float32], %v_param_758: Tensor[(1024), float32], %v_param_759: Tensor[(1024), float32], %v_param_760: Tensor[(1024), float32], %v_param_761: Tensor[(1024), float32], %v_param_762: Tensor[(1024), float32], %v_param_763: Tensor[(256, 1024, 1, 1), float32], %v_param_764: Tensor[(256), float32], %v_param_765: Tensor[(256), float32], %v_param_766: Tensor[(256), float32], %v_param_767: Tensor[(256), float32], %v_param_768: Tensor[(256), float32], %v_param_769: Tensor[(256, 256, 3, 3), float32], %v_param_770: Tensor[(256), float32], %v_param_771: Tensor[(256), float32], %v_param_772: Tensor[(256), float32], %v_param_773: Tensor[(256), float32], %v_param_774: Tensor[(256), float32], %v_param_775: Tensor[(1024, 256, 1, 1), float32], %v_param_776: Tensor[(1024), float32], %v_param_777: Tensor[(1024), float32], %v_param_778: Tensor[(1024), float32], %v_param_779: Tensor[(1024), float32], %v_param_780: Tensor[(1024), float32], %v_param_781: Tensor[(256, 1024, 1, 1), float32], %v_param_782: Tensor[(256), float32], %v_param_783: Tensor[(256), float32], %v_param_784: Tensor[(256), float32], %v_param_785: Tensor[(256), float32], %v_param_786: Tensor[(256), float32], %v_param_787: Tensor[(256, 256, 3, 3), float32], %v_param_788: Tensor[(256), float32], %v_param_789: Tensor[(256), float32], %v_param_790: Tensor[(256), float32], %v_param_791: Tensor[(256), float32], %v_param_792: Tensor[(256), float32], %v_param_793: Tensor[(1024, 256, 1, 1), float32], %v_param_794: Tensor[(1024), float32], %v_param_795: Tensor[(1024), float32], %v_param_796: Tensor[(1024), float32], %v_param_797: Tensor[(1024), float32], %v_param_798: Tensor[(1024), float32], %v_param_799: Tensor[(256, 1024, 1, 1), float32], %v_param_800: Tensor[(256), float32], %v_param_801: Tensor[(256), float32], %v_param_802: Tensor[(256), float32], %v_param_803: Tensor[(256), float32], %v_param_804: Tensor[(256), float32], %v_param_805: Tensor[(256, 256, 3, 3), float32], %v_param_806: Tensor[(256), float32], %v_param_807: Tensor[(256), float32], %v_param_808: Tensor[(256), float32], %v_param_809: Tensor[(256), float32], %v_param_810: Tensor[(256), float32], %v_param_811: Tensor[(1024, 256, 1, 1), float32], %v_param_812: Tensor[(1024), float32], %v_param_813: Tensor[(1024), float32], %v_param_814: Tensor[(1024), float32], %v_param_815: Tensor[(1024), float32], %v_param_816: Tensor[(1024), float32], %v_param_817: Tensor[(256, 1024, 1, 1), float32], %v_param_818: Tensor[(256), float32], %v_param_819: Tensor[(256), float32], %v_param_820: Tensor[(256), float32], %v_param_821: Tensor[(256), float32], %v_param_822: Tensor[(256), float32], %v_param_823: Tensor[(256, 256, 3, 3), float32], %v_param_824: Tensor[(256), float32], %v_param_825: Tensor[(256), float32], %v_param_826: Tensor[(256), float32], %v_param_827: Tensor[(256), float32], %v_param_828: Tensor[(256), float32], %v_param_829: Tensor[(1024, 256, 1, 1), float32], %v_param_830: Tensor[(1024), float32], %v_param_831: Tensor[(1024), float32], %v_param_832: Tensor[(1024), float32], %v_param_833: Tensor[(1024), float32], %v_param_834: Tensor[(1024), float32], %v_param_835: Tensor[(256, 1024, 1, 1), float32], %v_param_836: Tensor[(256), float32], %v_param_837: Tensor[(256), float32], %v_param_838: Tensor[(256), float32], %v_param_839: Tensor[(256), float32], %v_param_840: Tensor[(256), float32], %v_param_841: Tensor[(256, 256, 3, 3), float32], %v_param_842: Tensor[(256), float32], %v_param_843: Tensor[(256), float32], %v_param_844: Tensor[(256), float32], %v_param_845: Tensor[(256), float32], %v_param_846: Tensor[(256), float32], %v_param_847: Tensor[(1024, 256, 1, 1), float32], %v_param_848: Tensor[(1024), float32], %v_param_849: Tensor[(1024), float32], %v_param_850: Tensor[(1024), float32], %v_param_851: Tensor[(1024), float32], %v_param_852: Tensor[(1024), float32], %v_param_853: Tensor[(256, 1024, 1, 1), float32], %v_param_854: Tensor[(256), float32], %v_param_855: Tensor[(256), float32], %v_param_856: Tensor[(256), float32], %v_param_857: Tensor[(256), float32], %v_param_858: Tensor[(256), float32], %v_param_859: Tensor[(256, 256, 3, 3), float32], %v_param_860: Tensor[(256), float32], %v_param_861: Tensor[(256), float32], %v_param_862: Tensor[(256), float32], %v_param_863: Tensor[(256), float32], %v_param_864: Tensor[(256), float32], %v_param_865: Tensor[(1024, 256, 1, 1), float32], %v_param_866: Tensor[(1024), float32], %v_param_867: Tensor[(1024), float32], %v_param_868: Tensor[(1024), float32], %v_param_869: Tensor[(1024), float32], %v_param_870: Tensor[(1024), float32], %v_param_883: Tensor[(2048, 1024, 1, 1), float32], %v_param_884: Tensor[(2048), float32], %v_param_887: Tensor[(2048), float32], %v_param_888: Tensor[(2048), float32], %v_param_889: Tensor[(2048), float32], %v_param_890: Tensor[(2048), float32], %v_param_871: Tensor[(512, 1024, 1, 1), float32], %v_param_872: Tensor[(512), float32], %v_param_873: Tensor[(512), float32], %v_param_874: Tensor[(512), float32], %v_param_875: Tensor[(512), float32], %v_param_876: Tensor[(512), float32], %v_param_877: Tensor[(512, 512, 3, 3), float32], %v_param_878: Tensor[(512), float32], %v_param_879: Tensor[(512), float32], %v_param_880: Tensor[(512), float32], %v_param_881: Tensor[(512), float32], %v_param_882: Tensor[(512), float32], %v_param_885: Tensor[(2048, 512, 1, 1), float32], %v_param_886: Tensor[(2048), float32], %v_param_891: Tensor[(2048), float32], %v_param_892: Tensor[(2048), float32], %v_param_893: Tensor[(2048), float32], %v_param_894: Tensor[(2048), float32], %v_param_895: Tensor[(512, 2048, 1, 1), float32], %v_param_896: Tensor[(512), float32], %v_param_897: Tensor[(512), float32], %v_param_898: Tensor[(512), float32], %v_param_899: Tensor[(512), float32], %v_param_900: Tensor[(512), float32], %v_param_901: Tensor[(512, 512, 3, 3), float32], %v_param_902: Tensor[(512), float32], %v_param_903: Tensor[(512), float32], %v_param_904: Tensor[(512), float32], %v_param_905: Tensor[(512), float32], %v_param_906: Tensor[(512), float32], %v_param_907: Tensor[(2048, 512, 1, 1), float32], %v_param_908: Tensor[(2048), float32], %v_param_909: Tensor[(2048), float32], %v_param_910: Tensor[(2048), float32], %v_param_911: Tensor[(2048), float32], %v_param_912: Tensor[(2048), float32], %v_param_913: Tensor[(512, 2048, 1, 1), float32], %v_param_914: Tensor[(512), float32], %v_param_915: Tensor[(512), float32], %v_param_916: Tensor[(512), float32], %v_param_917: Tensor[(512), float32], %v_param_918: Tensor[(512), float32], %v_param_919: Tensor[(512, 512, 3, 3), float32], %v_param_920: Tensor[(512), float32], %v_param_921: Tensor[(512), float32], %v_param_922: Tensor[(512), float32], %v_param_923: Tensor[(512), float32], %v_param_924: Tensor[(512), float32], %v_param_925: Tensor[(2048, 512, 1, 1), float32], %v_param_926: Tensor[(2048), float32], %v_param_927: Tensor[(2048), float32], %v_param_928: Tensor[(2048), float32], %v_param_929: Tensor[(2048), float32], %v_param_930: Tensor[(2048), float32], %v_param_931: Tensor[(1000, 2048), float32], %v_param_932: Tensor[(1000), float32]) {\n",
       "  %0 = nn.pad(%input_1, 0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);\n",
       "  %1 = nn.conv2d(%0, %v_param_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7]);\n",
       "  %2 = nn.bias_add(%1, %v_param_2);\n",
       "  %3 = nn.batch_norm(%2, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=1.001e-05f);\n",
       "  %4 = %3.0;\n",
       "  %5 = nn.relu(%4);\n",
       "  %6 = nn.pad(%5, 0, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);\n",
       "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %8 = nn.conv2d(%7, %v_param_19, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %9 = nn.bias_add(%8, %v_param_20);\n",
       "  %10 = nn.batch_norm(%9, %v_param_23, %v_param_24, %v_param_25, %v_param_26, epsilon=1.001e-05f);\n",
       "  %11 = nn.conv2d(%7, %v_param_7, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %12 = nn.bias_add(%11, %v_param_8);\n",
       "  %13 = nn.batch_norm(%12, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=1.001e-05f);\n",
       "  %14 = %13.0;\n",
       "  %15 = nn.relu(%14);\n",
       "  %16 = nn.conv2d(%15, %v_param_13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %17 = nn.bias_add(%16, %v_param_14);\n",
       "  %18 = nn.batch_norm(%17, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=1.001e-05f);\n",
       "  %19 = %18.0;\n",
       "  %20 = nn.relu(%19);\n",
       "  %21 = nn.conv2d(%20, %v_param_21, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %22 = nn.bias_add(%21, %v_param_22);\n",
       "  %23 = nn.batch_norm(%22, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=1.001e-05f);\n",
       "  %24 = %10.0;\n",
       "  %25 = %23.0;\n",
       "  %26 = add(%24, %25);\n",
       "  %27 = nn.relu(%26);\n",
       "  %28 = nn.conv2d(%27, %v_param_31, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %29 = nn.bias_add(%28, %v_param_32);\n",
       "  %30 = nn.batch_norm(%29, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=1.001e-05f);\n",
       "  %31 = %30.0;\n",
       "  %32 = nn.relu(%31);\n",
       "  %33 = nn.conv2d(%32, %v_param_37, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %34 = nn.bias_add(%33, %v_param_38);\n",
       "  %35 = nn.batch_norm(%34, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=1.001e-05f);\n",
       "  %36 = %35.0;\n",
       "  %37 = nn.relu(%36);\n",
       "  %38 = nn.conv2d(%37, %v_param_43, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %39 = nn.bias_add(%38, %v_param_44);\n",
       "  %40 = nn.batch_norm(%39, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=1.001e-05f);\n",
       "  %41 = %40.0;\n",
       "  %42 = add(%27, %41);\n",
       "  %43 = nn.relu(%42);\n",
       "  %44 = nn.conv2d(%43, %v_param_49, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %45 = nn.bias_add(%44, %v_param_50);\n",
       "  %46 = nn.batch_norm(%45, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=1.001e-05f);\n",
       "  %47 = %46.0;\n",
       "  %48 = nn.relu(%47);\n",
       "  %49 = nn.conv2d(%48, %v_param_55, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %50 = nn.bias_add(%49, %v_param_56);\n",
       "  %51 = nn.batch_norm(%50, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=1.001e-05f);\n",
       "  %52 = %51.0;\n",
       "  %53 = nn.relu(%52);\n",
       "  %54 = nn.conv2d(%53, %v_param_61, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %55 = nn.bias_add(%54, %v_param_62);\n",
       "  %56 = nn.batch_norm(%55, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=1.001e-05f);\n",
       "  %57 = %56.0;\n",
       "  %58 = add(%43, %57);\n",
       "  %59 = nn.relu(%58);\n",
       "  %60 = nn.conv2d(%59, %v_param_79, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %61 = nn.bias_add(%60, %v_param_80);\n",
       "  %62 = nn.batch_norm(%61, %v_param_83, %v_param_84, %v_param_85, %v_param_86, epsilon=1.001e-05f);\n",
       "  %63 = nn.conv2d(%59, %v_param_67, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %64 = nn.bias_add(%63, %v_param_68);\n",
       "  %65 = nn.batch_norm(%64, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=1.001e-05f);\n",
       "  %66 = %65.0;\n",
       "  %67 = nn.relu(%66);\n",
       "  %68 = nn.conv2d(%67, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %69 = nn.bias_add(%68, %v_param_74);\n",
       "  %70 = nn.batch_norm(%69, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=1.001e-05f);\n",
       "  %71 = %70.0;\n",
       "  %72 = nn.relu(%71);\n",
       "  %73 = nn.conv2d(%72, %v_param_81, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %74 = nn.bias_add(%73, %v_param_82);\n",
       "  %75 = nn.batch_norm(%74, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=1.001e-05f);\n",
       "  %76 = %62.0;\n",
       "  %77 = %75.0;\n",
       "  %78 = add(%76, %77);\n",
       "  %79 = nn.relu(%78);\n",
       "  %80 = nn.conv2d(%79, %v_param_91, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %81 = nn.bias_add(%80, %v_param_92);\n",
       "  %82 = nn.batch_norm(%81, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=1.001e-05f);\n",
       "  %83 = %82.0;\n",
       "  %84 = nn.relu(%83);\n",
       "  %85 = nn.conv2d(%84, %v_param_97, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %86 = nn.bias_add(%85, %v_param_98);\n",
       "  %87 = nn.batch_norm(%86, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=1.001e-05f);\n",
       "  %88 = %87.0;\n",
       "  %89 = nn.relu(%88);\n",
       "  %90 = nn.conv2d(%89, %v_param_103, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %91 = nn.bias_add(%90, %v_param_104);\n",
       "  %92 = nn.batch_norm(%91, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=1.001e-05f);\n",
       "  %93 = %92.0;\n",
       "  %94 = add(%79, %93);\n",
       "  %95 = nn.relu(%94);\n",
       "  %96 = nn.conv2d(%95, %v_param_109, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %97 = nn.bias_add(%96, %v_param_110);\n",
       "  %98 = nn.batch_norm(%97, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=1.001e-05f);\n",
       "  %99 = %98.0;\n",
       "  %100 = nn.relu(%99);\n",
       "  %101 = nn.conv2d(%100, %v_param_115, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %102 = nn.bias_add(%101, %v_param_116);\n",
       "  %103 = nn.batch_norm(%102, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=1.001e-05f);\n",
       "  %104 = %103.0;\n",
       "  %105 = nn.relu(%104);\n",
       "  %106 = nn.conv2d(%105, %v_param_121, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %107 = nn.bias_add(%106, %v_param_122);\n",
       "  %108 = nn.batch_norm(%107, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=1.001e-05f);\n",
       "  %109 = %108.0;\n",
       "  %110 = add(%95, %109);\n",
       "  %111 = nn.relu(%110);\n",
       "  %112 = nn.conv2d(%111, %v_param_127, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %113 = nn.bias_add(%112, %v_param_128);\n",
       "  %114 = nn.batch_norm(%113, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=1.001e-05f);\n",
       "  %115 = %114.0;\n",
       "  %116 = nn.relu(%115);\n",
       "  %117 = nn.conv2d(%116, %v_param_133, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %118 = nn.bias_add(%117, %v_param_134);\n",
       "  %119 = nn.batch_norm(%118, %v_param_135, %v_param_136, %v_param_137, %v_param_138, epsilon=1.001e-05f);\n",
       "  %120 = %119.0;\n",
       "  %121 = nn.relu(%120);\n",
       "  %122 = nn.conv2d(%121, %v_param_139, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %123 = nn.bias_add(%122, %v_param_140);\n",
       "  %124 = nn.batch_norm(%123, %v_param_141, %v_param_142, %v_param_143, %v_param_144, epsilon=1.001e-05f);\n",
       "  %125 = %124.0;\n",
       "  %126 = add(%111, %125);\n",
       "  %127 = nn.relu(%126);\n",
       "  %128 = nn.conv2d(%127, %v_param_145, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %129 = nn.bias_add(%128, %v_param_146);\n",
       "  %130 = nn.batch_norm(%129, %v_param_147, %v_param_148, %v_param_149, %v_param_150, epsilon=1.001e-05f);\n",
       "  %131 = %130.0;\n",
       "  %132 = nn.relu(%131);\n",
       "  %133 = nn.conv2d(%132, %v_param_151, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %134 = nn.bias_add(%133, %v_param_152);\n",
       "  %135 = nn.batch_norm(%134, %v_param_153, %v_param_154, %v_param_155, %v_param_156, epsilon=1.001e-05f);\n",
       "  %136 = %135.0;\n",
       "  %137 = nn.relu(%136);\n",
       "  %138 = nn.conv2d(%137, %v_param_157, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %139 = nn.bias_add(%138, %v_param_158);\n",
       "  %140 = nn.batch_norm(%139, %v_param_159, %v_param_160, %v_param_161, %v_param_162, epsilon=1.001e-05f);\n",
       "  %141 = %140.0;\n",
       "  %142 = add(%127, %141);\n",
       "  %143 = nn.relu(%142);\n",
       "  %144 = nn.conv2d(%143, %v_param_163, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %145 = nn.bias_add(%144, %v_param_164);\n",
       "  %146 = nn.batch_norm(%145, %v_param_165, %v_param_166, %v_param_167, %v_param_168, epsilon=1.001e-05f);\n",
       "  %147 = %146.0;\n",
       "  %148 = nn.relu(%147);\n",
       "  %149 = nn.conv2d(%148, %v_param_169, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %150 = nn.bias_add(%149, %v_param_170);\n",
       "  %151 = nn.batch_norm(%150, %v_param_171, %v_param_172, %v_param_173, %v_param_174, epsilon=1.001e-05f);\n",
       "  %152 = %151.0;\n",
       "  %153 = nn.relu(%152);\n",
       "  %154 = nn.conv2d(%153, %v_param_175, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %155 = nn.bias_add(%154, %v_param_176);\n",
       "  %156 = nn.batch_norm(%155, %v_param_177, %v_param_178, %v_param_179, %v_param_180, epsilon=1.001e-05f);\n",
       "  %157 = %156.0;\n",
       "  %158 = add(%143, %157);\n",
       "  %159 = nn.relu(%158);\n",
       "  %160 = nn.conv2d(%159, %v_param_181, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %161 = nn.bias_add(%160, %v_param_182);\n",
       "  %162 = nn.batch_norm(%161, %v_param_183, %v_param_184, %v_param_185, %v_param_186, epsilon=1.001e-05f);\n",
       "  %163 = %162.0;\n",
       "  %164 = nn.relu(%163);\n",
       "  %165 = nn.conv2d(%164, %v_param_187, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %166 = nn.bias_add(%165, %v_param_188);\n",
       "  %167 = nn.batch_norm(%166, %v_param_189, %v_param_190, %v_param_191, %v_param_192, epsilon=1.001e-05f);\n",
       "  %168 = %167.0;\n",
       "  %169 = nn.relu(%168);\n",
       "  %170 = nn.conv2d(%169, %v_param_193, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %171 = nn.bias_add(%170, %v_param_194);\n",
       "  %172 = nn.batch_norm(%171, %v_param_195, %v_param_196, %v_param_197, %v_param_198, epsilon=1.001e-05f);\n",
       "  %173 = %172.0;\n",
       "  %174 = add(%159, %173);\n",
       "  %175 = nn.relu(%174);\n",
       "  %176 = nn.conv2d(%175, %v_param_199, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %177 = nn.bias_add(%176, %v_param_200);\n",
       "  %178 = nn.batch_norm(%177, %v_param_201, %v_param_202, %v_param_203, %v_param_204, epsilon=1.001e-05f);\n",
       "  %179 = %178.0;\n",
       "  %180 = nn.relu(%179);\n",
       "  %181 = nn.conv2d(%180, %v_param_205, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %182 = nn.bias_add(%181, %v_param_206);\n",
       "  %183 = nn.batch_norm(%182, %v_param_207, %v_param_208, %v_param_209, %v_param_210, epsilon=1.001e-05f);\n",
       "  %184 = %183.0;\n",
       "  %185 = nn.relu(%184);\n",
       "  %186 = nn.conv2d(%185, %v_param_211, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %187 = nn.bias_add(%186, %v_param_212);\n",
       "  %188 = nn.batch_norm(%187, %v_param_213, %v_param_214, %v_param_215, %v_param_216, epsilon=1.001e-05f);\n",
       "  %189 = %188.0;\n",
       "  %190 = add(%175, %189);\n",
       "  %191 = nn.relu(%190);\n",
       "  %192 = nn.conv2d(%191, %v_param_229, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %193 = nn.bias_add(%192, %v_param_230);\n",
       "  %194 = nn.batch_norm(%193, %v_param_233, %v_param_234, %v_param_235, %v_param_236, epsilon=1.001e-05f);\n",
       "  %195 = nn.conv2d(%191, %v_param_217, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %196 = nn.bias_add(%195, %v_param_218);\n",
       "  %197 = nn.batch_norm(%196, %v_param_219, %v_param_220, %v_param_221, %v_param_222, epsilon=1.001e-05f);\n",
       "  %198 = %197.0;\n",
       "  %199 = nn.relu(%198);\n",
       "  %200 = nn.conv2d(%199, %v_param_223, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %201 = nn.bias_add(%200, %v_param_224);\n",
       "  %202 = nn.batch_norm(%201, %v_param_225, %v_param_226, %v_param_227, %v_param_228, epsilon=1.001e-05f);\n",
       "  %203 = %202.0;\n",
       "  %204 = nn.relu(%203);\n",
       "  %205 = nn.conv2d(%204, %v_param_231, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %206 = nn.bias_add(%205, %v_param_232);\n",
       "  %207 = nn.batch_norm(%206, %v_param_237, %v_param_238, %v_param_239, %v_param_240, epsilon=1.001e-05f);\n",
       "  %208 = %194.0;\n",
       "  %209 = %207.0;\n",
       "  %210 = add(%208, %209);\n",
       "  %211 = nn.relu(%210);\n",
       "  %212 = nn.conv2d(%211, %v_param_241, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %213 = nn.bias_add(%212, %v_param_242);\n",
       "  %214 = nn.batch_norm(%213, %v_param_243, %v_param_244, %v_param_245, %v_param_246, epsilon=1.001e-05f);\n",
       "  %215 = %214.0;\n",
       "  %216 = nn.relu(%215);\n",
       "  %217 = nn.conv2d(%216, %v_param_247, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %218 = nn.bias_add(%217, %v_param_248);\n",
       "  %219 = nn.batch_norm(%218, %v_param_249, %v_param_250, %v_param_251, %v_param_252, epsilon=1.001e-05f);\n",
       "  %220 = %219.0;\n",
       "  %221 = nn.relu(%220);\n",
       "  %222 = nn.conv2d(%221, %v_param_253, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %223 = nn.bias_add(%222, %v_param_254);\n",
       "  %224 = nn.batch_norm(%223, %v_param_255, %v_param_256, %v_param_257, %v_param_258, epsilon=1.001e-05f);\n",
       "  %225 = %224.0;\n",
       "  %226 = add(%211, %225);\n",
       "  %227 = nn.relu(%226);\n",
       "  %228 = nn.conv2d(%227, %v_param_259, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %229 = nn.bias_add(%228, %v_param_260);\n",
       "  %230 = nn.batch_norm(%229, %v_param_261, %v_param_262, %v_param_263, %v_param_264, epsilon=1.001e-05f);\n",
       "  %231 = %230.0;\n",
       "  %232 = nn.relu(%231);\n",
       "  %233 = nn.conv2d(%232, %v_param_265, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %234 = nn.bias_add(%233, %v_param_266);\n",
       "  %235 = nn.batch_norm(%234, %v_param_267, %v_param_268, %v_param_269, %v_param_270, epsilon=1.001e-05f);\n",
       "  %236 = %235.0;\n",
       "  %237 = nn.relu(%236);\n",
       "  %238 = nn.conv2d(%237, %v_param_271, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %239 = nn.bias_add(%238, %v_param_272);\n",
       "  %240 = nn.batch_norm(%239, %v_param_273, %v_param_274, %v_param_275, %v_param_276, epsilon=1.001e-05f);\n",
       "  %241 = %240.0;\n",
       "  %242 = add(%227, %241);\n",
       "  %243 = nn.relu(%242);\n",
       "  %244 = nn.conv2d(%243, %v_param_277, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %245 = nn.bias_add(%244, %v_param_278);\n",
       "  %246 = nn.batch_norm(%245, %v_param_279, %v_param_280, %v_param_281, %v_param_282, epsilon=1.001e-05f);\n",
       "  %247 = %246.0;\n",
       "  %248 = nn.relu(%247);\n",
       "  %249 = nn.conv2d(%248, %v_param_283, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %250 = nn.bias_add(%249, %v_param_284);\n",
       "  %251 = nn.batch_norm(%250, %v_param_285, %v_param_286, %v_param_287, %v_param_288, epsilon=1.001e-05f);\n",
       "  %252 = %251.0;\n",
       "  %253 = nn.relu(%252);\n",
       "  %254 = nn.conv2d(%253, %v_param_289, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %255 = nn.bias_add(%254, %v_param_290);\n",
       "  %256 = nn.batch_norm(%255, %v_param_291, %v_param_292, %v_param_293, %v_param_294, epsilon=1.001e-05f);\n",
       "  %257 = %256.0;\n",
       "  %258 = add(%243, %257);\n",
       "  %259 = nn.relu(%258);\n",
       "  %260 = nn.conv2d(%259, %v_param_295, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %261 = nn.bias_add(%260, %v_param_296);\n",
       "  %262 = nn.batch_norm(%261, %v_param_297, %v_param_298, %v_param_299, %v_param_300, epsilon=1.001e-05f);\n",
       "  %263 = %262.0;\n",
       "  %264 = nn.relu(%263);\n",
       "  %265 = nn.conv2d(%264, %v_param_301, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %266 = nn.bias_add(%265, %v_param_302);\n",
       "  %267 = nn.batch_norm(%266, %v_param_303, %v_param_304, %v_param_305, %v_param_306, epsilon=1.001e-05f);\n",
       "  %268 = %267.0;\n",
       "  %269 = nn.relu(%268);\n",
       "  %270 = nn.conv2d(%269, %v_param_307, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %271 = nn.bias_add(%270, %v_param_308);\n",
       "  %272 = nn.batch_norm(%271, %v_param_309, %v_param_310, %v_param_311, %v_param_312, epsilon=1.001e-05f);\n",
       "  %273 = %272.0;\n",
       "  %274 = add(%259, %273);\n",
       "  %275 = nn.relu(%274);\n",
       "  %276 = nn.conv2d(%275, %v_param_313, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %277 = nn.bias_add(%276, %v_param_314);\n",
       "  %278 = nn.batch_norm(%277, %v_param_315, %v_param_316, %v_param_317, %v_param_318, epsilon=1.001e-05f);\n",
       "  %279 = %278.0;\n",
       "  %280 = nn.relu(%279);\n",
       "  %281 = nn.conv2d(%280, %v_param_319, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %282 = nn.bias_add(%281, %v_param_320);\n",
       "  %283 = nn.batch_norm(%282, %v_param_321, %v_param_322, %v_param_323, %v_param_324, epsilon=1.001e-05f);\n",
       "  %284 = %283.0;\n",
       "  %285 = nn.relu(%284);\n",
       "  %286 = nn.conv2d(%285, %v_param_325, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %287 = nn.bias_add(%286, %v_param_326);\n",
       "  %288 = nn.batch_norm(%287, %v_param_327, %v_param_328, %v_param_329, %v_param_330, epsilon=1.001e-05f);\n",
       "  %289 = %288.0;\n",
       "  %290 = add(%275, %289);\n",
       "  %291 = nn.relu(%290);\n",
       "  %292 = nn.conv2d(%291, %v_param_331, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %293 = nn.bias_add(%292, %v_param_332);\n",
       "  %294 = nn.batch_norm(%293, %v_param_333, %v_param_334, %v_param_335, %v_param_336, epsilon=1.001e-05f);\n",
       "  %295 = %294.0;\n",
       "  %296 = nn.relu(%295);\n",
       "  %297 = nn.conv2d(%296, %v_param_337, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %298 = nn.bias_add(%297, %v_param_338);\n",
       "  %299 = nn.batch_norm(%298, %v_param_339, %v_param_340, %v_param_341, %v_param_342, epsilon=1.001e-05f);\n",
       "  %300 = %299.0;\n",
       "  %301 = nn.relu(%300);\n",
       "  %302 = nn.conv2d(%301, %v_param_343, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %303 = nn.bias_add(%302, %v_param_344);\n",
       "  %304 = nn.batch_norm(%303, %v_param_345, %v_param_346, %v_param_347, %v_param_348, epsilon=1.001e-05f);\n",
       "  %305 = %304.0;\n",
       "  %306 = add(%291, %305);\n",
       "  %307 = nn.relu(%306);\n",
       "  %308 = nn.conv2d(%307, %v_param_349, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %309 = nn.bias_add(%308, %v_param_350);\n",
       "  %310 = nn.batch_norm(%309, %v_param_351, %v_param_352, %v_param_353, %v_param_354, epsilon=1.001e-05f);\n",
       "  %311 = %310.0;\n",
       "  %312 = nn.relu(%311);\n",
       "  %313 = nn.conv2d(%312, %v_param_355, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %314 = nn.bias_add(%313, %v_param_356);\n",
       "  %315 = nn.batch_norm(%314, %v_param_357, %v_param_358, %v_param_359, %v_param_360, epsilon=1.001e-05f);\n",
       "  %316 = %315.0;\n",
       "  %317 = nn.relu(%316);\n",
       "  %318 = nn.conv2d(%317, %v_param_361, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %319 = nn.bias_add(%318, %v_param_362);\n",
       "  %320 = nn.batch_norm(%319, %v_param_363, %v_param_364, %v_param_365, %v_param_366, epsilon=1.001e-05f);\n",
       "  %321 = %320.0;\n",
       "  %322 = add(%307, %321);\n",
       "  %323 = nn.relu(%322);\n",
       "  %324 = nn.conv2d(%323, %v_param_367, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %325 = nn.bias_add(%324, %v_param_368);\n",
       "  %326 = nn.batch_norm(%325, %v_param_369, %v_param_370, %v_param_371, %v_param_372, epsilon=1.001e-05f);\n",
       "  %327 = %326.0;\n",
       "  %328 = nn.relu(%327);\n",
       "  %329 = nn.conv2d(%328, %v_param_373, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %330 = nn.bias_add(%329, %v_param_374);\n",
       "  %331 = nn.batch_norm(%330, %v_param_375, %v_param_376, %v_param_377, %v_param_378, epsilon=1.001e-05f);\n",
       "  %332 = %331.0;\n",
       "  %333 = nn.relu(%332);\n",
       "  %334 = nn.conv2d(%333, %v_param_379, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %335 = nn.bias_add(%334, %v_param_380);\n",
       "  %336 = nn.batch_norm(%335, %v_param_381, %v_param_382, %v_param_383, %v_param_384, epsilon=1.001e-05f);\n",
       "  %337 = %336.0;\n",
       "  %338 = add(%323, %337);\n",
       "  %339 = nn.relu(%338);\n",
       "  %340 = nn.conv2d(%339, %v_param_385, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %341 = nn.bias_add(%340, %v_param_386);\n",
       "  %342 = nn.batch_norm(%341, %v_param_387, %v_param_388, %v_param_389, %v_param_390, epsilon=1.001e-05f);\n",
       "  %343 = %342.0;\n",
       "  %344 = nn.relu(%343);\n",
       "  %345 = nn.conv2d(%344, %v_param_391, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %346 = nn.bias_add(%345, %v_param_392);\n",
       "  %347 = nn.batch_norm(%346, %v_param_393, %v_param_394, %v_param_395, %v_param_396, epsilon=1.001e-05f);\n",
       "  %348 = %347.0;\n",
       "  %349 = nn.relu(%348);\n",
       "  %350 = nn.conv2d(%349, %v_param_397, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %351 = nn.bias_add(%350, %v_param_398);\n",
       "  %352 = nn.batch_norm(%351, %v_param_399, %v_param_400, %v_param_401, %v_param_402, epsilon=1.001e-05f);\n",
       "  %353 = %352.0;\n",
       "  %354 = add(%339, %353);\n",
       "  %355 = nn.relu(%354);\n",
       "  %356 = nn.conv2d(%355, %v_param_403, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %357 = nn.bias_add(%356, %v_param_404);\n",
       "  %358 = nn.batch_norm(%357, %v_param_405, %v_param_406, %v_param_407, %v_param_408, epsilon=1.001e-05f);\n",
       "  %359 = %358.0;\n",
       "  %360 = nn.relu(%359);\n",
       "  %361 = nn.conv2d(%360, %v_param_409, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %362 = nn.bias_add(%361, %v_param_410);\n",
       "  %363 = nn.batch_norm(%362, %v_param_411, %v_param_412, %v_param_413, %v_param_414, epsilon=1.001e-05f);\n",
       "  %364 = %363.0;\n",
       "  %365 = nn.relu(%364);\n",
       "  %366 = nn.conv2d(%365, %v_param_415, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %367 = nn.bias_add(%366, %v_param_416);\n",
       "  %368 = nn.batch_norm(%367, %v_param_417, %v_param_418, %v_param_419, %v_param_420, epsilon=1.001e-05f);\n",
       "  %369 = %368.0;\n",
       "  %370 = add(%355, %369);\n",
       "  %371 = nn.relu(%370);\n",
       "  %372 = nn.conv2d(%371, %v_param_421, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %373 = nn.bias_add(%372, %v_param_422);\n",
       "  %374 = nn.batch_norm(%373, %v_param_423, %v_param_424, %v_param_425, %v_param_426, epsilon=1.001e-05f);\n",
       "  %375 = %374.0;\n",
       "  %376 = nn.relu(%375);\n",
       "  %377 = nn.conv2d(%376, %v_param_427, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %378 = nn.bias_add(%377, %v_param_428);\n",
       "  %379 = nn.batch_norm(%378, %v_param_429, %v_param_430, %v_param_431, %v_param_432, epsilon=1.001e-05f);\n",
       "  %380 = %379.0;\n",
       "  %381 = nn.relu(%380);\n",
       "  %382 = nn.conv2d(%381, %v_param_433, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %383 = nn.bias_add(%382, %v_param_434);\n",
       "  %384 = nn.batch_norm(%383, %v_param_435, %v_param_436, %v_param_437, %v_param_438, epsilon=1.001e-05f);\n",
       "  %385 = %384.0;\n",
       "  %386 = add(%371, %385);\n",
       "  %387 = nn.relu(%386);\n",
       "  %388 = nn.conv2d(%387, %v_param_439, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %389 = nn.bias_add(%388, %v_param_440);\n",
       "  %390 = nn.batch_norm(%389, %v_param_441, %v_param_442, %v_param_443, %v_param_444, epsilon=1.001e-05f);\n",
       "  %391 = %390.0;\n",
       "  %392 = nn.relu(%391);\n",
       "  %393 = nn.conv2d(%392, %v_param_445, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %394 = nn.bias_add(%393, %v_param_446);\n",
       "  %395 = nn.batch_norm(%394, %v_param_447, %v_param_448, %v_param_449, %v_param_450, epsilon=1.001e-05f);\n",
       "  %396 = %395.0;\n",
       "  %397 = nn.relu(%396);\n",
       "  %398 = nn.conv2d(%397, %v_param_451, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %399 = nn.bias_add(%398, %v_param_452);\n",
       "  %400 = nn.batch_norm(%399, %v_param_453, %v_param_454, %v_param_455, %v_param_456, epsilon=1.001e-05f);\n",
       "  %401 = %400.0;\n",
       "  %402 = add(%387, %401);\n",
       "  %403 = nn.relu(%402);\n",
       "  %404 = nn.conv2d(%403, %v_param_457, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %405 = nn.bias_add(%404, %v_param_458);\n",
       "  %406 = nn.batch_norm(%405, %v_param_459, %v_param_460, %v_param_461, %v_param_462, epsilon=1.001e-05f);\n",
       "  %407 = %406.0;\n",
       "  %408 = nn.relu(%407);\n",
       "  %409 = nn.conv2d(%408, %v_param_463, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %410 = nn.bias_add(%409, %v_param_464);\n",
       "  %411 = nn.batch_norm(%410, %v_param_465, %v_param_466, %v_param_467, %v_param_468, epsilon=1.001e-05f);\n",
       "  %412 = %411.0;\n",
       "  %413 = nn.relu(%412);\n",
       "  %414 = nn.conv2d(%413, %v_param_469, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %415 = nn.bias_add(%414, %v_param_470);\n",
       "  %416 = nn.batch_norm(%415, %v_param_471, %v_param_472, %v_param_473, %v_param_474, epsilon=1.001e-05f);\n",
       "  %417 = %416.0;\n",
       "  %418 = add(%403, %417);\n",
       "  %419 = nn.relu(%418);\n",
       "  %420 = nn.conv2d(%419, %v_param_475, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %421 = nn.bias_add(%420, %v_param_476);\n",
       "  %422 = nn.batch_norm(%421, %v_param_477, %v_param_478, %v_param_479, %v_param_480, epsilon=1.001e-05f);\n",
       "  %423 = %422.0;\n",
       "  %424 = nn.relu(%423);\n",
       "  %425 = nn.conv2d(%424, %v_param_481, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %426 = nn.bias_add(%425, %v_param_482);\n",
       "  %427 = nn.batch_norm(%426, %v_param_483, %v_param_484, %v_param_485, %v_param_486, epsilon=1.001e-05f);\n",
       "  %428 = %427.0;\n",
       "  %429 = nn.relu(%428);\n",
       "  %430 = nn.conv2d(%429, %v_param_487, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %431 = nn.bias_add(%430, %v_param_488);\n",
       "  %432 = nn.batch_norm(%431, %v_param_489, %v_param_490, %v_param_491, %v_param_492, epsilon=1.001e-05f);\n",
       "  %433 = %432.0;\n",
       "  %434 = add(%419, %433);\n",
       "  %435 = nn.relu(%434);\n",
       "  %436 = nn.conv2d(%435, %v_param_493, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %437 = nn.bias_add(%436, %v_param_494);\n",
       "  %438 = nn.batch_norm(%437, %v_param_495, %v_param_496, %v_param_497, %v_param_498, epsilon=1.001e-05f);\n",
       "  %439 = %438.0;\n",
       "  %440 = nn.relu(%439);\n",
       "  %441 = nn.conv2d(%440, %v_param_499, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %442 = nn.bias_add(%441, %v_param_500);\n",
       "  %443 = nn.batch_norm(%442, %v_param_501, %v_param_502, %v_param_503, %v_param_504, epsilon=1.001e-05f);\n",
       "  %444 = %443.0;\n",
       "  %445 = nn.relu(%444);\n",
       "  %446 = nn.conv2d(%445, %v_param_505, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %447 = nn.bias_add(%446, %v_param_506);\n",
       "  %448 = nn.batch_norm(%447, %v_param_507, %v_param_508, %v_param_509, %v_param_510, epsilon=1.001e-05f);\n",
       "  %449 = %448.0;\n",
       "  %450 = add(%435, %449);\n",
       "  %451 = nn.relu(%450);\n",
       "  %452 = nn.conv2d(%451, %v_param_511, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %453 = nn.bias_add(%452, %v_param_512);\n",
       "  %454 = nn.batch_norm(%453, %v_param_513, %v_param_514, %v_param_515, %v_param_516, epsilon=1.001e-05f);\n",
       "  %455 = %454.0;\n",
       "  %456 = nn.relu(%455);\n",
       "  %457 = nn.conv2d(%456, %v_param_517, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %458 = nn.bias_add(%457, %v_param_518);\n",
       "  %459 = nn.batch_norm(%458, %v_param_519, %v_param_520, %v_param_521, %v_param_522, epsilon=1.001e-05f);\n",
       "  %460 = %459.0;\n",
       "  %461 = nn.relu(%460);\n",
       "  %462 = nn.conv2d(%461, %v_param_523, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %463 = nn.bias_add(%462, %v_param_524);\n",
       "  %464 = nn.batch_norm(%463, %v_param_525, %v_param_526, %v_param_527, %v_param_528, epsilon=1.001e-05f);\n",
       "  %465 = %464.0;\n",
       "  %466 = add(%451, %465);\n",
       "  %467 = nn.relu(%466);\n",
       "  %468 = nn.conv2d(%467, %v_param_529, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %469 = nn.bias_add(%468, %v_param_530);\n",
       "  %470 = nn.batch_norm(%469, %v_param_531, %v_param_532, %v_param_533, %v_param_534, epsilon=1.001e-05f);\n",
       "  %471 = %470.0;\n",
       "  %472 = nn.relu(%471);\n",
       "  %473 = nn.conv2d(%472, %v_param_535, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %474 = nn.bias_add(%473, %v_param_536);\n",
       "  %475 = nn.batch_norm(%474, %v_param_537, %v_param_538, %v_param_539, %v_param_540, epsilon=1.001e-05f);\n",
       "  %476 = %475.0;\n",
       "  %477 = nn.relu(%476);\n",
       "  %478 = nn.conv2d(%477, %v_param_541, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %479 = nn.bias_add(%478, %v_param_542);\n",
       "  %480 = nn.batch_norm(%479, %v_param_543, %v_param_544, %v_param_545, %v_param_546, epsilon=1.001e-05f);\n",
       "  %481 = %480.0;\n",
       "  %482 = add(%467, %481);\n",
       "  %483 = nn.relu(%482);\n",
       "  %484 = nn.conv2d(%483, %v_param_547, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %485 = nn.bias_add(%484, %v_param_548);\n",
       "  %486 = nn.batch_norm(%485, %v_param_549, %v_param_550, %v_param_551, %v_param_552, epsilon=1.001e-05f);\n",
       "  %487 = %486.0;\n",
       "  %488 = nn.relu(%487);\n",
       "  %489 = nn.conv2d(%488, %v_param_553, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %490 = nn.bias_add(%489, %v_param_554);\n",
       "  %491 = nn.batch_norm(%490, %v_param_555, %v_param_556, %v_param_557, %v_param_558, epsilon=1.001e-05f);\n",
       "  %492 = %491.0;\n",
       "  %493 = nn.relu(%492);\n",
       "  %494 = nn.conv2d(%493, %v_param_559, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %495 = nn.bias_add(%494, %v_param_560);\n",
       "  %496 = nn.batch_norm(%495, %v_param_561, %v_param_562, %v_param_563, %v_param_564, epsilon=1.001e-05f);\n",
       "  %497 = %496.0;\n",
       "  %498 = add(%483, %497);\n",
       "  %499 = nn.relu(%498);\n",
       "  %500 = nn.conv2d(%499, %v_param_565, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %501 = nn.bias_add(%500, %v_param_566);\n",
       "  %502 = nn.batch_norm(%501, %v_param_567, %v_param_568, %v_param_569, %v_param_570, epsilon=1.001e-05f);\n",
       "  %503 = %502.0;\n",
       "  %504 = nn.relu(%503);\n",
       "  %505 = nn.conv2d(%504, %v_param_571, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %506 = nn.bias_add(%505, %v_param_572);\n",
       "  %507 = nn.batch_norm(%506, %v_param_573, %v_param_574, %v_param_575, %v_param_576, epsilon=1.001e-05f);\n",
       "  %508 = %507.0;\n",
       "  %509 = nn.relu(%508);\n",
       "  %510 = nn.conv2d(%509, %v_param_577, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %511 = nn.bias_add(%510, %v_param_578);\n",
       "  %512 = nn.batch_norm(%511, %v_param_579, %v_param_580, %v_param_581, %v_param_582, epsilon=1.001e-05f);\n",
       "  %513 = %512.0;\n",
       "  %514 = add(%499, %513);\n",
       "  %515 = nn.relu(%514);\n",
       "  %516 = nn.conv2d(%515, %v_param_583, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %517 = nn.bias_add(%516, %v_param_584);\n",
       "  %518 = nn.batch_norm(%517, %v_param_585, %v_param_586, %v_param_587, %v_param_588, epsilon=1.001e-05f);\n",
       "  %519 = %518.0;\n",
       "  %520 = nn.relu(%519);\n",
       "  %521 = nn.conv2d(%520, %v_param_589, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %522 = nn.bias_add(%521, %v_param_590);\n",
       "  %523 = nn.batch_norm(%522, %v_param_591, %v_param_592, %v_param_593, %v_param_594, epsilon=1.001e-05f);\n",
       "  %524 = %523.0;\n",
       "  %525 = nn.relu(%524);\n",
       "  %526 = nn.conv2d(%525, %v_param_595, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %527 = nn.bias_add(%526, %v_param_596);\n",
       "  %528 = nn.batch_norm(%527, %v_param_597, %v_param_598, %v_param_599, %v_param_600, epsilon=1.001e-05f);\n",
       "  %529 = %528.0;\n",
       "  %530 = add(%515, %529);\n",
       "  %531 = nn.relu(%530);\n",
       "  %532 = nn.conv2d(%531, %v_param_601, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %533 = nn.bias_add(%532, %v_param_602);\n",
       "  %534 = nn.batch_norm(%533, %v_param_603, %v_param_604, %v_param_605, %v_param_606, epsilon=1.001e-05f);\n",
       "  %535 = %534.0;\n",
       "  %536 = nn.relu(%535);\n",
       "  %537 = nn.conv2d(%536, %v_param_607, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %538 = nn.bias_add(%537, %v_param_608);\n",
       "  %539 = nn.batch_norm(%538, %v_param_609, %v_param_610, %v_param_611, %v_param_612, epsilon=1.001e-05f);\n",
       "  %540 = %539.0;\n",
       "  %541 = nn.relu(%540);\n",
       "  %542 = nn.conv2d(%541, %v_param_613, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %543 = nn.bias_add(%542, %v_param_614);\n",
       "  %544 = nn.batch_norm(%543, %v_param_615, %v_param_616, %v_param_617, %v_param_618, epsilon=1.001e-05f);\n",
       "  %545 = %544.0;\n",
       "  %546 = add(%531, %545);\n",
       "  %547 = nn.relu(%546);\n",
       "  %548 = nn.conv2d(%547, %v_param_619, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %549 = nn.bias_add(%548, %v_param_620);\n",
       "  %550 = nn.batch_norm(%549, %v_param_621, %v_param_622, %v_param_623, %v_param_624, epsilon=1.001e-05f);\n",
       "  %551 = %550.0;\n",
       "  %552 = nn.relu(%551);\n",
       "  %553 = nn.conv2d(%552, %v_param_625, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %554 = nn.bias_add(%553, %v_param_626);\n",
       "  %555 = nn.batch_norm(%554, %v_param_627, %v_param_628, %v_param_629, %v_param_630, epsilon=1.001e-05f);\n",
       "  %556 = %555.0;\n",
       "  %557 = nn.relu(%556);\n",
       "  %558 = nn.conv2d(%557, %v_param_631, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %559 = nn.bias_add(%558, %v_param_632);\n",
       "  %560 = nn.batch_norm(%559, %v_param_633, %v_param_634, %v_param_635, %v_param_636, epsilon=1.001e-05f);\n",
       "  %561 = %560.0;\n",
       "  %562 = add(%547, %561);\n",
       "  %563 = nn.relu(%562);\n",
       "  %564 = nn.conv2d(%563, %v_param_637, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %565 = nn.bias_add(%564, %v_param_638);\n",
       "  %566 = nn.batch_norm(%565, %v_param_639, %v_param_640, %v_param_641, %v_param_642, epsilon=1.001e-05f);\n",
       "  %567 = %566.0;\n",
       "  %568 = nn.relu(%567);\n",
       "  %569 = nn.conv2d(%568, %v_param_643, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %570 = nn.bias_add(%569, %v_param_644);\n",
       "  %571 = nn.batch_norm(%570, %v_param_645, %v_param_646, %v_param_647, %v_param_648, epsilon=1.001e-05f);\n",
       "  %572 = %571.0;\n",
       "  %573 = nn.relu(%572);\n",
       "  %574 = nn.conv2d(%573, %v_param_649, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %575 = nn.bias_add(%574, %v_param_650);\n",
       "  %576 = nn.batch_norm(%575, %v_param_651, %v_param_652, %v_param_653, %v_param_654, epsilon=1.001e-05f);\n",
       "  %577 = %576.0;\n",
       "  %578 = add(%563, %577);\n",
       "  %579 = nn.relu(%578);\n",
       "  %580 = nn.conv2d(%579, %v_param_655, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %581 = nn.bias_add(%580, %v_param_656);\n",
       "  %582 = nn.batch_norm(%581, %v_param_657, %v_param_658, %v_param_659, %v_param_660, epsilon=1.001e-05f);\n",
       "  %583 = %582.0;\n",
       "  %584 = nn.relu(%583);\n",
       "  %585 = nn.conv2d(%584, %v_param_661, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %586 = nn.bias_add(%585, %v_param_662);\n",
       "  %587 = nn.batch_norm(%586, %v_param_663, %v_param_664, %v_param_665, %v_param_666, epsilon=1.001e-05f);\n",
       "  %588 = %587.0;\n",
       "  %589 = nn.relu(%588);\n",
       "  %590 = nn.conv2d(%589, %v_param_667, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %591 = nn.bias_add(%590, %v_param_668);\n",
       "  %592 = nn.batch_norm(%591, %v_param_669, %v_param_670, %v_param_671, %v_param_672, epsilon=1.001e-05f);\n",
       "  %593 = %592.0;\n",
       "  %594 = add(%579, %593);\n",
       "  %595 = nn.relu(%594);\n",
       "  %596 = nn.conv2d(%595, %v_param_673, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %597 = nn.bias_add(%596, %v_param_674);\n",
       "  %598 = nn.batch_norm(%597, %v_param_675, %v_param_676, %v_param_677, %v_param_678, epsilon=1.001e-05f);\n",
       "  %599 = %598.0;\n",
       "  %600 = nn.relu(%599);\n",
       "  %601 = nn.conv2d(%600, %v_param_679, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %602 = nn.bias_add(%601, %v_param_680);\n",
       "  %603 = nn.batch_norm(%602, %v_param_681, %v_param_682, %v_param_683, %v_param_684, epsilon=1.001e-05f);\n",
       "  %604 = %603.0;\n",
       "  %605 = nn.relu(%604);\n",
       "  %606 = nn.conv2d(%605, %v_param_685, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %607 = nn.bias_add(%606, %v_param_686);\n",
       "  %608 = nn.batch_norm(%607, %v_param_687, %v_param_688, %v_param_689, %v_param_690, epsilon=1.001e-05f);\n",
       "  %609 = %608.0;\n",
       "  %610 = add(%595, %609);\n",
       "  %611 = nn.relu(%610);\n",
       "  %612 = nn.conv2d(%611, %v_param_691, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %613 = nn.bias_add(%612, %v_param_692);\n",
       "  %614 = nn.batch_norm(%613, %v_param_693, %v_param_694, %v_param_695, %v_param_696, epsilon=1.001e-05f);\n",
       "  %615 = %614.0;\n",
       "  %616 = nn.relu(%615);\n",
       "  %617 = nn.conv2d(%616, %v_param_697, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %618 = nn.bias_add(%617, %v_param_698);\n",
       "  %619 = nn.batch_norm(%618, %v_param_699, %v_param_700, %v_param_701, %v_param_702, epsilon=1.001e-05f);\n",
       "  %620 = %619.0;\n",
       "  %621 = nn.relu(%620);\n",
       "  %622 = nn.conv2d(%621, %v_param_703, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %623 = nn.bias_add(%622, %v_param_704);\n",
       "  %624 = nn.batch_norm(%623, %v_param_705, %v_param_706, %v_param_707, %v_param_708, epsilon=1.001e-05f);\n",
       "  %625 = %624.0;\n",
       "  %626 = add(%611, %625);\n",
       "  %627 = nn.relu(%626);\n",
       "  %628 = nn.conv2d(%627, %v_param_709, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %629 = nn.bias_add(%628, %v_param_710);\n",
       "  %630 = nn.batch_norm(%629, %v_param_711, %v_param_712, %v_param_713, %v_param_714, epsilon=1.001e-05f);\n",
       "  %631 = %630.0;\n",
       "  %632 = nn.relu(%631);\n",
       "  %633 = nn.conv2d(%632, %v_param_715, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %634 = nn.bias_add(%633, %v_param_716);\n",
       "  %635 = nn.batch_norm(%634, %v_param_717, %v_param_718, %v_param_719, %v_param_720, epsilon=1.001e-05f);\n",
       "  %636 = %635.0;\n",
       "  %637 = nn.relu(%636);\n",
       "  %638 = nn.conv2d(%637, %v_param_721, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %639 = nn.bias_add(%638, %v_param_722);\n",
       "  %640 = nn.batch_norm(%639, %v_param_723, %v_param_724, %v_param_725, %v_param_726, epsilon=1.001e-05f);\n",
       "  %641 = %640.0;\n",
       "  %642 = add(%627, %641);\n",
       "  %643 = nn.relu(%642);\n",
       "  %644 = nn.conv2d(%643, %v_param_727, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %645 = nn.bias_add(%644, %v_param_728);\n",
       "  %646 = nn.batch_norm(%645, %v_param_729, %v_param_730, %v_param_731, %v_param_732, epsilon=1.001e-05f);\n",
       "  %647 = %646.0;\n",
       "  %648 = nn.relu(%647);\n",
       "  %649 = nn.conv2d(%648, %v_param_733, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %650 = nn.bias_add(%649, %v_param_734);\n",
       "  %651 = nn.batch_norm(%650, %v_param_735, %v_param_736, %v_param_737, %v_param_738, epsilon=1.001e-05f);\n",
       "  %652 = %651.0;\n",
       "  %653 = nn.relu(%652);\n",
       "  %654 = nn.conv2d(%653, %v_param_739, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %655 = nn.bias_add(%654, %v_param_740);\n",
       "  %656 = nn.batch_norm(%655, %v_param_741, %v_param_742, %v_param_743, %v_param_744, epsilon=1.001e-05f);\n",
       "  %657 = %656.0;\n",
       "  %658 = add(%643, %657);\n",
       "  %659 = nn.relu(%658);\n",
       "  %660 = nn.conv2d(%659, %v_param_745, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %661 = nn.bias_add(%660, %v_param_746);\n",
       "  %662 = nn.batch_norm(%661, %v_param_747, %v_param_748, %v_param_749, %v_param_750, epsilon=1.001e-05f);\n",
       "  %663 = %662.0;\n",
       "  %664 = nn.relu(%663);\n",
       "  %665 = nn.conv2d(%664, %v_param_751, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %666 = nn.bias_add(%665, %v_param_752);\n",
       "  %667 = nn.batch_norm(%666, %v_param_753, %v_param_754, %v_param_755, %v_param_756, epsilon=1.001e-05f);\n",
       "  %668 = %667.0;\n",
       "  %669 = nn.relu(%668);\n",
       "  %670 = nn.conv2d(%669, %v_param_757, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %671 = nn.bias_add(%670, %v_param_758);\n",
       "  %672 = nn.batch_norm(%671, %v_param_759, %v_param_760, %v_param_761, %v_param_762, epsilon=1.001e-05f);\n",
       "  %673 = %672.0;\n",
       "  %674 = add(%659, %673);\n",
       "  %675 = nn.relu(%674);\n",
       "  %676 = nn.conv2d(%675, %v_param_763, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %677 = nn.bias_add(%676, %v_param_764);\n",
       "  %678 = nn.batch_norm(%677, %v_param_765, %v_param_766, %v_param_767, %v_param_768, epsilon=1.001e-05f);\n",
       "  %679 = %678.0;\n",
       "  %680 = nn.relu(%679);\n",
       "  %681 = nn.conv2d(%680, %v_param_769, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %682 = nn.bias_add(%681, %v_param_770);\n",
       "  %683 = nn.batch_norm(%682, %v_param_771, %v_param_772, %v_param_773, %v_param_774, epsilon=1.001e-05f);\n",
       "  %684 = %683.0;\n",
       "  %685 = nn.relu(%684);\n",
       "  %686 = nn.conv2d(%685, %v_param_775, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %687 = nn.bias_add(%686, %v_param_776);\n",
       "  %688 = nn.batch_norm(%687, %v_param_777, %v_param_778, %v_param_779, %v_param_780, epsilon=1.001e-05f);\n",
       "  %689 = %688.0;\n",
       "  %690 = add(%675, %689);\n",
       "  %691 = nn.relu(%690);\n",
       "  %692 = nn.conv2d(%691, %v_param_781, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %693 = nn.bias_add(%692, %v_param_782);\n",
       "  %694 = nn.batch_norm(%693, %v_param_783, %v_param_784, %v_param_785, %v_param_786, epsilon=1.001e-05f);\n",
       "  %695 = %694.0;\n",
       "  %696 = nn.relu(%695);\n",
       "  %697 = nn.conv2d(%696, %v_param_787, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %698 = nn.bias_add(%697, %v_param_788);\n",
       "  %699 = nn.batch_norm(%698, %v_param_789, %v_param_790, %v_param_791, %v_param_792, epsilon=1.001e-05f);\n",
       "  %700 = %699.0;\n",
       "  %701 = nn.relu(%700);\n",
       "  %702 = nn.conv2d(%701, %v_param_793, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %703 = nn.bias_add(%702, %v_param_794);\n",
       "  %704 = nn.batch_norm(%703, %v_param_795, %v_param_796, %v_param_797, %v_param_798, epsilon=1.001e-05f);\n",
       "  %705 = %704.0;\n",
       "  %706 = add(%691, %705);\n",
       "  %707 = nn.relu(%706);\n",
       "  %708 = nn.conv2d(%707, %v_param_799, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %709 = nn.bias_add(%708, %v_param_800);\n",
       "  %710 = nn.batch_norm(%709, %v_param_801, %v_param_802, %v_param_803, %v_param_804, epsilon=1.001e-05f);\n",
       "  %711 = %710.0;\n",
       "  %712 = nn.relu(%711);\n",
       "  %713 = nn.conv2d(%712, %v_param_805, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %714 = nn.bias_add(%713, %v_param_806);\n",
       "  %715 = nn.batch_norm(%714, %v_param_807, %v_param_808, %v_param_809, %v_param_810, epsilon=1.001e-05f);\n",
       "  %716 = %715.0;\n",
       "  %717 = nn.relu(%716);\n",
       "  %718 = nn.conv2d(%717, %v_param_811, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %719 = nn.bias_add(%718, %v_param_812);\n",
       "  %720 = nn.batch_norm(%719, %v_param_813, %v_param_814, %v_param_815, %v_param_816, epsilon=1.001e-05f);\n",
       "  %721 = %720.0;\n",
       "  %722 = add(%707, %721);\n",
       "  %723 = nn.relu(%722);\n",
       "  %724 = nn.conv2d(%723, %v_param_817, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %725 = nn.bias_add(%724, %v_param_818);\n",
       "  %726 = nn.batch_norm(%725, %v_param_819, %v_param_820, %v_param_821, %v_param_822, epsilon=1.001e-05f);\n",
       "  %727 = %726.0;\n",
       "  %728 = nn.relu(%727);\n",
       "  %729 = nn.conv2d(%728, %v_param_823, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %730 = nn.bias_add(%729, %v_param_824);\n",
       "  %731 = nn.batch_norm(%730, %v_param_825, %v_param_826, %v_param_827, %v_param_828, epsilon=1.001e-05f);\n",
       "  %732 = %731.0;\n",
       "  %733 = nn.relu(%732);\n",
       "  %734 = nn.conv2d(%733, %v_param_829, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %735 = nn.bias_add(%734, %v_param_830);\n",
       "  %736 = nn.batch_norm(%735, %v_param_831, %v_param_832, %v_param_833, %v_param_834, epsilon=1.001e-05f);\n",
       "  %737 = %736.0;\n",
       "  %738 = add(%723, %737);\n",
       "  %739 = nn.relu(%738);\n",
       "  %740 = nn.conv2d(%739, %v_param_835, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %741 = nn.bias_add(%740, %v_param_836);\n",
       "  %742 = nn.batch_norm(%741, %v_param_837, %v_param_838, %v_param_839, %v_param_840, epsilon=1.001e-05f);\n",
       "  %743 = %742.0;\n",
       "  %744 = nn.relu(%743);\n",
       "  %745 = nn.conv2d(%744, %v_param_841, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %746 = nn.bias_add(%745, %v_param_842);\n",
       "  %747 = nn.batch_norm(%746, %v_param_843, %v_param_844, %v_param_845, %v_param_846, epsilon=1.001e-05f);\n",
       "  %748 = %747.0;\n",
       "  %749 = nn.relu(%748);\n",
       "  %750 = nn.conv2d(%749, %v_param_847, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %751 = nn.bias_add(%750, %v_param_848);\n",
       "  %752 = nn.batch_norm(%751, %v_param_849, %v_param_850, %v_param_851, %v_param_852, epsilon=1.001e-05f);\n",
       "  %753 = %752.0;\n",
       "  %754 = add(%739, %753);\n",
       "  %755 = nn.relu(%754);\n",
       "  %756 = nn.conv2d(%755, %v_param_853, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %757 = nn.bias_add(%756, %v_param_854);\n",
       "  %758 = nn.batch_norm(%757, %v_param_855, %v_param_856, %v_param_857, %v_param_858, epsilon=1.001e-05f);\n",
       "  %759 = %758.0;\n",
       "  %760 = nn.relu(%759);\n",
       "  %761 = nn.conv2d(%760, %v_param_859, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %762 = nn.bias_add(%761, %v_param_860);\n",
       "  %763 = nn.batch_norm(%762, %v_param_861, %v_param_862, %v_param_863, %v_param_864, epsilon=1.001e-05f);\n",
       "  %764 = %763.0;\n",
       "  %765 = nn.relu(%764);\n",
       "  %766 = nn.conv2d(%765, %v_param_865, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %767 = nn.bias_add(%766, %v_param_866);\n",
       "  %768 = nn.batch_norm(%767, %v_param_867, %v_param_868, %v_param_869, %v_param_870, epsilon=1.001e-05f);\n",
       "  %769 = %768.0;\n",
       "  %770 = add(%755, %769);\n",
       "  %771 = nn.relu(%770);\n",
       "  %772 = nn.conv2d(%771, %v_param_883, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %773 = nn.bias_add(%772, %v_param_884);\n",
       "  %774 = nn.batch_norm(%773, %v_param_887, %v_param_888, %v_param_889, %v_param_890, epsilon=1.001e-05f);\n",
       "  %775 = nn.conv2d(%771, %v_param_871, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %776 = nn.bias_add(%775, %v_param_872);\n",
       "  %777 = nn.batch_norm(%776, %v_param_873, %v_param_874, %v_param_875, %v_param_876, epsilon=1.001e-05f);\n",
       "  %778 = %777.0;\n",
       "  %779 = nn.relu(%778);\n",
       "  %780 = nn.conv2d(%779, %v_param_877, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %781 = nn.bias_add(%780, %v_param_878);\n",
       "  %782 = nn.batch_norm(%781, %v_param_879, %v_param_880, %v_param_881, %v_param_882, epsilon=1.001e-05f);\n",
       "  %783 = %782.0;\n",
       "  %784 = nn.relu(%783);\n",
       "  %785 = nn.conv2d(%784, %v_param_885, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %786 = nn.bias_add(%785, %v_param_886);\n",
       "  %787 = nn.batch_norm(%786, %v_param_891, %v_param_892, %v_param_893, %v_param_894, epsilon=1.001e-05f);\n",
       "  %788 = %774.0;\n",
       "  %789 = %787.0;\n",
       "  %790 = add(%788, %789);\n",
       "  %791 = nn.relu(%790);\n",
       "  %792 = nn.conv2d(%791, %v_param_895, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %793 = nn.bias_add(%792, %v_param_896);\n",
       "  %794 = nn.batch_norm(%793, %v_param_897, %v_param_898, %v_param_899, %v_param_900, epsilon=1.001e-05f);\n",
       "  %795 = %794.0;\n",
       "  %796 = nn.relu(%795);\n",
       "  %797 = nn.conv2d(%796, %v_param_901, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %798 = nn.bias_add(%797, %v_param_902);\n",
       "  %799 = nn.batch_norm(%798, %v_param_903, %v_param_904, %v_param_905, %v_param_906, epsilon=1.001e-05f);\n",
       "  %800 = %799.0;\n",
       "  %801 = nn.relu(%800);\n",
       "  %802 = nn.conv2d(%801, %v_param_907, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %803 = nn.bias_add(%802, %v_param_908);\n",
       "  %804 = nn.batch_norm(%803, %v_param_909, %v_param_910, %v_param_911, %v_param_912, epsilon=1.001e-05f);\n",
       "  %805 = %804.0;\n",
       "  %806 = add(%791, %805);\n",
       "  %807 = nn.relu(%806);\n",
       "  %808 = nn.conv2d(%807, %v_param_913, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %809 = nn.bias_add(%808, %v_param_914);\n",
       "  %810 = nn.batch_norm(%809, %v_param_915, %v_param_916, %v_param_917, %v_param_918, epsilon=1.001e-05f);\n",
       "  %811 = %810.0;\n",
       "  %812 = nn.relu(%811);\n",
       "  %813 = nn.conv2d(%812, %v_param_919, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %814 = nn.bias_add(%813, %v_param_920);\n",
       "  %815 = nn.batch_norm(%814, %v_param_921, %v_param_922, %v_param_923, %v_param_924, epsilon=1.001e-05f);\n",
       "  %816 = %815.0;\n",
       "  %817 = nn.relu(%816);\n",
       "  %818 = nn.conv2d(%817, %v_param_925, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %819 = nn.bias_add(%818, %v_param_926);\n",
       "  %820 = nn.batch_norm(%819, %v_param_927, %v_param_928, %v_param_929, %v_param_930, epsilon=1.001e-05f);\n",
       "  %821 = %820.0;\n",
       "  %822 = add(%807, %821);\n",
       "  %823 = nn.relu(%822);\n",
       "  %824 = nn.global_avg_pool2d(%823);\n",
       "  %825 = transpose(%824, axes=[0, 2, 3, 1]);\n",
       "  %826 = nn.batch_flatten(%825);\n",
       "  %827 = nn.dense(%826, %v_param_931, units=1000);\n",
       "  %828 = nn.bias_add(%827, %v_param_932);\n",
       "  nn.softmax(%828, axis=1)\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = is_op(\"nn.relu\")(is_tuple_get_item(is_op('nn.batch_norm')))\n",
    "conv2d_1 = is_op(\"nn.conv2d\")(wildcard(), wildcard())\n",
    "bias_add_1 = is_op(\"nn.bias_add\")(conv2d_1, wildcard())\n",
    "pattern =  bias_add_1\n",
    "# %60 = nn.conv2d(%59, %v_param_79, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
    "# %61 = nn.bias_add(%60, %v_param_80);\n",
    "# %62 = nn.batch_norm(%61, %v_param_83, %v_param_84, %v_param_85, %v_param_86, epsilon=1.001e-05f);\n",
    "# %63 = nn.conv2d(%59, %v_param_67, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
    "# %64 = nn.bias_add(%63, %v_param_68);\n",
    "\n",
    "partitioned = pattern.partition(mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "z = relay.var(\"z\", shape=(8, 8))\n",
    "k = relay.var(\"k\", shape=(8, 8))\n",
    "\n",
    "p = (x+y)*z + k\n",
    "a = (x+y)\n",
    "b = a * z + k\n",
    "c = b - a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = relay.Function([x,y,z,k], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%x: Tensor[(8, 8), float32], %y: Tensor[(8, 8), float32], %z: Tensor[(8, 8), float32], %k: Tensor[(8, 8), float32]) {\n",
       "  %0 = add(%x, %y);\n",
       "  %1 = multiply(%0, %z);\n",
       "  %2 = add(%1, %k);\n",
       "  subtract(%2, %0)\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'params' and 'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000042?line=0'>1</a>\u001b[0m f1 \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mFunction()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'params' and 'body'"
     ]
    }
   ],
   "source": [
    "f1 = relay.Function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Op(subtract)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tvm.relay.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = f.body.args[1].args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %x: Tensor[(8, 8), float32];\n",
      "free_var %y: Tensor[(8, 8), float32];\n",
      "add(%x, %y)\n"
     ]
    }
   ],
   "source": [
    "print(f.body.args[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(shape_of), [Var(x, ty=TensorType([8, 8], float32))], relay.attrs.ShapeOfAttrs(0x21dc34e8), [])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm.relay.shape_of(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit(node):\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "post_order_visit() missing 1 required positional argument: 'fvisit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000049?line=0'>1</a>\u001b[0m tvm\u001b[39m.\u001b[39;49mtir\u001b[39m.\u001b[39;49mstmt_functor\u001b[39m.\u001b[39;49mpost_order_visit(mod)\n",
      "\u001b[0;31mTypeError\u001b[0m: post_order_visit() missing 1 required positional argument: 'fvisit'"
     ]
    }
   ],
   "source": [
    "tvm.tir.stmt_functor.post_order_visit(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.body.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.expr.Call'>\n",
      "Functions:\n",
      "free_var %x: Tensor[(8, 8), float32];\n",
      "free_var %y: Tensor[(8, 8), float32];\n",
      "%0 = add(%x, %y);\n",
      "free_var %z: Tensor[(8, 8), float32];\n",
      "%1 = multiply(%0, %z);\n",
      "free_var %k: Tensor[(8, 8), float32];\n",
      "add(%1, %k)\n"
     ]
    }
   ],
   "source": [
    "class FuncCollector(tvm.relay.ExprVisitor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.funcs = set()\n",
    "        self.funcs = []\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        # print(call)\n",
    "        # op = call.op\n",
    "        op = call\n",
    "        print(type(call))\n",
    "        if isinstance(op, relay.Call):\n",
    "            self.funcs.append(op)\n",
    "\n",
    "collector = FuncCollector()\n",
    "collector.visit(f)\n",
    "print(\"Functions:\")\n",
    "for func in collector.funcs:\n",
    "    print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# ev = tvm.relay.ExprVisitor()\n",
    "ev = FuncCollector()\n",
    "ev.visit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncCollector(tvm.relay.ExprVisitor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.funcs = set()\n",
    "        self.funcs = []\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        # print(call)\n",
    "        # op = call.op\n",
    "        print(1)\n",
    "        # op = call\n",
    "        # print(type(call))\n",
    "        # if isinstance(op, relay.Call):\n",
    "        #     self.funcs.append(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  =f.body.args[0].args[0].op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000041?line=0'>1</a>\u001b[0m relay\u001b[39m.\u001b[39;49mop(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "relay.op(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Op(nn.softmax)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  2: TVMFuncCall\n  1: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::IRModule<tvm::IRModule>() const\n  3: TVMFuncCall\n  2: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::IRModule<tvm::IRModule>() const\n  0: tvm::IRModule tvm::runtime::TVMPODValue_::AsObjectRef<tvm::IRModule>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function transform.RunPass: error while converting argument 1: [19:48:09] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected IRModule, but got relay.Function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000031?line=0'>1</a>\u001b[0m tvm\u001b[39m.\u001b[39;49mrelay\u001b[39m.\u001b[39;49mtransform\u001b[39m.\u001b[39;49mPartitionGraph()(partitioned)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/ir/transform.py:161\u001b[0m, in \u001b[0;36mPass.__call__\u001b[0;34m(self, mod)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=146'>147</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, mod):\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=147'>148</a>\u001b[0m     \u001b[39m\"\"\"Execute the pass. Note that for sequential pass, the dependency among\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=148'>149</a>\u001b[0m \u001b[39m    different passes will be resolved in the backend.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=149'>150</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=158'>159</a>\u001b[0m \u001b[39m        The updated module after applying this pass.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=159'>160</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/ir/transform.py?line=160'>161</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_transform_api\u001b[39m.\u001b[39;49mRunPass(\u001b[39mself\u001b[39;49m, mod)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=224'>225</a>\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=225'>226</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=226'>227</a>\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=227'>228</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=234'>235</a>\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=235'>236</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=236'>237</a>\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=237'>238</a>\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=238'>239</a>\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  2: TVMFuncCall\n  1: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::IRModule<tvm::IRModule>() const\n  3: TVMFuncCall\n  2: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::IRModule<tvm::IRModule>() const\n  0: tvm::IRModule tvm::runtime::TVMPODValue_::AsObjectRef<tvm::IRModule>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function transform.RunPass: error while converting argument 1: [19:48:09] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected IRModule, but got relay.Function\n"
     ]
    }
   ],
   "source": [
    "tvm.relay.transform.PartitionGraph()(partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%input_1: Tensor[(1, 3, 224, 224), float32], %v_param_1: Tensor[(64, 3, 7, 7), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_19: Tensor[(256, 64, 1, 1), float32], %v_param_20: Tensor[(256), float32], %v_param_23: Tensor[(256), float32], %v_param_24: Tensor[(256), float32], %v_param_25: Tensor[(256), float32], %v_param_26: Tensor[(256), float32], %v_param_7: Tensor[(64, 64, 1, 1), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(64, 64, 3, 3), float32], %v_param_14: Tensor[(64), float32], %v_param_15: Tensor[(64), float32], %v_param_16: Tensor[(64), float32], %v_param_17: Tensor[(64), float32], %v_param_18: Tensor[(64), float32], %v_param_21: Tensor[(256, 64, 1, 1), float32], %v_param_22: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(64, 256, 1, 1), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(64, 64, 3, 3), float32], %v_param_38: Tensor[(64), float32], %v_param_39: Tensor[(64), float32], %v_param_40: Tensor[(64), float32], %v_param_41: Tensor[(64), float32], %v_param_42: Tensor[(64), float32], %v_param_43: Tensor[(256, 64, 1, 1), float32], %v_param_44: Tensor[(256), float32], %v_param_45: Tensor[(256), float32], %v_param_46: Tensor[(256), float32], %v_param_47: Tensor[(256), float32], %v_param_48: Tensor[(256), float32], %v_param_49: Tensor[(64, 256, 1, 1), float32], %v_param_50: Tensor[(64), float32], %v_param_51: Tensor[(64), float32], %v_param_52: Tensor[(64), float32], %v_param_53: Tensor[(64), float32], %v_param_54: Tensor[(64), float32], %v_param_55: Tensor[(64, 64, 3, 3), float32], %v_param_56: Tensor[(64), float32], %v_param_57: Tensor[(64), float32], %v_param_58: Tensor[(64), float32], %v_param_59: Tensor[(64), float32], %v_param_60: Tensor[(64), float32], %v_param_61: Tensor[(256, 64, 1, 1), float32], %v_param_62: Tensor[(256), float32], %v_param_63: Tensor[(256), float32], %v_param_64: Tensor[(256), float32], %v_param_65: Tensor[(256), float32], %v_param_66: Tensor[(256), float32], %v_param_79: Tensor[(512, 256, 1, 1), float32], %v_param_80: Tensor[(512), float32], %v_param_83: Tensor[(512), float32], %v_param_84: Tensor[(512), float32], %v_param_85: Tensor[(512), float32], %v_param_86: Tensor[(512), float32], %v_param_67: Tensor[(128, 256, 1, 1), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_81: Tensor[(512, 128, 1, 1), float32], %v_param_82: Tensor[(512), float32], %v_param_87: Tensor[(512), float32], %v_param_88: Tensor[(512), float32], %v_param_89: Tensor[(512), float32], %v_param_90: Tensor[(512), float32], %v_param_91: Tensor[(128, 512, 1, 1), float32], %v_param_92: Tensor[(128), float32], %v_param_93: Tensor[(128), float32], %v_param_94: Tensor[(128), float32], %v_param_95: Tensor[(128), float32], %v_param_96: Tensor[(128), float32], %v_param_97: Tensor[(128, 128, 3, 3), float32], %v_param_98: Tensor[(128), float32], %v_param_99: Tensor[(128), float32], %v_param_100: Tensor[(128), float32], %v_param_101: Tensor[(128), float32], %v_param_102: Tensor[(128), float32], %v_param_103: Tensor[(512, 128, 1, 1), float32], %v_param_104: Tensor[(512), float32], %v_param_105: Tensor[(512), float32], %v_param_106: Tensor[(512), float32], %v_param_107: Tensor[(512), float32], %v_param_108: Tensor[(512), float32], %v_param_109: Tensor[(128, 512, 1, 1), float32], %v_param_110: Tensor[(128), float32], %v_param_111: Tensor[(128), float32], %v_param_112: Tensor[(128), float32], %v_param_113: Tensor[(128), float32], %v_param_114: Tensor[(128), float32], %v_param_115: Tensor[(128, 128, 3, 3), float32], %v_param_116: Tensor[(128), float32], %v_param_117: Tensor[(128), float32], %v_param_118: Tensor[(128), float32], %v_param_119: Tensor[(128), float32], %v_param_120: Tensor[(128), float32], %v_param_121: Tensor[(512, 128, 1, 1), float32], %v_param_122: Tensor[(512), float32], %v_param_123: Tensor[(512), float32], %v_param_124: Tensor[(512), float32], %v_param_125: Tensor[(512), float32], %v_param_126: Tensor[(512), float32], %v_param_127: Tensor[(128, 512, 1, 1), float32], %v_param_128: Tensor[(128), float32], %v_param_129: Tensor[(128), float32], %v_param_130: Tensor[(128), float32], %v_param_131: Tensor[(128), float32], %v_param_132: Tensor[(128), float32], %v_param_133: Tensor[(128, 128, 3, 3), float32], %v_param_134: Tensor[(128), float32], %v_param_135: Tensor[(128), float32], %v_param_136: Tensor[(128), float32], %v_param_137: Tensor[(128), float32], %v_param_138: Tensor[(128), float32], %v_param_139: Tensor[(512, 128, 1, 1), float32], %v_param_140: Tensor[(512), float32], %v_param_141: Tensor[(512), float32], %v_param_142: Tensor[(512), float32], %v_param_143: Tensor[(512), float32], %v_param_144: Tensor[(512), float32], %v_param_145: Tensor[(128, 512, 1, 1), float32], %v_param_146: Tensor[(128), float32], %v_param_147: Tensor[(128), float32], %v_param_148: Tensor[(128), float32], %v_param_149: Tensor[(128), float32], %v_param_150: Tensor[(128), float32], %v_param_151: Tensor[(128, 128, 3, 3), float32], %v_param_152: Tensor[(128), float32], %v_param_153: Tensor[(128), float32], %v_param_154: Tensor[(128), float32], %v_param_155: Tensor[(128), float32], %v_param_156: Tensor[(128), float32], %v_param_157: Tensor[(512, 128, 1, 1), float32], %v_param_158: Tensor[(512), float32], %v_param_159: Tensor[(512), float32], %v_param_160: Tensor[(512), float32], %v_param_161: Tensor[(512), float32], %v_param_162: Tensor[(512), float32], %v_param_163: Tensor[(128, 512, 1, 1), float32], %v_param_164: Tensor[(128), float32], %v_param_165: Tensor[(128), float32], %v_param_166: Tensor[(128), float32], %v_param_167: Tensor[(128), float32], %v_param_168: Tensor[(128), float32], %v_param_169: Tensor[(128, 128, 3, 3), float32], %v_param_170: Tensor[(128), float32], %v_param_171: Tensor[(128), float32], %v_param_172: Tensor[(128), float32], %v_param_173: Tensor[(128), float32], %v_param_174: Tensor[(128), float32], %v_param_175: Tensor[(512, 128, 1, 1), float32], %v_param_176: Tensor[(512), float32], %v_param_177: Tensor[(512), float32], %v_param_178: Tensor[(512), float32], %v_param_179: Tensor[(512), float32], %v_param_180: Tensor[(512), float32], %v_param_181: Tensor[(128, 512, 1, 1), float32], %v_param_182: Tensor[(128), float32], %v_param_183: Tensor[(128), float32], %v_param_184: Tensor[(128), float32], %v_param_185: Tensor[(128), float32], %v_param_186: Tensor[(128), float32], %v_param_187: Tensor[(128, 128, 3, 3), float32], %v_param_188: Tensor[(128), float32], %v_param_189: Tensor[(128), float32], %v_param_190: Tensor[(128), float32], %v_param_191: Tensor[(128), float32], %v_param_192: Tensor[(128), float32], %v_param_193: Tensor[(512, 128, 1, 1), float32], %v_param_194: Tensor[(512), float32], %v_param_195: Tensor[(512), float32], %v_param_196: Tensor[(512), float32], %v_param_197: Tensor[(512), float32], %v_param_198: Tensor[(512), float32], %v_param_199: Tensor[(128, 512, 1, 1), float32], %v_param_200: Tensor[(128), float32], %v_param_201: Tensor[(128), float32], %v_param_202: Tensor[(128), float32], %v_param_203: Tensor[(128), float32], %v_param_204: Tensor[(128), float32], %v_param_205: Tensor[(128, 128, 3, 3), float32], %v_param_206: Tensor[(128), float32], %v_param_207: Tensor[(128), float32], %v_param_208: Tensor[(128), float32], %v_param_209: Tensor[(128), float32], %v_param_210: Tensor[(128), float32], %v_param_211: Tensor[(512, 128, 1, 1), float32], %v_param_212: Tensor[(512), float32], %v_param_213: Tensor[(512), float32], %v_param_214: Tensor[(512), float32], %v_param_215: Tensor[(512), float32], %v_param_216: Tensor[(512), float32], %v_param_229: Tensor[(1024, 512, 1, 1), float32], %v_param_230: Tensor[(1024), float32], %v_param_233: Tensor[(1024), float32], %v_param_234: Tensor[(1024), float32], %v_param_235: Tensor[(1024), float32], %v_param_236: Tensor[(1024), float32], %v_param_217: Tensor[(256, 512, 1, 1), float32], %v_param_218: Tensor[(256), float32], %v_param_219: Tensor[(256), float32], %v_param_220: Tensor[(256), float32], %v_param_221: Tensor[(256), float32], %v_param_222: Tensor[(256), float32], %v_param_223: Tensor[(256, 256, 3, 3), float32], %v_param_224: Tensor[(256), float32], %v_param_225: Tensor[(256), float32], %v_param_226: Tensor[(256), float32], %v_param_227: Tensor[(256), float32], %v_param_228: Tensor[(256), float32], %v_param_231: Tensor[(1024, 256, 1, 1), float32], %v_param_232: Tensor[(1024), float32], %v_param_237: Tensor[(1024), float32], %v_param_238: Tensor[(1024), float32], %v_param_239: Tensor[(1024), float32], %v_param_240: Tensor[(1024), float32], %v_param_241: Tensor[(256, 1024, 1, 1), float32], %v_param_242: Tensor[(256), float32], %v_param_243: Tensor[(256), float32], %v_param_244: Tensor[(256), float32], %v_param_245: Tensor[(256), float32], %v_param_246: Tensor[(256), float32], %v_param_247: Tensor[(256, 256, 3, 3), float32], %v_param_248: Tensor[(256), float32], %v_param_249: Tensor[(256), float32], %v_param_250: Tensor[(256), float32], %v_param_251: Tensor[(256), float32], %v_param_252: Tensor[(256), float32], %v_param_253: Tensor[(1024, 256, 1, 1), float32], %v_param_254: Tensor[(1024), float32], %v_param_255: Tensor[(1024), float32], %v_param_256: Tensor[(1024), float32], %v_param_257: Tensor[(1024), float32], %v_param_258: Tensor[(1024), float32], %v_param_259: Tensor[(256, 1024, 1, 1), float32], %v_param_260: Tensor[(256), float32], %v_param_261: Tensor[(256), float32], %v_param_262: Tensor[(256), float32], %v_param_263: Tensor[(256), float32], %v_param_264: Tensor[(256), float32], %v_param_265: Tensor[(256, 256, 3, 3), float32], %v_param_266: Tensor[(256), float32], %v_param_267: Tensor[(256), float32], %v_param_268: Tensor[(256), float32], %v_param_269: Tensor[(256), float32], %v_param_270: Tensor[(256), float32], %v_param_271: Tensor[(1024, 256, 1, 1), float32], %v_param_272: Tensor[(1024), float32], %v_param_273: Tensor[(1024), float32], %v_param_274: Tensor[(1024), float32], %v_param_275: Tensor[(1024), float32], %v_param_276: Tensor[(1024), float32], %v_param_277: Tensor[(256, 1024, 1, 1), float32], %v_param_278: Tensor[(256), float32], %v_param_279: Tensor[(256), float32], %v_param_280: Tensor[(256), float32], %v_param_281: Tensor[(256), float32], %v_param_282: Tensor[(256), float32], %v_param_283: Tensor[(256, 256, 3, 3), float32], %v_param_284: Tensor[(256), float32], %v_param_285: Tensor[(256), float32], %v_param_286: Tensor[(256), float32], %v_param_287: Tensor[(256), float32], %v_param_288: Tensor[(256), float32], %v_param_289: Tensor[(1024, 256, 1, 1), float32], %v_param_290: Tensor[(1024), float32], %v_param_291: Tensor[(1024), float32], %v_param_292: Tensor[(1024), float32], %v_param_293: Tensor[(1024), float32], %v_param_294: Tensor[(1024), float32], %v_param_295: Tensor[(256, 1024, 1, 1), float32], %v_param_296: Tensor[(256), float32], %v_param_297: Tensor[(256), float32], %v_param_298: Tensor[(256), float32], %v_param_299: Tensor[(256), float32], %v_param_300: Tensor[(256), float32], %v_param_301: Tensor[(256, 256, 3, 3), float32], %v_param_302: Tensor[(256), float32], %v_param_303: Tensor[(256), float32], %v_param_304: Tensor[(256), float32], %v_param_305: Tensor[(256), float32], %v_param_306: Tensor[(256), float32], %v_param_307: Tensor[(1024, 256, 1, 1), float32], %v_param_308: Tensor[(1024), float32], %v_param_309: Tensor[(1024), float32], %v_param_310: Tensor[(1024), float32], %v_param_311: Tensor[(1024), float32], %v_param_312: Tensor[(1024), float32], %v_param_313: Tensor[(256, 1024, 1, 1), float32], %v_param_314: Tensor[(256), float32], %v_param_315: Tensor[(256), float32], %v_param_316: Tensor[(256), float32], %v_param_317: Tensor[(256), float32], %v_param_318: Tensor[(256), float32], %v_param_319: Tensor[(256, 256, 3, 3), float32], %v_param_320: Tensor[(256), float32], %v_param_321: Tensor[(256), float32], %v_param_322: Tensor[(256), float32], %v_param_323: Tensor[(256), float32], %v_param_324: Tensor[(256), float32], %v_param_325: Tensor[(1024, 256, 1, 1), float32], %v_param_326: Tensor[(1024), float32], %v_param_327: Tensor[(1024), float32], %v_param_328: Tensor[(1024), float32], %v_param_329: Tensor[(1024), float32], %v_param_330: Tensor[(1024), float32], %v_param_331: Tensor[(256, 1024, 1, 1), float32], %v_param_332: Tensor[(256), float32], %v_param_333: Tensor[(256), float32], %v_param_334: Tensor[(256), float32], %v_param_335: Tensor[(256), float32], %v_param_336: Tensor[(256), float32], %v_param_337: Tensor[(256, 256, 3, 3), float32], %v_param_338: Tensor[(256), float32], %v_param_339: Tensor[(256), float32], %v_param_340: Tensor[(256), float32], %v_param_341: Tensor[(256), float32], %v_param_342: Tensor[(256), float32], %v_param_343: Tensor[(1024, 256, 1, 1), float32], %v_param_344: Tensor[(1024), float32], %v_param_345: Tensor[(1024), float32], %v_param_346: Tensor[(1024), float32], %v_param_347: Tensor[(1024), float32], %v_param_348: Tensor[(1024), float32], %v_param_349: Tensor[(256, 1024, 1, 1), float32], %v_param_350: Tensor[(256), float32], %v_param_351: Tensor[(256), float32], %v_param_352: Tensor[(256), float32], %v_param_353: Tensor[(256), float32], %v_param_354: Tensor[(256), float32], %v_param_355: Tensor[(256, 256, 3, 3), float32], %v_param_356: Tensor[(256), float32], %v_param_357: Tensor[(256), float32], %v_param_358: Tensor[(256), float32], %v_param_359: Tensor[(256), float32], %v_param_360: Tensor[(256), float32], %v_param_361: Tensor[(1024, 256, 1, 1), float32], %v_param_362: Tensor[(1024), float32], %v_param_363: Tensor[(1024), float32], %v_param_364: Tensor[(1024), float32], %v_param_365: Tensor[(1024), float32], %v_param_366: Tensor[(1024), float32], %v_param_367: Tensor[(256, 1024, 1, 1), float32], %v_param_368: Tensor[(256), float32], %v_param_369: Tensor[(256), float32], %v_param_370: Tensor[(256), float32], %v_param_371: Tensor[(256), float32], %v_param_372: Tensor[(256), float32], %v_param_373: Tensor[(256, 256, 3, 3), float32], %v_param_374: Tensor[(256), float32], %v_param_375: Tensor[(256), float32], %v_param_376: Tensor[(256), float32], %v_param_377: Tensor[(256), float32], %v_param_378: Tensor[(256), float32], %v_param_379: Tensor[(1024, 256, 1, 1), float32], %v_param_380: Tensor[(1024), float32], %v_param_381: Tensor[(1024), float32], %v_param_382: Tensor[(1024), float32], %v_param_383: Tensor[(1024), float32], %v_param_384: Tensor[(1024), float32], %v_param_385: Tensor[(256, 1024, 1, 1), float32], %v_param_386: Tensor[(256), float32], %v_param_387: Tensor[(256), float32], %v_param_388: Tensor[(256), float32], %v_param_389: Tensor[(256), float32], %v_param_390: Tensor[(256), float32], %v_param_391: Tensor[(256, 256, 3, 3), float32], %v_param_392: Tensor[(256), float32], %v_param_393: Tensor[(256), float32], %v_param_394: Tensor[(256), float32], %v_param_395: Tensor[(256), float32], %v_param_396: Tensor[(256), float32], %v_param_397: Tensor[(1024, 256, 1, 1), float32], %v_param_398: Tensor[(1024), float32], %v_param_399: Tensor[(1024), float32], %v_param_400: Tensor[(1024), float32], %v_param_401: Tensor[(1024), float32], %v_param_402: Tensor[(1024), float32], %v_param_403: Tensor[(256, 1024, 1, 1), float32], %v_param_404: Tensor[(256), float32], %v_param_405: Tensor[(256), float32], %v_param_406: Tensor[(256), float32], %v_param_407: Tensor[(256), float32], %v_param_408: Tensor[(256), float32], %v_param_409: Tensor[(256, 256, 3, 3), float32], %v_param_410: Tensor[(256), float32], %v_param_411: Tensor[(256), float32], %v_param_412: Tensor[(256), float32], %v_param_413: Tensor[(256), float32], %v_param_414: Tensor[(256), float32], %v_param_415: Tensor[(1024, 256, 1, 1), float32], %v_param_416: Tensor[(1024), float32], %v_param_417: Tensor[(1024), float32], %v_param_418: Tensor[(1024), float32], %v_param_419: Tensor[(1024), float32], %v_param_420: Tensor[(1024), float32], %v_param_421: Tensor[(256, 1024, 1, 1), float32], %v_param_422: Tensor[(256), float32], %v_param_423: Tensor[(256), float32], %v_param_424: Tensor[(256), float32], %v_param_425: Tensor[(256), float32], %v_param_426: Tensor[(256), float32], %v_param_427: Tensor[(256, 256, 3, 3), float32], %v_param_428: Tensor[(256), float32], %v_param_429: Tensor[(256), float32], %v_param_430: Tensor[(256), float32], %v_param_431: Tensor[(256), float32], %v_param_432: Tensor[(256), float32], %v_param_433: Tensor[(1024, 256, 1, 1), float32], %v_param_434: Tensor[(1024), float32], %v_param_435: Tensor[(1024), float32], %v_param_436: Tensor[(1024), float32], %v_param_437: Tensor[(1024), float32], %v_param_438: Tensor[(1024), float32], %v_param_439: Tensor[(256, 1024, 1, 1), float32], %v_param_440: Tensor[(256), float32], %v_param_441: Tensor[(256), float32], %v_param_442: Tensor[(256), float32], %v_param_443: Tensor[(256), float32], %v_param_444: Tensor[(256), float32], %v_param_445: Tensor[(256, 256, 3, 3), float32], %v_param_446: Tensor[(256), float32], %v_param_447: Tensor[(256), float32], %v_param_448: Tensor[(256), float32], %v_param_449: Tensor[(256), float32], %v_param_450: Tensor[(256), float32], %v_param_451: Tensor[(1024, 256, 1, 1), float32], %v_param_452: Tensor[(1024), float32], %v_param_453: Tensor[(1024), float32], %v_param_454: Tensor[(1024), float32], %v_param_455: Tensor[(1024), float32], %v_param_456: Tensor[(1024), float32], %v_param_457: Tensor[(256, 1024, 1, 1), float32], %v_param_458: Tensor[(256), float32], %v_param_459: Tensor[(256), float32], %v_param_460: Tensor[(256), float32], %v_param_461: Tensor[(256), float32], %v_param_462: Tensor[(256), float32], %v_param_463: Tensor[(256, 256, 3, 3), float32], %v_param_464: Tensor[(256), float32], %v_param_465: Tensor[(256), float32], %v_param_466: Tensor[(256), float32], %v_param_467: Tensor[(256), float32], %v_param_468: Tensor[(256), float32], %v_param_469: Tensor[(1024, 256, 1, 1), float32], %v_param_470: Tensor[(1024), float32], %v_param_471: Tensor[(1024), float32], %v_param_472: Tensor[(1024), float32], %v_param_473: Tensor[(1024), float32], %v_param_474: Tensor[(1024), float32], %v_param_475: Tensor[(256, 1024, 1, 1), float32], %v_param_476: Tensor[(256), float32], %v_param_477: Tensor[(256), float32], %v_param_478: Tensor[(256), float32], %v_param_479: Tensor[(256), float32], %v_param_480: Tensor[(256), float32], %v_param_481: Tensor[(256, 256, 3, 3), float32], %v_param_482: Tensor[(256), float32], %v_param_483: Tensor[(256), float32], %v_param_484: Tensor[(256), float32], %v_param_485: Tensor[(256), float32], %v_param_486: Tensor[(256), float32], %v_param_487: Tensor[(1024, 256, 1, 1), float32], %v_param_488: Tensor[(1024), float32], %v_param_489: Tensor[(1024), float32], %v_param_490: Tensor[(1024), float32], %v_param_491: Tensor[(1024), float32], %v_param_492: Tensor[(1024), float32], %v_param_493: Tensor[(256, 1024, 1, 1), float32], %v_param_494: Tensor[(256), float32], %v_param_495: Tensor[(256), float32], %v_param_496: Tensor[(256), float32], %v_param_497: Tensor[(256), float32], %v_param_498: Tensor[(256), float32], %v_param_499: Tensor[(256, 256, 3, 3), float32], %v_param_500: Tensor[(256), float32], %v_param_501: Tensor[(256), float32], %v_param_502: Tensor[(256), float32], %v_param_503: Tensor[(256), float32], %v_param_504: Tensor[(256), float32], %v_param_505: Tensor[(1024, 256, 1, 1), float32], %v_param_506: Tensor[(1024), float32], %v_param_507: Tensor[(1024), float32], %v_param_508: Tensor[(1024), float32], %v_param_509: Tensor[(1024), float32], %v_param_510: Tensor[(1024), float32], %v_param_511: Tensor[(256, 1024, 1, 1), float32], %v_param_512: Tensor[(256), float32], %v_param_513: Tensor[(256), float32], %v_param_514: Tensor[(256), float32], %v_param_515: Tensor[(256), float32], %v_param_516: Tensor[(256), float32], %v_param_517: Tensor[(256, 256, 3, 3), float32], %v_param_518: Tensor[(256), float32], %v_param_519: Tensor[(256), float32], %v_param_520: Tensor[(256), float32], %v_param_521: Tensor[(256), float32], %v_param_522: Tensor[(256), float32], %v_param_523: Tensor[(1024, 256, 1, 1), float32], %v_param_524: Tensor[(1024), float32], %v_param_525: Tensor[(1024), float32], %v_param_526: Tensor[(1024), float32], %v_param_527: Tensor[(1024), float32], %v_param_528: Tensor[(1024), float32], %v_param_529: Tensor[(256, 1024, 1, 1), float32], %v_param_530: Tensor[(256), float32], %v_param_531: Tensor[(256), float32], %v_param_532: Tensor[(256), float32], %v_param_533: Tensor[(256), float32], %v_param_534: Tensor[(256), float32], %v_param_535: Tensor[(256, 256, 3, 3), float32], %v_param_536: Tensor[(256), float32], %v_param_537: Tensor[(256), float32], %v_param_538: Tensor[(256), float32], %v_param_539: Tensor[(256), float32], %v_param_540: Tensor[(256), float32], %v_param_541: Tensor[(1024, 256, 1, 1), float32], %v_param_542: Tensor[(1024), float32], %v_param_543: Tensor[(1024), float32], %v_param_544: Tensor[(1024), float32], %v_param_545: Tensor[(1024), float32], %v_param_546: Tensor[(1024), float32], %v_param_547: Tensor[(256, 1024, 1, 1), float32], %v_param_548: Tensor[(256), float32], %v_param_549: Tensor[(256), float32], %v_param_550: Tensor[(256), float32], %v_param_551: Tensor[(256), float32], %v_param_552: Tensor[(256), float32], %v_param_553: Tensor[(256, 256, 3, 3), float32], %v_param_554: Tensor[(256), float32], %v_param_555: Tensor[(256), float32], %v_param_556: Tensor[(256), float32], %v_param_557: Tensor[(256), float32], %v_param_558: Tensor[(256), float32], %v_param_559: Tensor[(1024, 256, 1, 1), float32], %v_param_560: Tensor[(1024), float32], %v_param_561: Tensor[(1024), float32], %v_param_562: Tensor[(1024), float32], %v_param_563: Tensor[(1024), float32], %v_param_564: Tensor[(1024), float32], %v_param_565: Tensor[(256, 1024, 1, 1), float32], %v_param_566: Tensor[(256), float32], %v_param_567: Tensor[(256), float32], %v_param_568: Tensor[(256), float32], %v_param_569: Tensor[(256), float32], %v_param_570: Tensor[(256), float32], %v_param_571: Tensor[(256, 256, 3, 3), float32], %v_param_572: Tensor[(256), float32], %v_param_573: Tensor[(256), float32], %v_param_574: Tensor[(256), float32], %v_param_575: Tensor[(256), float32], %v_param_576: Tensor[(256), float32], %v_param_577: Tensor[(1024, 256, 1, 1), float32], %v_param_578: Tensor[(1024), float32], %v_param_579: Tensor[(1024), float32], %v_param_580: Tensor[(1024), float32], %v_param_581: Tensor[(1024), float32], %v_param_582: Tensor[(1024), float32], %v_param_583: Tensor[(256, 1024, 1, 1), float32], %v_param_584: Tensor[(256), float32], %v_param_585: Tensor[(256), float32], %v_param_586: Tensor[(256), float32], %v_param_587: Tensor[(256), float32], %v_param_588: Tensor[(256), float32], %v_param_589: Tensor[(256, 256, 3, 3), float32], %v_param_590: Tensor[(256), float32], %v_param_591: Tensor[(256), float32], %v_param_592: Tensor[(256), float32], %v_param_593: Tensor[(256), float32], %v_param_594: Tensor[(256), float32], %v_param_595: Tensor[(1024, 256, 1, 1), float32], %v_param_596: Tensor[(1024), float32], %v_param_597: Tensor[(1024), float32], %v_param_598: Tensor[(1024), float32], %v_param_599: Tensor[(1024), float32], %v_param_600: Tensor[(1024), float32], %v_param_601: Tensor[(256, 1024, 1, 1), float32], %v_param_602: Tensor[(256), float32], %v_param_603: Tensor[(256), float32], %v_param_604: Tensor[(256), float32], %v_param_605: Tensor[(256), float32], %v_param_606: Tensor[(256), float32], %v_param_607: Tensor[(256, 256, 3, 3), float32], %v_param_608: Tensor[(256), float32], %v_param_609: Tensor[(256), float32], %v_param_610: Tensor[(256), float32], %v_param_611: Tensor[(256), float32], %v_param_612: Tensor[(256), float32], %v_param_613: Tensor[(1024, 256, 1, 1), float32], %v_param_614: Tensor[(1024), float32], %v_param_615: Tensor[(1024), float32], %v_param_616: Tensor[(1024), float32], %v_param_617: Tensor[(1024), float32], %v_param_618: Tensor[(1024), float32], %v_param_619: Tensor[(256, 1024, 1, 1), float32], %v_param_620: Tensor[(256), float32], %v_param_621: Tensor[(256), float32], %v_param_622: Tensor[(256), float32], %v_param_623: Tensor[(256), float32], %v_param_624: Tensor[(256), float32], %v_param_625: Tensor[(256, 256, 3, 3), float32], %v_param_626: Tensor[(256), float32], %v_param_627: Tensor[(256), float32], %v_param_628: Tensor[(256), float32], %v_param_629: Tensor[(256), float32], %v_param_630: Tensor[(256), float32], %v_param_631: Tensor[(1024, 256, 1, 1), float32], %v_param_632: Tensor[(1024), float32], %v_param_633: Tensor[(1024), float32], %v_param_634: Tensor[(1024), float32], %v_param_635: Tensor[(1024), float32], %v_param_636: Tensor[(1024), float32], %v_param_637: Tensor[(256, 1024, 1, 1), float32], %v_param_638: Tensor[(256), float32], %v_param_639: Tensor[(256), float32], %v_param_640: Tensor[(256), float32], %v_param_641: Tensor[(256), float32], %v_param_642: Tensor[(256), float32], %v_param_643: Tensor[(256, 256, 3, 3), float32], %v_param_644: Tensor[(256), float32], %v_param_645: Tensor[(256), float32], %v_param_646: Tensor[(256), float32], %v_param_647: Tensor[(256), float32], %v_param_648: Tensor[(256), float32], %v_param_649: Tensor[(1024, 256, 1, 1), float32], %v_param_650: Tensor[(1024), float32], %v_param_651: Tensor[(1024), float32], %v_param_652: Tensor[(1024), float32], %v_param_653: Tensor[(1024), float32], %v_param_654: Tensor[(1024), float32], %v_param_655: Tensor[(256, 1024, 1, 1), float32], %v_param_656: Tensor[(256), float32], %v_param_657: Tensor[(256), float32], %v_param_658: Tensor[(256), float32], %v_param_659: Tensor[(256), float32], %v_param_660: Tensor[(256), float32], %v_param_661: Tensor[(256, 256, 3, 3), float32], %v_param_662: Tensor[(256), float32], %v_param_663: Tensor[(256), float32], %v_param_664: Tensor[(256), float32], %v_param_665: Tensor[(256), float32], %v_param_666: Tensor[(256), float32], %v_param_667: Tensor[(1024, 256, 1, 1), float32], %v_param_668: Tensor[(1024), float32], %v_param_669: Tensor[(1024), float32], %v_param_670: Tensor[(1024), float32], %v_param_671: Tensor[(1024), float32], %v_param_672: Tensor[(1024), float32], %v_param_673: Tensor[(256, 1024, 1, 1), float32], %v_param_674: Tensor[(256), float32], %v_param_675: Tensor[(256), float32], %v_param_676: Tensor[(256), float32], %v_param_677: Tensor[(256), float32], %v_param_678: Tensor[(256), float32], %v_param_679: Tensor[(256, 256, 3, 3), float32], %v_param_680: Tensor[(256), float32], %v_param_681: Tensor[(256), float32], %v_param_682: Tensor[(256), float32], %v_param_683: Tensor[(256), float32], %v_param_684: Tensor[(256), float32], %v_param_685: Tensor[(1024, 256, 1, 1), float32], %v_param_686: Tensor[(1024), float32], %v_param_687: Tensor[(1024), float32], %v_param_688: Tensor[(1024), float32], %v_param_689: Tensor[(1024), float32], %v_param_690: Tensor[(1024), float32], %v_param_691: Tensor[(256, 1024, 1, 1), float32], %v_param_692: Tensor[(256), float32], %v_param_693: Tensor[(256), float32], %v_param_694: Tensor[(256), float32], %v_param_695: Tensor[(256), float32], %v_param_696: Tensor[(256), float32], %v_param_697: Tensor[(256, 256, 3, 3), float32], %v_param_698: Tensor[(256), float32], %v_param_699: Tensor[(256), float32], %v_param_700: Tensor[(256), float32], %v_param_701: Tensor[(256), float32], %v_param_702: Tensor[(256), float32], %v_param_703: Tensor[(1024, 256, 1, 1), float32], %v_param_704: Tensor[(1024), float32], %v_param_705: Tensor[(1024), float32], %v_param_706: Tensor[(1024), float32], %v_param_707: Tensor[(1024), float32], %v_param_708: Tensor[(1024), float32], %v_param_709: Tensor[(256, 1024, 1, 1), float32], %v_param_710: Tensor[(256), float32], %v_param_711: Tensor[(256), float32], %v_param_712: Tensor[(256), float32], %v_param_713: Tensor[(256), float32], %v_param_714: Tensor[(256), float32], %v_param_715: Tensor[(256, 256, 3, 3), float32], %v_param_716: Tensor[(256), float32], %v_param_717: Tensor[(256), float32], %v_param_718: Tensor[(256), float32], %v_param_719: Tensor[(256), float32], %v_param_720: Tensor[(256), float32], %v_param_721: Tensor[(1024, 256, 1, 1), float32], %v_param_722: Tensor[(1024), float32], %v_param_723: Tensor[(1024), float32], %v_param_724: Tensor[(1024), float32], %v_param_725: Tensor[(1024), float32], %v_param_726: Tensor[(1024), float32], %v_param_727: Tensor[(256, 1024, 1, 1), float32], %v_param_728: Tensor[(256), float32], %v_param_729: Tensor[(256), float32], %v_param_730: Tensor[(256), float32], %v_param_731: Tensor[(256), float32], %v_param_732: Tensor[(256), float32], %v_param_733: Tensor[(256, 256, 3, 3), float32], %v_param_734: Tensor[(256), float32], %v_param_735: Tensor[(256), float32], %v_param_736: Tensor[(256), float32], %v_param_737: Tensor[(256), float32], %v_param_738: Tensor[(256), float32], %v_param_739: Tensor[(1024, 256, 1, 1), float32], %v_param_740: Tensor[(1024), float32], %v_param_741: Tensor[(1024), float32], %v_param_742: Tensor[(1024), float32], %v_param_743: Tensor[(1024), float32], %v_param_744: Tensor[(1024), float32], %v_param_745: Tensor[(256, 1024, 1, 1), float32], %v_param_746: Tensor[(256), float32], %v_param_747: Tensor[(256), float32], %v_param_748: Tensor[(256), float32], %v_param_749: Tensor[(256), float32], %v_param_750: Tensor[(256), float32], %v_param_751: Tensor[(256, 256, 3, 3), float32], %v_param_752: Tensor[(256), float32], %v_param_753: Tensor[(256), float32], %v_param_754: Tensor[(256), float32], %v_param_755: Tensor[(256), float32], %v_param_756: Tensor[(256), float32], %v_param_757: Tensor[(1024, 256, 1, 1), float32], %v_param_758: Tensor[(1024), float32], %v_param_759: Tensor[(1024), float32], %v_param_760: Tensor[(1024), float32], %v_param_761: Tensor[(1024), float32], %v_param_762: Tensor[(1024), float32], %v_param_763: Tensor[(256, 1024, 1, 1), float32], %v_param_764: Tensor[(256), float32], %v_param_765: Tensor[(256), float32], %v_param_766: Tensor[(256), float32], %v_param_767: Tensor[(256), float32], %v_param_768: Tensor[(256), float32], %v_param_769: Tensor[(256, 256, 3, 3), float32], %v_param_770: Tensor[(256), float32], %v_param_771: Tensor[(256), float32], %v_param_772: Tensor[(256), float32], %v_param_773: Tensor[(256), float32], %v_param_774: Tensor[(256), float32], %v_param_775: Tensor[(1024, 256, 1, 1), float32], %v_param_776: Tensor[(1024), float32], %v_param_777: Tensor[(1024), float32], %v_param_778: Tensor[(1024), float32], %v_param_779: Tensor[(1024), float32], %v_param_780: Tensor[(1024), float32], %v_param_781: Tensor[(256, 1024, 1, 1), float32], %v_param_782: Tensor[(256), float32], %v_param_783: Tensor[(256), float32], %v_param_784: Tensor[(256), float32], %v_param_785: Tensor[(256), float32], %v_param_786: Tensor[(256), float32], %v_param_787: Tensor[(256, 256, 3, 3), float32], %v_param_788: Tensor[(256), float32], %v_param_789: Tensor[(256), float32], %v_param_790: Tensor[(256), float32], %v_param_791: Tensor[(256), float32], %v_param_792: Tensor[(256), float32], %v_param_793: Tensor[(1024, 256, 1, 1), float32], %v_param_794: Tensor[(1024), float32], %v_param_795: Tensor[(1024), float32], %v_param_796: Tensor[(1024), float32], %v_param_797: Tensor[(1024), float32], %v_param_798: Tensor[(1024), float32], %v_param_799: Tensor[(256, 1024, 1, 1), float32], %v_param_800: Tensor[(256), float32], %v_param_801: Tensor[(256), float32], %v_param_802: Tensor[(256), float32], %v_param_803: Tensor[(256), float32], %v_param_804: Tensor[(256), float32], %v_param_805: Tensor[(256, 256, 3, 3), float32], %v_param_806: Tensor[(256), float32], %v_param_807: Tensor[(256), float32], %v_param_808: Tensor[(256), float32], %v_param_809: Tensor[(256), float32], %v_param_810: Tensor[(256), float32], %v_param_811: Tensor[(1024, 256, 1, 1), float32], %v_param_812: Tensor[(1024), float32], %v_param_813: Tensor[(1024), float32], %v_param_814: Tensor[(1024), float32], %v_param_815: Tensor[(1024), float32], %v_param_816: Tensor[(1024), float32], %v_param_817: Tensor[(256, 1024, 1, 1), float32], %v_param_818: Tensor[(256), float32], %v_param_819: Tensor[(256), float32], %v_param_820: Tensor[(256), float32], %v_param_821: Tensor[(256), float32], %v_param_822: Tensor[(256), float32], %v_param_823: Tensor[(256, 256, 3, 3), float32], %v_param_824: Tensor[(256), float32], %v_param_825: Tensor[(256), float32], %v_param_826: Tensor[(256), float32], %v_param_827: Tensor[(256), float32], %v_param_828: Tensor[(256), float32], %v_param_829: Tensor[(1024, 256, 1, 1), float32], %v_param_830: Tensor[(1024), float32], %v_param_831: Tensor[(1024), float32], %v_param_832: Tensor[(1024), float32], %v_param_833: Tensor[(1024), float32], %v_param_834: Tensor[(1024), float32], %v_param_835: Tensor[(256, 1024, 1, 1), float32], %v_param_836: Tensor[(256), float32], %v_param_837: Tensor[(256), float32], %v_param_838: Tensor[(256), float32], %v_param_839: Tensor[(256), float32], %v_param_840: Tensor[(256), float32], %v_param_841: Tensor[(256, 256, 3, 3), float32], %v_param_842: Tensor[(256), float32], %v_param_843: Tensor[(256), float32], %v_param_844: Tensor[(256), float32], %v_param_845: Tensor[(256), float32], %v_param_846: Tensor[(256), float32], %v_param_847: Tensor[(1024, 256, 1, 1), float32], %v_param_848: Tensor[(1024), float32], %v_param_849: Tensor[(1024), float32], %v_param_850: Tensor[(1024), float32], %v_param_851: Tensor[(1024), float32], %v_param_852: Tensor[(1024), float32], %v_param_853: Tensor[(256, 1024, 1, 1), float32], %v_param_854: Tensor[(256), float32], %v_param_855: Tensor[(256), float32], %v_param_856: Tensor[(256), float32], %v_param_857: Tensor[(256), float32], %v_param_858: Tensor[(256), float32], %v_param_859: Tensor[(256, 256, 3, 3), float32], %v_param_860: Tensor[(256), float32], %v_param_861: Tensor[(256), float32], %v_param_862: Tensor[(256), float32], %v_param_863: Tensor[(256), float32], %v_param_864: Tensor[(256), float32], %v_param_865: Tensor[(1024, 256, 1, 1), float32], %v_param_866: Tensor[(1024), float32], %v_param_867: Tensor[(1024), float32], %v_param_868: Tensor[(1024), float32], %v_param_869: Tensor[(1024), float32], %v_param_870: Tensor[(1024), float32], %v_param_883: Tensor[(2048, 1024, 1, 1), float32], %v_param_884: Tensor[(2048), float32], %v_param_887: Tensor[(2048), float32], %v_param_888: Tensor[(2048), float32], %v_param_889: Tensor[(2048), float32], %v_param_890: Tensor[(2048), float32], %v_param_871: Tensor[(512, 1024, 1, 1), float32], %v_param_872: Tensor[(512), float32], %v_param_873: Tensor[(512), float32], %v_param_874: Tensor[(512), float32], %v_param_875: Tensor[(512), float32], %v_param_876: Tensor[(512), float32], %v_param_877: Tensor[(512, 512, 3, 3), float32], %v_param_878: Tensor[(512), float32], %v_param_879: Tensor[(512), float32], %v_param_880: Tensor[(512), float32], %v_param_881: Tensor[(512), float32], %v_param_882: Tensor[(512), float32], %v_param_885: Tensor[(2048, 512, 1, 1), float32], %v_param_886: Tensor[(2048), float32], %v_param_891: Tensor[(2048), float32], %v_param_892: Tensor[(2048), float32], %v_param_893: Tensor[(2048), float32], %v_param_894: Tensor[(2048), float32], %v_param_895: Tensor[(512, 2048, 1, 1), float32], %v_param_896: Tensor[(512), float32], %v_param_897: Tensor[(512), float32], %v_param_898: Tensor[(512), float32], %v_param_899: Tensor[(512), float32], %v_param_900: Tensor[(512), float32], %v_param_901: Tensor[(512, 512, 3, 3), float32], %v_param_902: Tensor[(512), float32], %v_param_903: Tensor[(512), float32], %v_param_904: Tensor[(512), float32], %v_param_905: Tensor[(512), float32], %v_param_906: Tensor[(512), float32], %v_param_907: Tensor[(2048, 512, 1, 1), float32], %v_param_908: Tensor[(2048), float32], %v_param_909: Tensor[(2048), float32], %v_param_910: Tensor[(2048), float32], %v_param_911: Tensor[(2048), float32], %v_param_912: Tensor[(2048), float32], %v_param_913: Tensor[(512, 2048, 1, 1), float32], %v_param_914: Tensor[(512), float32], %v_param_915: Tensor[(512), float32], %v_param_916: Tensor[(512), float32], %v_param_917: Tensor[(512), float32], %v_param_918: Tensor[(512), float32], %v_param_919: Tensor[(512, 512, 3, 3), float32], %v_param_920: Tensor[(512), float32], %v_param_921: Tensor[(512), float32], %v_param_922: Tensor[(512), float32], %v_param_923: Tensor[(512), float32], %v_param_924: Tensor[(512), float32], %v_param_925: Tensor[(2048, 512, 1, 1), float32], %v_param_926: Tensor[(2048), float32], %v_param_927: Tensor[(2048), float32], %v_param_928: Tensor[(2048), float32], %v_param_929: Tensor[(2048), float32], %v_param_930: Tensor[(2048), float32], %v_param_931: Tensor[(1000, 2048), float32], %v_param_932: Tensor[(1000), float32]) {\n",
       "  %0 = nn.pad(%input_1, 0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);\n",
       "  %1 = nn.conv2d(%0, %v_param_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7]);\n",
       "  %2 = nn.bias_add(%1, %v_param_2);\n",
       "  %3 = nn.batch_norm(%2, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=1.001e-05f);\n",
       "  %4 = %3.0;\n",
       "  %5 = nn.relu(%4);\n",
       "  %6 = nn.pad(%5, 0, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);\n",
       "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %8 = nn.conv2d(%7, %v_param_19, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %9 = nn.bias_add(%8, %v_param_20);\n",
       "  %10 = nn.batch_norm(%9, %v_param_23, %v_param_24, %v_param_25, %v_param_26, epsilon=1.001e-05f);\n",
       "  %11 = nn.conv2d(%7, %v_param_7, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %12 = nn.bias_add(%11, %v_param_8);\n",
       "  %13 = nn.batch_norm(%12, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=1.001e-05f);\n",
       "  %14 = %13.0;\n",
       "  %15 = nn.relu(%14);\n",
       "  %16 = nn.conv2d(%15, %v_param_13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %17 = nn.bias_add(%16, %v_param_14);\n",
       "  %18 = nn.batch_norm(%17, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=1.001e-05f);\n",
       "  %19 = %18.0;\n",
       "  %20 = nn.relu(%19);\n",
       "  %21 = nn.conv2d(%20, %v_param_21, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %22 = nn.bias_add(%21, %v_param_22);\n",
       "  %23 = nn.batch_norm(%22, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=1.001e-05f);\n",
       "  %24 = %10.0;\n",
       "  %25 = %23.0;\n",
       "  %26 = add(%24, %25);\n",
       "  %27 = nn.relu(%26);\n",
       "  %28 = nn.conv2d(%27, %v_param_31, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %29 = nn.bias_add(%28, %v_param_32);\n",
       "  %30 = nn.batch_norm(%29, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=1.001e-05f);\n",
       "  %31 = %30.0;\n",
       "  %32 = nn.relu(%31);\n",
       "  %33 = nn.conv2d(%32, %v_param_37, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %34 = nn.bias_add(%33, %v_param_38);\n",
       "  %35 = nn.batch_norm(%34, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=1.001e-05f);\n",
       "  %36 = %35.0;\n",
       "  %37 = nn.relu(%36);\n",
       "  %38 = nn.conv2d(%37, %v_param_43, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %39 = nn.bias_add(%38, %v_param_44);\n",
       "  %40 = nn.batch_norm(%39, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=1.001e-05f);\n",
       "  %41 = %40.0;\n",
       "  %42 = add(%27, %41);\n",
       "  %43 = nn.relu(%42);\n",
       "  %44 = nn.conv2d(%43, %v_param_49, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
       "  %45 = nn.bias_add(%44, %v_param_50);\n",
       "  %46 = nn.batch_norm(%45, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=1.001e-05f);\n",
       "  %47 = %46.0;\n",
       "  %48 = nn.relu(%47);\n",
       "  %49 = nn.conv2d(%48, %v_param_55, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %50 = nn.bias_add(%49, %v_param_56);\n",
       "  %51 = nn.batch_norm(%50, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=1.001e-05f);\n",
       "  %52 = %51.0;\n",
       "  %53 = nn.relu(%52);\n",
       "  %54 = nn.conv2d(%53, %v_param_61, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %55 = nn.bias_add(%54, %v_param_62);\n",
       "  %56 = nn.batch_norm(%55, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=1.001e-05f);\n",
       "  %57 = %56.0;\n",
       "  %58 = add(%43, %57);\n",
       "  %59 = nn.relu(%58);\n",
       "  %60 = nn.conv2d(%59, %v_param_79, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %61 = nn.bias_add(%60, %v_param_80);\n",
       "  %62 = nn.batch_norm(%61, %v_param_83, %v_param_84, %v_param_85, %v_param_86, epsilon=1.001e-05f);\n",
       "  %63 = nn.conv2d(%59, %v_param_67, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %64 = nn.bias_add(%63, %v_param_68);\n",
       "  %65 = nn.batch_norm(%64, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=1.001e-05f);\n",
       "  %66 = %65.0;\n",
       "  %67 = nn.relu(%66);\n",
       "  %68 = nn.conv2d(%67, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %69 = nn.bias_add(%68, %v_param_74);\n",
       "  %70 = nn.batch_norm(%69, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=1.001e-05f);\n",
       "  %71 = %70.0;\n",
       "  %72 = nn.relu(%71);\n",
       "  %73 = nn.conv2d(%72, %v_param_81, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %74 = nn.bias_add(%73, %v_param_82);\n",
       "  %75 = nn.batch_norm(%74, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=1.001e-05f);\n",
       "  %76 = %62.0;\n",
       "  %77 = %75.0;\n",
       "  %78 = add(%76, %77);\n",
       "  %79 = nn.relu(%78);\n",
       "  %80 = nn.conv2d(%79, %v_param_91, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %81 = nn.bias_add(%80, %v_param_92);\n",
       "  %82 = nn.batch_norm(%81, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=1.001e-05f);\n",
       "  %83 = %82.0;\n",
       "  %84 = nn.relu(%83);\n",
       "  %85 = nn.conv2d(%84, %v_param_97, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %86 = nn.bias_add(%85, %v_param_98);\n",
       "  %87 = nn.batch_norm(%86, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=1.001e-05f);\n",
       "  %88 = %87.0;\n",
       "  %89 = nn.relu(%88);\n",
       "  %90 = nn.conv2d(%89, %v_param_103, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %91 = nn.bias_add(%90, %v_param_104);\n",
       "  %92 = nn.batch_norm(%91, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=1.001e-05f);\n",
       "  %93 = %92.0;\n",
       "  %94 = add(%79, %93);\n",
       "  %95 = nn.relu(%94);\n",
       "  %96 = nn.conv2d(%95, %v_param_109, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %97 = nn.bias_add(%96, %v_param_110);\n",
       "  %98 = nn.batch_norm(%97, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=1.001e-05f);\n",
       "  %99 = %98.0;\n",
       "  %100 = nn.relu(%99);\n",
       "  %101 = nn.conv2d(%100, %v_param_115, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %102 = nn.bias_add(%101, %v_param_116);\n",
       "  %103 = nn.batch_norm(%102, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=1.001e-05f);\n",
       "  %104 = %103.0;\n",
       "  %105 = nn.relu(%104);\n",
       "  %106 = nn.conv2d(%105, %v_param_121, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %107 = nn.bias_add(%106, %v_param_122);\n",
       "  %108 = nn.batch_norm(%107, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=1.001e-05f);\n",
       "  %109 = %108.0;\n",
       "  %110 = add(%95, %109);\n",
       "  %111 = nn.relu(%110);\n",
       "  %112 = nn.conv2d(%111, %v_param_127, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %113 = nn.bias_add(%112, %v_param_128);\n",
       "  %114 = nn.batch_norm(%113, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=1.001e-05f);\n",
       "  %115 = %114.0;\n",
       "  %116 = nn.relu(%115);\n",
       "  %117 = nn.conv2d(%116, %v_param_133, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %118 = nn.bias_add(%117, %v_param_134);\n",
       "  %119 = nn.batch_norm(%118, %v_param_135, %v_param_136, %v_param_137, %v_param_138, epsilon=1.001e-05f);\n",
       "  %120 = %119.0;\n",
       "  %121 = nn.relu(%120);\n",
       "  %122 = nn.conv2d(%121, %v_param_139, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %123 = nn.bias_add(%122, %v_param_140);\n",
       "  %124 = nn.batch_norm(%123, %v_param_141, %v_param_142, %v_param_143, %v_param_144, epsilon=1.001e-05f);\n",
       "  %125 = %124.0;\n",
       "  %126 = add(%111, %125);\n",
       "  %127 = nn.relu(%126);\n",
       "  %128 = nn.conv2d(%127, %v_param_145, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %129 = nn.bias_add(%128, %v_param_146);\n",
       "  %130 = nn.batch_norm(%129, %v_param_147, %v_param_148, %v_param_149, %v_param_150, epsilon=1.001e-05f);\n",
       "  %131 = %130.0;\n",
       "  %132 = nn.relu(%131);\n",
       "  %133 = nn.conv2d(%132, %v_param_151, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %134 = nn.bias_add(%133, %v_param_152);\n",
       "  %135 = nn.batch_norm(%134, %v_param_153, %v_param_154, %v_param_155, %v_param_156, epsilon=1.001e-05f);\n",
       "  %136 = %135.0;\n",
       "  %137 = nn.relu(%136);\n",
       "  %138 = nn.conv2d(%137, %v_param_157, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %139 = nn.bias_add(%138, %v_param_158);\n",
       "  %140 = nn.batch_norm(%139, %v_param_159, %v_param_160, %v_param_161, %v_param_162, epsilon=1.001e-05f);\n",
       "  %141 = %140.0;\n",
       "  %142 = add(%127, %141);\n",
       "  %143 = nn.relu(%142);\n",
       "  %144 = nn.conv2d(%143, %v_param_163, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %145 = nn.bias_add(%144, %v_param_164);\n",
       "  %146 = nn.batch_norm(%145, %v_param_165, %v_param_166, %v_param_167, %v_param_168, epsilon=1.001e-05f);\n",
       "  %147 = %146.0;\n",
       "  %148 = nn.relu(%147);\n",
       "  %149 = nn.conv2d(%148, %v_param_169, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %150 = nn.bias_add(%149, %v_param_170);\n",
       "  %151 = nn.batch_norm(%150, %v_param_171, %v_param_172, %v_param_173, %v_param_174, epsilon=1.001e-05f);\n",
       "  %152 = %151.0;\n",
       "  %153 = nn.relu(%152);\n",
       "  %154 = nn.conv2d(%153, %v_param_175, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %155 = nn.bias_add(%154, %v_param_176);\n",
       "  %156 = nn.batch_norm(%155, %v_param_177, %v_param_178, %v_param_179, %v_param_180, epsilon=1.001e-05f);\n",
       "  %157 = %156.0;\n",
       "  %158 = add(%143, %157);\n",
       "  %159 = nn.relu(%158);\n",
       "  %160 = nn.conv2d(%159, %v_param_181, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %161 = nn.bias_add(%160, %v_param_182);\n",
       "  %162 = nn.batch_norm(%161, %v_param_183, %v_param_184, %v_param_185, %v_param_186, epsilon=1.001e-05f);\n",
       "  %163 = %162.0;\n",
       "  %164 = nn.relu(%163);\n",
       "  %165 = nn.conv2d(%164, %v_param_187, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %166 = nn.bias_add(%165, %v_param_188);\n",
       "  %167 = nn.batch_norm(%166, %v_param_189, %v_param_190, %v_param_191, %v_param_192, epsilon=1.001e-05f);\n",
       "  %168 = %167.0;\n",
       "  %169 = nn.relu(%168);\n",
       "  %170 = nn.conv2d(%169, %v_param_193, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %171 = nn.bias_add(%170, %v_param_194);\n",
       "  %172 = nn.batch_norm(%171, %v_param_195, %v_param_196, %v_param_197, %v_param_198, epsilon=1.001e-05f);\n",
       "  %173 = %172.0;\n",
       "  %174 = add(%159, %173);\n",
       "  %175 = nn.relu(%174);\n",
       "  %176 = nn.conv2d(%175, %v_param_199, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
       "  %177 = nn.bias_add(%176, %v_param_200);\n",
       "  %178 = nn.batch_norm(%177, %v_param_201, %v_param_202, %v_param_203, %v_param_204, epsilon=1.001e-05f);\n",
       "  %179 = %178.0;\n",
       "  %180 = nn.relu(%179);\n",
       "  %181 = nn.conv2d(%180, %v_param_205, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %182 = nn.bias_add(%181, %v_param_206);\n",
       "  %183 = nn.batch_norm(%182, %v_param_207, %v_param_208, %v_param_209, %v_param_210, epsilon=1.001e-05f);\n",
       "  %184 = %183.0;\n",
       "  %185 = nn.relu(%184);\n",
       "  %186 = nn.conv2d(%185, %v_param_211, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %187 = nn.bias_add(%186, %v_param_212);\n",
       "  %188 = nn.batch_norm(%187, %v_param_213, %v_param_214, %v_param_215, %v_param_216, epsilon=1.001e-05f);\n",
       "  %189 = %188.0;\n",
       "  %190 = add(%175, %189);\n",
       "  %191 = nn.relu(%190);\n",
       "  %192 = nn.conv2d(%191, %v_param_229, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %193 = nn.bias_add(%192, %v_param_230);\n",
       "  %194 = nn.batch_norm(%193, %v_param_233, %v_param_234, %v_param_235, %v_param_236, epsilon=1.001e-05f);\n",
       "  %195 = nn.conv2d(%191, %v_param_217, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %196 = nn.bias_add(%195, %v_param_218);\n",
       "  %197 = nn.batch_norm(%196, %v_param_219, %v_param_220, %v_param_221, %v_param_222, epsilon=1.001e-05f);\n",
       "  %198 = %197.0;\n",
       "  %199 = nn.relu(%198);\n",
       "  %200 = nn.conv2d(%199, %v_param_223, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %201 = nn.bias_add(%200, %v_param_224);\n",
       "  %202 = nn.batch_norm(%201, %v_param_225, %v_param_226, %v_param_227, %v_param_228, epsilon=1.001e-05f);\n",
       "  %203 = %202.0;\n",
       "  %204 = nn.relu(%203);\n",
       "  %205 = nn.conv2d(%204, %v_param_231, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %206 = nn.bias_add(%205, %v_param_232);\n",
       "  %207 = nn.batch_norm(%206, %v_param_237, %v_param_238, %v_param_239, %v_param_240, epsilon=1.001e-05f);\n",
       "  %208 = %194.0;\n",
       "  %209 = %207.0;\n",
       "  %210 = add(%208, %209);\n",
       "  %211 = nn.relu(%210);\n",
       "  %212 = nn.conv2d(%211, %v_param_241, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %213 = nn.bias_add(%212, %v_param_242);\n",
       "  %214 = nn.batch_norm(%213, %v_param_243, %v_param_244, %v_param_245, %v_param_246, epsilon=1.001e-05f);\n",
       "  %215 = %214.0;\n",
       "  %216 = nn.relu(%215);\n",
       "  %217 = nn.conv2d(%216, %v_param_247, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %218 = nn.bias_add(%217, %v_param_248);\n",
       "  %219 = nn.batch_norm(%218, %v_param_249, %v_param_250, %v_param_251, %v_param_252, epsilon=1.001e-05f);\n",
       "  %220 = %219.0;\n",
       "  %221 = nn.relu(%220);\n",
       "  %222 = nn.conv2d(%221, %v_param_253, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %223 = nn.bias_add(%222, %v_param_254);\n",
       "  %224 = nn.batch_norm(%223, %v_param_255, %v_param_256, %v_param_257, %v_param_258, epsilon=1.001e-05f);\n",
       "  %225 = %224.0;\n",
       "  %226 = add(%211, %225);\n",
       "  %227 = nn.relu(%226);\n",
       "  %228 = nn.conv2d(%227, %v_param_259, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %229 = nn.bias_add(%228, %v_param_260);\n",
       "  %230 = nn.batch_norm(%229, %v_param_261, %v_param_262, %v_param_263, %v_param_264, epsilon=1.001e-05f);\n",
       "  %231 = %230.0;\n",
       "  %232 = nn.relu(%231);\n",
       "  %233 = nn.conv2d(%232, %v_param_265, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %234 = nn.bias_add(%233, %v_param_266);\n",
       "  %235 = nn.batch_norm(%234, %v_param_267, %v_param_268, %v_param_269, %v_param_270, epsilon=1.001e-05f);\n",
       "  %236 = %235.0;\n",
       "  %237 = nn.relu(%236);\n",
       "  %238 = nn.conv2d(%237, %v_param_271, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %239 = nn.bias_add(%238, %v_param_272);\n",
       "  %240 = nn.batch_norm(%239, %v_param_273, %v_param_274, %v_param_275, %v_param_276, epsilon=1.001e-05f);\n",
       "  %241 = %240.0;\n",
       "  %242 = add(%227, %241);\n",
       "  %243 = nn.relu(%242);\n",
       "  %244 = nn.conv2d(%243, %v_param_277, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %245 = nn.bias_add(%244, %v_param_278);\n",
       "  %246 = nn.batch_norm(%245, %v_param_279, %v_param_280, %v_param_281, %v_param_282, epsilon=1.001e-05f);\n",
       "  %247 = %246.0;\n",
       "  %248 = nn.relu(%247);\n",
       "  %249 = nn.conv2d(%248, %v_param_283, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %250 = nn.bias_add(%249, %v_param_284);\n",
       "  %251 = nn.batch_norm(%250, %v_param_285, %v_param_286, %v_param_287, %v_param_288, epsilon=1.001e-05f);\n",
       "  %252 = %251.0;\n",
       "  %253 = nn.relu(%252);\n",
       "  %254 = nn.conv2d(%253, %v_param_289, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %255 = nn.bias_add(%254, %v_param_290);\n",
       "  %256 = nn.batch_norm(%255, %v_param_291, %v_param_292, %v_param_293, %v_param_294, epsilon=1.001e-05f);\n",
       "  %257 = %256.0;\n",
       "  %258 = add(%243, %257);\n",
       "  %259 = nn.relu(%258);\n",
       "  %260 = nn.conv2d(%259, %v_param_295, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %261 = nn.bias_add(%260, %v_param_296);\n",
       "  %262 = nn.batch_norm(%261, %v_param_297, %v_param_298, %v_param_299, %v_param_300, epsilon=1.001e-05f);\n",
       "  %263 = %262.0;\n",
       "  %264 = nn.relu(%263);\n",
       "  %265 = nn.conv2d(%264, %v_param_301, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %266 = nn.bias_add(%265, %v_param_302);\n",
       "  %267 = nn.batch_norm(%266, %v_param_303, %v_param_304, %v_param_305, %v_param_306, epsilon=1.001e-05f);\n",
       "  %268 = %267.0;\n",
       "  %269 = nn.relu(%268);\n",
       "  %270 = nn.conv2d(%269, %v_param_307, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %271 = nn.bias_add(%270, %v_param_308);\n",
       "  %272 = nn.batch_norm(%271, %v_param_309, %v_param_310, %v_param_311, %v_param_312, epsilon=1.001e-05f);\n",
       "  %273 = %272.0;\n",
       "  %274 = add(%259, %273);\n",
       "  %275 = nn.relu(%274);\n",
       "  %276 = nn.conv2d(%275, %v_param_313, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %277 = nn.bias_add(%276, %v_param_314);\n",
       "  %278 = nn.batch_norm(%277, %v_param_315, %v_param_316, %v_param_317, %v_param_318, epsilon=1.001e-05f);\n",
       "  %279 = %278.0;\n",
       "  %280 = nn.relu(%279);\n",
       "  %281 = nn.conv2d(%280, %v_param_319, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %282 = nn.bias_add(%281, %v_param_320);\n",
       "  %283 = nn.batch_norm(%282, %v_param_321, %v_param_322, %v_param_323, %v_param_324, epsilon=1.001e-05f);\n",
       "  %284 = %283.0;\n",
       "  %285 = nn.relu(%284);\n",
       "  %286 = nn.conv2d(%285, %v_param_325, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %287 = nn.bias_add(%286, %v_param_326);\n",
       "  %288 = nn.batch_norm(%287, %v_param_327, %v_param_328, %v_param_329, %v_param_330, epsilon=1.001e-05f);\n",
       "  %289 = %288.0;\n",
       "  %290 = add(%275, %289);\n",
       "  %291 = nn.relu(%290);\n",
       "  %292 = nn.conv2d(%291, %v_param_331, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %293 = nn.bias_add(%292, %v_param_332);\n",
       "  %294 = nn.batch_norm(%293, %v_param_333, %v_param_334, %v_param_335, %v_param_336, epsilon=1.001e-05f);\n",
       "  %295 = %294.0;\n",
       "  %296 = nn.relu(%295);\n",
       "  %297 = nn.conv2d(%296, %v_param_337, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %298 = nn.bias_add(%297, %v_param_338);\n",
       "  %299 = nn.batch_norm(%298, %v_param_339, %v_param_340, %v_param_341, %v_param_342, epsilon=1.001e-05f);\n",
       "  %300 = %299.0;\n",
       "  %301 = nn.relu(%300);\n",
       "  %302 = nn.conv2d(%301, %v_param_343, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %303 = nn.bias_add(%302, %v_param_344);\n",
       "  %304 = nn.batch_norm(%303, %v_param_345, %v_param_346, %v_param_347, %v_param_348, epsilon=1.001e-05f);\n",
       "  %305 = %304.0;\n",
       "  %306 = add(%291, %305);\n",
       "  %307 = nn.relu(%306);\n",
       "  %308 = nn.conv2d(%307, %v_param_349, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %309 = nn.bias_add(%308, %v_param_350);\n",
       "  %310 = nn.batch_norm(%309, %v_param_351, %v_param_352, %v_param_353, %v_param_354, epsilon=1.001e-05f);\n",
       "  %311 = %310.0;\n",
       "  %312 = nn.relu(%311);\n",
       "  %313 = nn.conv2d(%312, %v_param_355, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %314 = nn.bias_add(%313, %v_param_356);\n",
       "  %315 = nn.batch_norm(%314, %v_param_357, %v_param_358, %v_param_359, %v_param_360, epsilon=1.001e-05f);\n",
       "  %316 = %315.0;\n",
       "  %317 = nn.relu(%316);\n",
       "  %318 = nn.conv2d(%317, %v_param_361, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %319 = nn.bias_add(%318, %v_param_362);\n",
       "  %320 = nn.batch_norm(%319, %v_param_363, %v_param_364, %v_param_365, %v_param_366, epsilon=1.001e-05f);\n",
       "  %321 = %320.0;\n",
       "  %322 = add(%307, %321);\n",
       "  %323 = nn.relu(%322);\n",
       "  %324 = nn.conv2d(%323, %v_param_367, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %325 = nn.bias_add(%324, %v_param_368);\n",
       "  %326 = nn.batch_norm(%325, %v_param_369, %v_param_370, %v_param_371, %v_param_372, epsilon=1.001e-05f);\n",
       "  %327 = %326.0;\n",
       "  %328 = nn.relu(%327);\n",
       "  %329 = nn.conv2d(%328, %v_param_373, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %330 = nn.bias_add(%329, %v_param_374);\n",
       "  %331 = nn.batch_norm(%330, %v_param_375, %v_param_376, %v_param_377, %v_param_378, epsilon=1.001e-05f);\n",
       "  %332 = %331.0;\n",
       "  %333 = nn.relu(%332);\n",
       "  %334 = nn.conv2d(%333, %v_param_379, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %335 = nn.bias_add(%334, %v_param_380);\n",
       "  %336 = nn.batch_norm(%335, %v_param_381, %v_param_382, %v_param_383, %v_param_384, epsilon=1.001e-05f);\n",
       "  %337 = %336.0;\n",
       "  %338 = add(%323, %337);\n",
       "  %339 = nn.relu(%338);\n",
       "  %340 = nn.conv2d(%339, %v_param_385, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %341 = nn.bias_add(%340, %v_param_386);\n",
       "  %342 = nn.batch_norm(%341, %v_param_387, %v_param_388, %v_param_389, %v_param_390, epsilon=1.001e-05f);\n",
       "  %343 = %342.0;\n",
       "  %344 = nn.relu(%343);\n",
       "  %345 = nn.conv2d(%344, %v_param_391, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %346 = nn.bias_add(%345, %v_param_392);\n",
       "  %347 = nn.batch_norm(%346, %v_param_393, %v_param_394, %v_param_395, %v_param_396, epsilon=1.001e-05f);\n",
       "  %348 = %347.0;\n",
       "  %349 = nn.relu(%348);\n",
       "  %350 = nn.conv2d(%349, %v_param_397, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %351 = nn.bias_add(%350, %v_param_398);\n",
       "  %352 = nn.batch_norm(%351, %v_param_399, %v_param_400, %v_param_401, %v_param_402, epsilon=1.001e-05f);\n",
       "  %353 = %352.0;\n",
       "  %354 = add(%339, %353);\n",
       "  %355 = nn.relu(%354);\n",
       "  %356 = nn.conv2d(%355, %v_param_403, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %357 = nn.bias_add(%356, %v_param_404);\n",
       "  %358 = nn.batch_norm(%357, %v_param_405, %v_param_406, %v_param_407, %v_param_408, epsilon=1.001e-05f);\n",
       "  %359 = %358.0;\n",
       "  %360 = nn.relu(%359);\n",
       "  %361 = nn.conv2d(%360, %v_param_409, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %362 = nn.bias_add(%361, %v_param_410);\n",
       "  %363 = nn.batch_norm(%362, %v_param_411, %v_param_412, %v_param_413, %v_param_414, epsilon=1.001e-05f);\n",
       "  %364 = %363.0;\n",
       "  %365 = nn.relu(%364);\n",
       "  %366 = nn.conv2d(%365, %v_param_415, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %367 = nn.bias_add(%366, %v_param_416);\n",
       "  %368 = nn.batch_norm(%367, %v_param_417, %v_param_418, %v_param_419, %v_param_420, epsilon=1.001e-05f);\n",
       "  %369 = %368.0;\n",
       "  %370 = add(%355, %369);\n",
       "  %371 = nn.relu(%370);\n",
       "  %372 = nn.conv2d(%371, %v_param_421, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %373 = nn.bias_add(%372, %v_param_422);\n",
       "  %374 = nn.batch_norm(%373, %v_param_423, %v_param_424, %v_param_425, %v_param_426, epsilon=1.001e-05f);\n",
       "  %375 = %374.0;\n",
       "  %376 = nn.relu(%375);\n",
       "  %377 = nn.conv2d(%376, %v_param_427, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %378 = nn.bias_add(%377, %v_param_428);\n",
       "  %379 = nn.batch_norm(%378, %v_param_429, %v_param_430, %v_param_431, %v_param_432, epsilon=1.001e-05f);\n",
       "  %380 = %379.0;\n",
       "  %381 = nn.relu(%380);\n",
       "  %382 = nn.conv2d(%381, %v_param_433, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %383 = nn.bias_add(%382, %v_param_434);\n",
       "  %384 = nn.batch_norm(%383, %v_param_435, %v_param_436, %v_param_437, %v_param_438, epsilon=1.001e-05f);\n",
       "  %385 = %384.0;\n",
       "  %386 = add(%371, %385);\n",
       "  %387 = nn.relu(%386);\n",
       "  %388 = nn.conv2d(%387, %v_param_439, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %389 = nn.bias_add(%388, %v_param_440);\n",
       "  %390 = nn.batch_norm(%389, %v_param_441, %v_param_442, %v_param_443, %v_param_444, epsilon=1.001e-05f);\n",
       "  %391 = %390.0;\n",
       "  %392 = nn.relu(%391);\n",
       "  %393 = nn.conv2d(%392, %v_param_445, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %394 = nn.bias_add(%393, %v_param_446);\n",
       "  %395 = nn.batch_norm(%394, %v_param_447, %v_param_448, %v_param_449, %v_param_450, epsilon=1.001e-05f);\n",
       "  %396 = %395.0;\n",
       "  %397 = nn.relu(%396);\n",
       "  %398 = nn.conv2d(%397, %v_param_451, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %399 = nn.bias_add(%398, %v_param_452);\n",
       "  %400 = nn.batch_norm(%399, %v_param_453, %v_param_454, %v_param_455, %v_param_456, epsilon=1.001e-05f);\n",
       "  %401 = %400.0;\n",
       "  %402 = add(%387, %401);\n",
       "  %403 = nn.relu(%402);\n",
       "  %404 = nn.conv2d(%403, %v_param_457, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %405 = nn.bias_add(%404, %v_param_458);\n",
       "  %406 = nn.batch_norm(%405, %v_param_459, %v_param_460, %v_param_461, %v_param_462, epsilon=1.001e-05f);\n",
       "  %407 = %406.0;\n",
       "  %408 = nn.relu(%407);\n",
       "  %409 = nn.conv2d(%408, %v_param_463, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %410 = nn.bias_add(%409, %v_param_464);\n",
       "  %411 = nn.batch_norm(%410, %v_param_465, %v_param_466, %v_param_467, %v_param_468, epsilon=1.001e-05f);\n",
       "  %412 = %411.0;\n",
       "  %413 = nn.relu(%412);\n",
       "  %414 = nn.conv2d(%413, %v_param_469, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %415 = nn.bias_add(%414, %v_param_470);\n",
       "  %416 = nn.batch_norm(%415, %v_param_471, %v_param_472, %v_param_473, %v_param_474, epsilon=1.001e-05f);\n",
       "  %417 = %416.0;\n",
       "  %418 = add(%403, %417);\n",
       "  %419 = nn.relu(%418);\n",
       "  %420 = nn.conv2d(%419, %v_param_475, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %421 = nn.bias_add(%420, %v_param_476);\n",
       "  %422 = nn.batch_norm(%421, %v_param_477, %v_param_478, %v_param_479, %v_param_480, epsilon=1.001e-05f);\n",
       "  %423 = %422.0;\n",
       "  %424 = nn.relu(%423);\n",
       "  %425 = nn.conv2d(%424, %v_param_481, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %426 = nn.bias_add(%425, %v_param_482);\n",
       "  %427 = nn.batch_norm(%426, %v_param_483, %v_param_484, %v_param_485, %v_param_486, epsilon=1.001e-05f);\n",
       "  %428 = %427.0;\n",
       "  %429 = nn.relu(%428);\n",
       "  %430 = nn.conv2d(%429, %v_param_487, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %431 = nn.bias_add(%430, %v_param_488);\n",
       "  %432 = nn.batch_norm(%431, %v_param_489, %v_param_490, %v_param_491, %v_param_492, epsilon=1.001e-05f);\n",
       "  %433 = %432.0;\n",
       "  %434 = add(%419, %433);\n",
       "  %435 = nn.relu(%434);\n",
       "  %436 = nn.conv2d(%435, %v_param_493, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %437 = nn.bias_add(%436, %v_param_494);\n",
       "  %438 = nn.batch_norm(%437, %v_param_495, %v_param_496, %v_param_497, %v_param_498, epsilon=1.001e-05f);\n",
       "  %439 = %438.0;\n",
       "  %440 = nn.relu(%439);\n",
       "  %441 = nn.conv2d(%440, %v_param_499, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %442 = nn.bias_add(%441, %v_param_500);\n",
       "  %443 = nn.batch_norm(%442, %v_param_501, %v_param_502, %v_param_503, %v_param_504, epsilon=1.001e-05f);\n",
       "  %444 = %443.0;\n",
       "  %445 = nn.relu(%444);\n",
       "  %446 = nn.conv2d(%445, %v_param_505, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %447 = nn.bias_add(%446, %v_param_506);\n",
       "  %448 = nn.batch_norm(%447, %v_param_507, %v_param_508, %v_param_509, %v_param_510, epsilon=1.001e-05f);\n",
       "  %449 = %448.0;\n",
       "  %450 = add(%435, %449);\n",
       "  %451 = nn.relu(%450);\n",
       "  %452 = nn.conv2d(%451, %v_param_511, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %453 = nn.bias_add(%452, %v_param_512);\n",
       "  %454 = nn.batch_norm(%453, %v_param_513, %v_param_514, %v_param_515, %v_param_516, epsilon=1.001e-05f);\n",
       "  %455 = %454.0;\n",
       "  %456 = nn.relu(%455);\n",
       "  %457 = nn.conv2d(%456, %v_param_517, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %458 = nn.bias_add(%457, %v_param_518);\n",
       "  %459 = nn.batch_norm(%458, %v_param_519, %v_param_520, %v_param_521, %v_param_522, epsilon=1.001e-05f);\n",
       "  %460 = %459.0;\n",
       "  %461 = nn.relu(%460);\n",
       "  %462 = nn.conv2d(%461, %v_param_523, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %463 = nn.bias_add(%462, %v_param_524);\n",
       "  %464 = nn.batch_norm(%463, %v_param_525, %v_param_526, %v_param_527, %v_param_528, epsilon=1.001e-05f);\n",
       "  %465 = %464.0;\n",
       "  %466 = add(%451, %465);\n",
       "  %467 = nn.relu(%466);\n",
       "  %468 = nn.conv2d(%467, %v_param_529, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %469 = nn.bias_add(%468, %v_param_530);\n",
       "  %470 = nn.batch_norm(%469, %v_param_531, %v_param_532, %v_param_533, %v_param_534, epsilon=1.001e-05f);\n",
       "  %471 = %470.0;\n",
       "  %472 = nn.relu(%471);\n",
       "  %473 = nn.conv2d(%472, %v_param_535, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %474 = nn.bias_add(%473, %v_param_536);\n",
       "  %475 = nn.batch_norm(%474, %v_param_537, %v_param_538, %v_param_539, %v_param_540, epsilon=1.001e-05f);\n",
       "  %476 = %475.0;\n",
       "  %477 = nn.relu(%476);\n",
       "  %478 = nn.conv2d(%477, %v_param_541, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %479 = nn.bias_add(%478, %v_param_542);\n",
       "  %480 = nn.batch_norm(%479, %v_param_543, %v_param_544, %v_param_545, %v_param_546, epsilon=1.001e-05f);\n",
       "  %481 = %480.0;\n",
       "  %482 = add(%467, %481);\n",
       "  %483 = nn.relu(%482);\n",
       "  %484 = nn.conv2d(%483, %v_param_547, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %485 = nn.bias_add(%484, %v_param_548);\n",
       "  %486 = nn.batch_norm(%485, %v_param_549, %v_param_550, %v_param_551, %v_param_552, epsilon=1.001e-05f);\n",
       "  %487 = %486.0;\n",
       "  %488 = nn.relu(%487);\n",
       "  %489 = nn.conv2d(%488, %v_param_553, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %490 = nn.bias_add(%489, %v_param_554);\n",
       "  %491 = nn.batch_norm(%490, %v_param_555, %v_param_556, %v_param_557, %v_param_558, epsilon=1.001e-05f);\n",
       "  %492 = %491.0;\n",
       "  %493 = nn.relu(%492);\n",
       "  %494 = nn.conv2d(%493, %v_param_559, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %495 = nn.bias_add(%494, %v_param_560);\n",
       "  %496 = nn.batch_norm(%495, %v_param_561, %v_param_562, %v_param_563, %v_param_564, epsilon=1.001e-05f);\n",
       "  %497 = %496.0;\n",
       "  %498 = add(%483, %497);\n",
       "  %499 = nn.relu(%498);\n",
       "  %500 = nn.conv2d(%499, %v_param_565, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %501 = nn.bias_add(%500, %v_param_566);\n",
       "  %502 = nn.batch_norm(%501, %v_param_567, %v_param_568, %v_param_569, %v_param_570, epsilon=1.001e-05f);\n",
       "  %503 = %502.0;\n",
       "  %504 = nn.relu(%503);\n",
       "  %505 = nn.conv2d(%504, %v_param_571, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %506 = nn.bias_add(%505, %v_param_572);\n",
       "  %507 = nn.batch_norm(%506, %v_param_573, %v_param_574, %v_param_575, %v_param_576, epsilon=1.001e-05f);\n",
       "  %508 = %507.0;\n",
       "  %509 = nn.relu(%508);\n",
       "  %510 = nn.conv2d(%509, %v_param_577, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %511 = nn.bias_add(%510, %v_param_578);\n",
       "  %512 = nn.batch_norm(%511, %v_param_579, %v_param_580, %v_param_581, %v_param_582, epsilon=1.001e-05f);\n",
       "  %513 = %512.0;\n",
       "  %514 = add(%499, %513);\n",
       "  %515 = nn.relu(%514);\n",
       "  %516 = nn.conv2d(%515, %v_param_583, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %517 = nn.bias_add(%516, %v_param_584);\n",
       "  %518 = nn.batch_norm(%517, %v_param_585, %v_param_586, %v_param_587, %v_param_588, epsilon=1.001e-05f);\n",
       "  %519 = %518.0;\n",
       "  %520 = nn.relu(%519);\n",
       "  %521 = nn.conv2d(%520, %v_param_589, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %522 = nn.bias_add(%521, %v_param_590);\n",
       "  %523 = nn.batch_norm(%522, %v_param_591, %v_param_592, %v_param_593, %v_param_594, epsilon=1.001e-05f);\n",
       "  %524 = %523.0;\n",
       "  %525 = nn.relu(%524);\n",
       "  %526 = nn.conv2d(%525, %v_param_595, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %527 = nn.bias_add(%526, %v_param_596);\n",
       "  %528 = nn.batch_norm(%527, %v_param_597, %v_param_598, %v_param_599, %v_param_600, epsilon=1.001e-05f);\n",
       "  %529 = %528.0;\n",
       "  %530 = add(%515, %529);\n",
       "  %531 = nn.relu(%530);\n",
       "  %532 = nn.conv2d(%531, %v_param_601, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %533 = nn.bias_add(%532, %v_param_602);\n",
       "  %534 = nn.batch_norm(%533, %v_param_603, %v_param_604, %v_param_605, %v_param_606, epsilon=1.001e-05f);\n",
       "  %535 = %534.0;\n",
       "  %536 = nn.relu(%535);\n",
       "  %537 = nn.conv2d(%536, %v_param_607, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %538 = nn.bias_add(%537, %v_param_608);\n",
       "  %539 = nn.batch_norm(%538, %v_param_609, %v_param_610, %v_param_611, %v_param_612, epsilon=1.001e-05f);\n",
       "  %540 = %539.0;\n",
       "  %541 = nn.relu(%540);\n",
       "  %542 = nn.conv2d(%541, %v_param_613, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %543 = nn.bias_add(%542, %v_param_614);\n",
       "  %544 = nn.batch_norm(%543, %v_param_615, %v_param_616, %v_param_617, %v_param_618, epsilon=1.001e-05f);\n",
       "  %545 = %544.0;\n",
       "  %546 = add(%531, %545);\n",
       "  %547 = nn.relu(%546);\n",
       "  %548 = nn.conv2d(%547, %v_param_619, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %549 = nn.bias_add(%548, %v_param_620);\n",
       "  %550 = nn.batch_norm(%549, %v_param_621, %v_param_622, %v_param_623, %v_param_624, epsilon=1.001e-05f);\n",
       "  %551 = %550.0;\n",
       "  %552 = nn.relu(%551);\n",
       "  %553 = nn.conv2d(%552, %v_param_625, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %554 = nn.bias_add(%553, %v_param_626);\n",
       "  %555 = nn.batch_norm(%554, %v_param_627, %v_param_628, %v_param_629, %v_param_630, epsilon=1.001e-05f);\n",
       "  %556 = %555.0;\n",
       "  %557 = nn.relu(%556);\n",
       "  %558 = nn.conv2d(%557, %v_param_631, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %559 = nn.bias_add(%558, %v_param_632);\n",
       "  %560 = nn.batch_norm(%559, %v_param_633, %v_param_634, %v_param_635, %v_param_636, epsilon=1.001e-05f);\n",
       "  %561 = %560.0;\n",
       "  %562 = add(%547, %561);\n",
       "  %563 = nn.relu(%562);\n",
       "  %564 = nn.conv2d(%563, %v_param_637, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %565 = nn.bias_add(%564, %v_param_638);\n",
       "  %566 = nn.batch_norm(%565, %v_param_639, %v_param_640, %v_param_641, %v_param_642, epsilon=1.001e-05f);\n",
       "  %567 = %566.0;\n",
       "  %568 = nn.relu(%567);\n",
       "  %569 = nn.conv2d(%568, %v_param_643, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %570 = nn.bias_add(%569, %v_param_644);\n",
       "  %571 = nn.batch_norm(%570, %v_param_645, %v_param_646, %v_param_647, %v_param_648, epsilon=1.001e-05f);\n",
       "  %572 = %571.0;\n",
       "  %573 = nn.relu(%572);\n",
       "  %574 = nn.conv2d(%573, %v_param_649, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %575 = nn.bias_add(%574, %v_param_650);\n",
       "  %576 = nn.batch_norm(%575, %v_param_651, %v_param_652, %v_param_653, %v_param_654, epsilon=1.001e-05f);\n",
       "  %577 = %576.0;\n",
       "  %578 = add(%563, %577);\n",
       "  %579 = nn.relu(%578);\n",
       "  %580 = nn.conv2d(%579, %v_param_655, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %581 = nn.bias_add(%580, %v_param_656);\n",
       "  %582 = nn.batch_norm(%581, %v_param_657, %v_param_658, %v_param_659, %v_param_660, epsilon=1.001e-05f);\n",
       "  %583 = %582.0;\n",
       "  %584 = nn.relu(%583);\n",
       "  %585 = nn.conv2d(%584, %v_param_661, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %586 = nn.bias_add(%585, %v_param_662);\n",
       "  %587 = nn.batch_norm(%586, %v_param_663, %v_param_664, %v_param_665, %v_param_666, epsilon=1.001e-05f);\n",
       "  %588 = %587.0;\n",
       "  %589 = nn.relu(%588);\n",
       "  %590 = nn.conv2d(%589, %v_param_667, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %591 = nn.bias_add(%590, %v_param_668);\n",
       "  %592 = nn.batch_norm(%591, %v_param_669, %v_param_670, %v_param_671, %v_param_672, epsilon=1.001e-05f);\n",
       "  %593 = %592.0;\n",
       "  %594 = add(%579, %593);\n",
       "  %595 = nn.relu(%594);\n",
       "  %596 = nn.conv2d(%595, %v_param_673, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %597 = nn.bias_add(%596, %v_param_674);\n",
       "  %598 = nn.batch_norm(%597, %v_param_675, %v_param_676, %v_param_677, %v_param_678, epsilon=1.001e-05f);\n",
       "  %599 = %598.0;\n",
       "  %600 = nn.relu(%599);\n",
       "  %601 = nn.conv2d(%600, %v_param_679, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %602 = nn.bias_add(%601, %v_param_680);\n",
       "  %603 = nn.batch_norm(%602, %v_param_681, %v_param_682, %v_param_683, %v_param_684, epsilon=1.001e-05f);\n",
       "  %604 = %603.0;\n",
       "  %605 = nn.relu(%604);\n",
       "  %606 = nn.conv2d(%605, %v_param_685, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %607 = nn.bias_add(%606, %v_param_686);\n",
       "  %608 = nn.batch_norm(%607, %v_param_687, %v_param_688, %v_param_689, %v_param_690, epsilon=1.001e-05f);\n",
       "  %609 = %608.0;\n",
       "  %610 = add(%595, %609);\n",
       "  %611 = nn.relu(%610);\n",
       "  %612 = nn.conv2d(%611, %v_param_691, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %613 = nn.bias_add(%612, %v_param_692);\n",
       "  %614 = nn.batch_norm(%613, %v_param_693, %v_param_694, %v_param_695, %v_param_696, epsilon=1.001e-05f);\n",
       "  %615 = %614.0;\n",
       "  %616 = nn.relu(%615);\n",
       "  %617 = nn.conv2d(%616, %v_param_697, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %618 = nn.bias_add(%617, %v_param_698);\n",
       "  %619 = nn.batch_norm(%618, %v_param_699, %v_param_700, %v_param_701, %v_param_702, epsilon=1.001e-05f);\n",
       "  %620 = %619.0;\n",
       "  %621 = nn.relu(%620);\n",
       "  %622 = nn.conv2d(%621, %v_param_703, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %623 = nn.bias_add(%622, %v_param_704);\n",
       "  %624 = nn.batch_norm(%623, %v_param_705, %v_param_706, %v_param_707, %v_param_708, epsilon=1.001e-05f);\n",
       "  %625 = %624.0;\n",
       "  %626 = add(%611, %625);\n",
       "  %627 = nn.relu(%626);\n",
       "  %628 = nn.conv2d(%627, %v_param_709, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %629 = nn.bias_add(%628, %v_param_710);\n",
       "  %630 = nn.batch_norm(%629, %v_param_711, %v_param_712, %v_param_713, %v_param_714, epsilon=1.001e-05f);\n",
       "  %631 = %630.0;\n",
       "  %632 = nn.relu(%631);\n",
       "  %633 = nn.conv2d(%632, %v_param_715, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %634 = nn.bias_add(%633, %v_param_716);\n",
       "  %635 = nn.batch_norm(%634, %v_param_717, %v_param_718, %v_param_719, %v_param_720, epsilon=1.001e-05f);\n",
       "  %636 = %635.0;\n",
       "  %637 = nn.relu(%636);\n",
       "  %638 = nn.conv2d(%637, %v_param_721, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %639 = nn.bias_add(%638, %v_param_722);\n",
       "  %640 = nn.batch_norm(%639, %v_param_723, %v_param_724, %v_param_725, %v_param_726, epsilon=1.001e-05f);\n",
       "  %641 = %640.0;\n",
       "  %642 = add(%627, %641);\n",
       "  %643 = nn.relu(%642);\n",
       "  %644 = nn.conv2d(%643, %v_param_727, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %645 = nn.bias_add(%644, %v_param_728);\n",
       "  %646 = nn.batch_norm(%645, %v_param_729, %v_param_730, %v_param_731, %v_param_732, epsilon=1.001e-05f);\n",
       "  %647 = %646.0;\n",
       "  %648 = nn.relu(%647);\n",
       "  %649 = nn.conv2d(%648, %v_param_733, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %650 = nn.bias_add(%649, %v_param_734);\n",
       "  %651 = nn.batch_norm(%650, %v_param_735, %v_param_736, %v_param_737, %v_param_738, epsilon=1.001e-05f);\n",
       "  %652 = %651.0;\n",
       "  %653 = nn.relu(%652);\n",
       "  %654 = nn.conv2d(%653, %v_param_739, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %655 = nn.bias_add(%654, %v_param_740);\n",
       "  %656 = nn.batch_norm(%655, %v_param_741, %v_param_742, %v_param_743, %v_param_744, epsilon=1.001e-05f);\n",
       "  %657 = %656.0;\n",
       "  %658 = add(%643, %657);\n",
       "  %659 = nn.relu(%658);\n",
       "  %660 = nn.conv2d(%659, %v_param_745, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %661 = nn.bias_add(%660, %v_param_746);\n",
       "  %662 = nn.batch_norm(%661, %v_param_747, %v_param_748, %v_param_749, %v_param_750, epsilon=1.001e-05f);\n",
       "  %663 = %662.0;\n",
       "  %664 = nn.relu(%663);\n",
       "  %665 = nn.conv2d(%664, %v_param_751, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %666 = nn.bias_add(%665, %v_param_752);\n",
       "  %667 = nn.batch_norm(%666, %v_param_753, %v_param_754, %v_param_755, %v_param_756, epsilon=1.001e-05f);\n",
       "  %668 = %667.0;\n",
       "  %669 = nn.relu(%668);\n",
       "  %670 = nn.conv2d(%669, %v_param_757, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %671 = nn.bias_add(%670, %v_param_758);\n",
       "  %672 = nn.batch_norm(%671, %v_param_759, %v_param_760, %v_param_761, %v_param_762, epsilon=1.001e-05f);\n",
       "  %673 = %672.0;\n",
       "  %674 = add(%659, %673);\n",
       "  %675 = nn.relu(%674);\n",
       "  %676 = nn.conv2d(%675, %v_param_763, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %677 = nn.bias_add(%676, %v_param_764);\n",
       "  %678 = nn.batch_norm(%677, %v_param_765, %v_param_766, %v_param_767, %v_param_768, epsilon=1.001e-05f);\n",
       "  %679 = %678.0;\n",
       "  %680 = nn.relu(%679);\n",
       "  %681 = nn.conv2d(%680, %v_param_769, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %682 = nn.bias_add(%681, %v_param_770);\n",
       "  %683 = nn.batch_norm(%682, %v_param_771, %v_param_772, %v_param_773, %v_param_774, epsilon=1.001e-05f);\n",
       "  %684 = %683.0;\n",
       "  %685 = nn.relu(%684);\n",
       "  %686 = nn.conv2d(%685, %v_param_775, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %687 = nn.bias_add(%686, %v_param_776);\n",
       "  %688 = nn.batch_norm(%687, %v_param_777, %v_param_778, %v_param_779, %v_param_780, epsilon=1.001e-05f);\n",
       "  %689 = %688.0;\n",
       "  %690 = add(%675, %689);\n",
       "  %691 = nn.relu(%690);\n",
       "  %692 = nn.conv2d(%691, %v_param_781, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %693 = nn.bias_add(%692, %v_param_782);\n",
       "  %694 = nn.batch_norm(%693, %v_param_783, %v_param_784, %v_param_785, %v_param_786, epsilon=1.001e-05f);\n",
       "  %695 = %694.0;\n",
       "  %696 = nn.relu(%695);\n",
       "  %697 = nn.conv2d(%696, %v_param_787, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %698 = nn.bias_add(%697, %v_param_788);\n",
       "  %699 = nn.batch_norm(%698, %v_param_789, %v_param_790, %v_param_791, %v_param_792, epsilon=1.001e-05f);\n",
       "  %700 = %699.0;\n",
       "  %701 = nn.relu(%700);\n",
       "  %702 = nn.conv2d(%701, %v_param_793, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %703 = nn.bias_add(%702, %v_param_794);\n",
       "  %704 = nn.batch_norm(%703, %v_param_795, %v_param_796, %v_param_797, %v_param_798, epsilon=1.001e-05f);\n",
       "  %705 = %704.0;\n",
       "  %706 = add(%691, %705);\n",
       "  %707 = nn.relu(%706);\n",
       "  %708 = nn.conv2d(%707, %v_param_799, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %709 = nn.bias_add(%708, %v_param_800);\n",
       "  %710 = nn.batch_norm(%709, %v_param_801, %v_param_802, %v_param_803, %v_param_804, epsilon=1.001e-05f);\n",
       "  %711 = %710.0;\n",
       "  %712 = nn.relu(%711);\n",
       "  %713 = nn.conv2d(%712, %v_param_805, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %714 = nn.bias_add(%713, %v_param_806);\n",
       "  %715 = nn.batch_norm(%714, %v_param_807, %v_param_808, %v_param_809, %v_param_810, epsilon=1.001e-05f);\n",
       "  %716 = %715.0;\n",
       "  %717 = nn.relu(%716);\n",
       "  %718 = nn.conv2d(%717, %v_param_811, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %719 = nn.bias_add(%718, %v_param_812);\n",
       "  %720 = nn.batch_norm(%719, %v_param_813, %v_param_814, %v_param_815, %v_param_816, epsilon=1.001e-05f);\n",
       "  %721 = %720.0;\n",
       "  %722 = add(%707, %721);\n",
       "  %723 = nn.relu(%722);\n",
       "  %724 = nn.conv2d(%723, %v_param_817, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %725 = nn.bias_add(%724, %v_param_818);\n",
       "  %726 = nn.batch_norm(%725, %v_param_819, %v_param_820, %v_param_821, %v_param_822, epsilon=1.001e-05f);\n",
       "  %727 = %726.0;\n",
       "  %728 = nn.relu(%727);\n",
       "  %729 = nn.conv2d(%728, %v_param_823, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %730 = nn.bias_add(%729, %v_param_824);\n",
       "  %731 = nn.batch_norm(%730, %v_param_825, %v_param_826, %v_param_827, %v_param_828, epsilon=1.001e-05f);\n",
       "  %732 = %731.0;\n",
       "  %733 = nn.relu(%732);\n",
       "  %734 = nn.conv2d(%733, %v_param_829, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %735 = nn.bias_add(%734, %v_param_830);\n",
       "  %736 = nn.batch_norm(%735, %v_param_831, %v_param_832, %v_param_833, %v_param_834, epsilon=1.001e-05f);\n",
       "  %737 = %736.0;\n",
       "  %738 = add(%723, %737);\n",
       "  %739 = nn.relu(%738);\n",
       "  %740 = nn.conv2d(%739, %v_param_835, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %741 = nn.bias_add(%740, %v_param_836);\n",
       "  %742 = nn.batch_norm(%741, %v_param_837, %v_param_838, %v_param_839, %v_param_840, epsilon=1.001e-05f);\n",
       "  %743 = %742.0;\n",
       "  %744 = nn.relu(%743);\n",
       "  %745 = nn.conv2d(%744, %v_param_841, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %746 = nn.bias_add(%745, %v_param_842);\n",
       "  %747 = nn.batch_norm(%746, %v_param_843, %v_param_844, %v_param_845, %v_param_846, epsilon=1.001e-05f);\n",
       "  %748 = %747.0;\n",
       "  %749 = nn.relu(%748);\n",
       "  %750 = nn.conv2d(%749, %v_param_847, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %751 = nn.bias_add(%750, %v_param_848);\n",
       "  %752 = nn.batch_norm(%751, %v_param_849, %v_param_850, %v_param_851, %v_param_852, epsilon=1.001e-05f);\n",
       "  %753 = %752.0;\n",
       "  %754 = add(%739, %753);\n",
       "  %755 = nn.relu(%754);\n",
       "  %756 = nn.conv2d(%755, %v_param_853, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
       "  %757 = nn.bias_add(%756, %v_param_854);\n",
       "  %758 = nn.batch_norm(%757, %v_param_855, %v_param_856, %v_param_857, %v_param_858, epsilon=1.001e-05f);\n",
       "  %759 = %758.0;\n",
       "  %760 = nn.relu(%759);\n",
       "  %761 = nn.conv2d(%760, %v_param_859, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %762 = nn.bias_add(%761, %v_param_860);\n",
       "  %763 = nn.batch_norm(%762, %v_param_861, %v_param_862, %v_param_863, %v_param_864, epsilon=1.001e-05f);\n",
       "  %764 = %763.0;\n",
       "  %765 = nn.relu(%764);\n",
       "  %766 = nn.conv2d(%765, %v_param_865, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
       "  %767 = nn.bias_add(%766, %v_param_866);\n",
       "  %768 = nn.batch_norm(%767, %v_param_867, %v_param_868, %v_param_869, %v_param_870, epsilon=1.001e-05f);\n",
       "  %769 = %768.0;\n",
       "  %770 = add(%755, %769);\n",
       "  %771 = nn.relu(%770);\n",
       "  %772 = nn.conv2d(%771, %v_param_883, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %773 = nn.bias_add(%772, %v_param_884);\n",
       "  %774 = nn.batch_norm(%773, %v_param_887, %v_param_888, %v_param_889, %v_param_890, epsilon=1.001e-05f);\n",
       "  %775 = nn.conv2d(%771, %v_param_871, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %776 = nn.bias_add(%775, %v_param_872);\n",
       "  %777 = nn.batch_norm(%776, %v_param_873, %v_param_874, %v_param_875, %v_param_876, epsilon=1.001e-05f);\n",
       "  %778 = %777.0;\n",
       "  %779 = nn.relu(%778);\n",
       "  %780 = nn.conv2d(%779, %v_param_877, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %781 = nn.bias_add(%780, %v_param_878);\n",
       "  %782 = nn.batch_norm(%781, %v_param_879, %v_param_880, %v_param_881, %v_param_882, epsilon=1.001e-05f);\n",
       "  %783 = %782.0;\n",
       "  %784 = nn.relu(%783);\n",
       "  %785 = nn.conv2d(%784, %v_param_885, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %786 = nn.bias_add(%785, %v_param_886);\n",
       "  %787 = nn.batch_norm(%786, %v_param_891, %v_param_892, %v_param_893, %v_param_894, epsilon=1.001e-05f);\n",
       "  %788 = %774.0;\n",
       "  %789 = %787.0;\n",
       "  %790 = add(%788, %789);\n",
       "  %791 = nn.relu(%790);\n",
       "  %792 = nn.conv2d(%791, %v_param_895, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %793 = nn.bias_add(%792, %v_param_896);\n",
       "  %794 = nn.batch_norm(%793, %v_param_897, %v_param_898, %v_param_899, %v_param_900, epsilon=1.001e-05f);\n",
       "  %795 = %794.0;\n",
       "  %796 = nn.relu(%795);\n",
       "  %797 = nn.conv2d(%796, %v_param_901, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %798 = nn.bias_add(%797, %v_param_902);\n",
       "  %799 = nn.batch_norm(%798, %v_param_903, %v_param_904, %v_param_905, %v_param_906, epsilon=1.001e-05f);\n",
       "  %800 = %799.0;\n",
       "  %801 = nn.relu(%800);\n",
       "  %802 = nn.conv2d(%801, %v_param_907, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %803 = nn.bias_add(%802, %v_param_908);\n",
       "  %804 = nn.batch_norm(%803, %v_param_909, %v_param_910, %v_param_911, %v_param_912, epsilon=1.001e-05f);\n",
       "  %805 = %804.0;\n",
       "  %806 = add(%791, %805);\n",
       "  %807 = nn.relu(%806);\n",
       "  %808 = nn.conv2d(%807, %v_param_913, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
       "  %809 = nn.bias_add(%808, %v_param_914);\n",
       "  %810 = nn.batch_norm(%809, %v_param_915, %v_param_916, %v_param_917, %v_param_918, epsilon=1.001e-05f);\n",
       "  %811 = %810.0;\n",
       "  %812 = nn.relu(%811);\n",
       "  %813 = nn.conv2d(%812, %v_param_919, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
       "  %814 = nn.bias_add(%813, %v_param_920);\n",
       "  %815 = nn.batch_norm(%814, %v_param_921, %v_param_922, %v_param_923, %v_param_924, epsilon=1.001e-05f);\n",
       "  %816 = %815.0;\n",
       "  %817 = nn.relu(%816);\n",
       "  %818 = nn.conv2d(%817, %v_param_925, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
       "  %819 = nn.bias_add(%818, %v_param_926);\n",
       "  %820 = nn.batch_norm(%819, %v_param_927, %v_param_928, %v_param_929, %v_param_930, epsilon=1.001e-05f);\n",
       "  %821 = %820.0;\n",
       "  %822 = add(%807, %821);\n",
       "  %823 = nn.relu(%822);\n",
       "  %824 = nn.global_avg_pool2d(%823);\n",
       "  %825 = transpose(%824, axes=[0, 2, 3, 1]);\n",
       "  %826 = nn.batch_flatten(%825);\n",
       "  %827 = nn.dense(%826, %v_param_931, units=1000);\n",
       "  %828 = nn.bias_add(%827, %v_param_932);\n",
       "  nn.softmax(%828, axis=1)\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet152Callback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        self.pool_size = is_constant()\n",
    "        self.strides = is_constant()\n",
    "        self.padding = is_constant()\n",
    "        self.padding = [1, 1, 1, 1]\n",
    "        # self.pattern = is_tuple([self.var1, self.var2])\n",
    "        bn_node = is_op('nn.batch_norm')(wildcard(), wildcard(), wildcard(), wildcard(), wildcard())\n",
    "        tuple_get_item_node = is_tuple_get_item(bn_node, 0)\n",
    "        add_node = is_op('add')(wildcard(), tuple_get_item_node)\n",
    "        relu_node = is_op('nn.relu')(add_node)\n",
    "        self.pattern = relu_node\n",
    "        # self.pattern = is_op('nn.batch_norm')(wildcard(), wildcard(),wildcard(),wildcard(),wildcard())\n",
    "        self.cnt = 0\n",
    "        self.target = 1\n",
    "        self.target_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        # if self.cnt != self.target:\n",
    "        if self.cnt % 3 != 0 or self.cnt / 3 > 5:\n",
    "            self.cnt += 1\n",
    "            return post\n",
    "        else:\n",
    "            self.cnt += 1\n",
    "            cast_to_int8 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.round(\n",
    "                        relay.multiply(post, relay.const(8.0))\n",
    "                    ), \n",
    "                    a_min=-127.0, a_max=127.0\n",
    "                ),\n",
    "                dtype=\"int8\"\n",
    "            )\n",
    "            cast_to_float32 = relay.divide(relay.cast(relay.annotation.stop_fusion(cast_to_int8), dtype='float32'), relay.const(8.0))\n",
    "\n",
    "            # cast_to_float32 = relay.cast(\n",
    "            #     relay.clip(\n",
    "            #         relay.right_shift(\n",
    "            #             relay.add(relay.cast(relay.annotation.stop_fusion(cast_to_int8), dtype='int32'), relay.const(512)),\n",
    "            #             relay.const(10)),\n",
    "            #         a_min=-127.0, a_max=127.0), \n",
    "            #     dtype=\"float32\"\n",
    "            # )\n",
    "            return cast_to_float32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1858775713.py, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [26]\u001b[0;36m\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class UnetPreProcessCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple([wildcard(), self.var2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        self.pattern = concat_node\n",
    "        self.match_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var2 = node_map[self.var2][0]\n",
    "        self.match_node.append(var2)\n",
    "        return post\n",
    "\n",
    "\n",
    "class UnetCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, match_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "\n",
    "        # self.batch_norm_node = is_op('nn.batch_norm')(wildcard())\n",
    "        # self.pattern_1 = self.batch_norm_node\n",
    "\n",
    "        self.tuple_get_item_node = is_tuple_get_item(wildcard(), 0)\n",
    "        self.pattern_1 = self.tuple_get_item_node\n",
    "\n",
    "        self.max_pool2d_arg_node = wildcard() \n",
    "        self.max_pool2d_node = is_op('nn.max_pool2d')(self.max_pool2d_arg_node)\n",
    "        self.pattern_2 = self.max_pool2d_node\n",
    "\n",
    "        self.concat_arg_1 = wildcard()\n",
    "        self.concat_arg_2 = wildcard()\n",
    "        tuple_node = is_tuple([self.concat_arg_1, self.concat_arg_2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        self.pattern_3 = concat_node\n",
    "\n",
    "        self.pattern = (self.pattern_1 | self.pattern_2 | self.pattern_3)\n",
    "        self.match_node = match_node\n",
    "\n",
    "    def quant(self, node):\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(node, relay.const(16.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        return relay.annotation.stop_fusion(cast_to_int8)\n",
    "\n",
    "    def dequant(self, node):\n",
    "        cast_to_float32 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.right_shift(\n",
    "                    relay.add(relay.cast(node, dtype='int32'), relay.const(512)),\n",
    "                    relay.const(10)),\n",
    "                a_min=-127.0, a_max=127.0), \n",
    "            dtype=\"float32\"\n",
    "        )\n",
    "        return cast_to_float32\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if self.pattern_1.match(pre):\n",
    "            # print(\"1\")\n",
    "            if pre in self.match_node:\n",
    "                print(\"pat 1\")\n",
    "                return self.quant(post)\n",
    "        elif self.pattern_2.match(pre):\n",
    "            # print(\"2\")\n",
    "            max_pool2d_arg_node = node_map[self.max_pool2d_arg_node][0]\n",
    "            # if max_pool2d_arg_node in self.match_node:\n",
    "            if True:\n",
    "                print(\"pat 2\")\n",
    "                return relay.nn.max_pool2d(self.dequant(max_pool2d_arg_node), pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0])\n",
    "        elif self.pattern_3.match(pre):\n",
    "            # print(\"3\")\n",
    "            concat_arg_1 = node_map[self.concat_arg_1][0]\n",
    "            concat_arg_2 = node_map[self.concat_arg_2][0]\n",
    "            # if concat_arg_2 in self.match_node:\n",
    "            if True:\n",
    "                print(\"pat 3\")\n",
    "                return relay.concatenate((concat_arg_1, self.dequant(concat_arg_2)), axis=1)\n",
    "        else:\n",
    "            print(\"asd\")\n",
    "        return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetPreProcessCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple([wildcard(), self.var2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        self.pattern = concat_node\n",
    "        self.match_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var2 = node_map[self.var2][0]\n",
    "        self.match_node.append(var2)\n",
    "        return post\n",
    "\n",
    "\n",
    "class UnetCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, match_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.tuple_get_item_node = is_tuple_get_item(wildcard(), 0)\n",
    "        self.pattern_1 = self.tuple_get_item_node\n",
    "\n",
    "        self.pattern = self.pattern_1\n",
    "        self.match_node = match_node\n",
    "\n",
    "    def quant(self, node):\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(node, relay.const(8.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        return relay.annotation.stop_fusion(cast_to_int8)\n",
    "\n",
    "    def dequant(self, node):\n",
    "        cast_to_float32 = relay.divide(\n",
    "            relay.cast(node, dtype='float32'), relay.const(8.0)\n",
    "        )\n",
    "        return cast_to_float32\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if self.pattern_1.match(pre):\n",
    "            if pre in self.match_node:\n",
    "                print(\"pat 1\")\n",
    "                return self.dequant(self.quant(post))\n",
    "        return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat 1\n",
      "pat 1\n",
      "pat 1\n",
      "pat 1\n"
     ]
    }
   ],
   "source": [
    "upc = UnetPreProcessCallback()\n",
    "rewrite(upc, mod['main'])\n",
    "uc = UnetCallback(upc.match_node)\n",
    "out = rewrite(uc, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet152PreProcessCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple([self.var1, self.var2])\n",
    "        concat_node = is_op('add')(tuple_node)\n",
    "        self.pattern = concat_node\n",
    "        self.match_node = []\n",
    "        self.counter = 0\n",
    "        self.slice_limit = 10\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if self.counter < self.slice_limit:\n",
    "            var2 = node_map[self.var2][0]\n",
    "            self.match_node.append(var2)\n",
    "            self.counter += 1\n",
    "        return post\n",
    "\n",
    "\n",
    "class Resnet152Callback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, match_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.tuple_get_item_node = is_tuple_get_item(wildcard(), 0)\n",
    "        self.pattern_1 = self.tuple_get_item_node\n",
    "\n",
    "        self.pattern = self.pattern_1\n",
    "        self.match_node = match_node\n",
    "\n",
    "    def quant(self, node):\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(node, relay.const(8.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        return relay.annotation.stop_fusion(cast_to_int8)\n",
    "\n",
    "    def dequant(self, node):\n",
    "        cast_to_float32 = relay.divide(\n",
    "            relay.cast(node, dtype='float32'), relay.const(8.0)\n",
    "        )\n",
    "        return cast_to_float32\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if self.pattern_1.match(pre):\n",
    "            if pre in self.match_node:\n",
    "                print(\"pat 1\")\n",
    "                return self.dequant(self.quant(post))\n",
    "        return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
       "  %3 = %2.0;\n",
       "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
       "  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %6 = nn.bias_add(%5, %v_param_8);\n",
       "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
       "  %8 = %7.0;\n",
       "  %9 = multiply(%8, 8f);\n",
       "  %10 = round(%9);\n",
       "  %11 = clip(%10, a_min=-127f, a_max=127f);\n",
       "  %12 = cast(%11, dtype=\"int8\");\n",
       "  %13 = annotation.stop_fusion(%12);\n",
       "  %14 = cast(%13, dtype=\"float32\");\n",
       "  %15 = divide(%14, 8f);\n",
       "  %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %17 = nn.conv2d(%16, %v_param_13, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
       "  %18 = nn.bias_add(%17, %v_param_14);\n",
       "  %19 = nn.batch_norm(%18, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);\n",
       "  %20 = %19.0;\n",
       "  %21 = nn.leaky_relu(%20, alpha=0.2f);\n",
       "  %22 = nn.conv2d(%21, %v_param_19, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
       "  %23 = nn.bias_add(%22, %v_param_20);\n",
       "  %24 = nn.batch_norm(%23, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);\n",
       "  %25 = %24.0;\n",
       "  %26 = multiply(%25, 8f);\n",
       "  %27 = round(%26);\n",
       "  %28 = clip(%27, a_min=-127f, a_max=127f);\n",
       "  %29 = cast(%28, dtype=\"int8\");\n",
       "  %30 = annotation.stop_fusion(%29);\n",
       "  %31 = cast(%30, dtype=\"float32\");\n",
       "  %32 = divide(%31, 8f);\n",
       "  %33 = nn.max_pool2d(%32, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %34 = nn.conv2d(%33, %v_param_25, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %35 = nn.bias_add(%34, %v_param_26);\n",
       "  %36 = nn.batch_norm(%35, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);\n",
       "  %37 = %36.0;\n",
       "  %38 = nn.leaky_relu(%37, alpha=0.2f);\n",
       "  %39 = nn.conv2d(%38, %v_param_31, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %40 = nn.bias_add(%39, %v_param_32);\n",
       "  %41 = nn.batch_norm(%40, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);\n",
       "  %42 = %41.0;\n",
       "  %43 = multiply(%42, 8f);\n",
       "  %44 = round(%43);\n",
       "  %45 = clip(%44, a_min=-127f, a_max=127f);\n",
       "  %46 = cast(%45, dtype=\"int8\");\n",
       "  %47 = annotation.stop_fusion(%46);\n",
       "  %48 = cast(%47, dtype=\"float32\");\n",
       "  %49 = divide(%48, 8f);\n",
       "  %50 = nn.max_pool2d(%49, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %51 = nn.conv2d(%50, %v_param_37, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %52 = nn.bias_add(%51, %v_param_38);\n",
       "  %53 = nn.batch_norm(%52, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);\n",
       "  %54 = %53.0;\n",
       "  %55 = nn.leaky_relu(%54, alpha=0.2f);\n",
       "  %56 = nn.conv2d(%55, %v_param_43, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %57 = nn.bias_add(%56, %v_param_44);\n",
       "  %58 = nn.batch_norm(%57, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);\n",
       "  %59 = %58.0;\n",
       "  %60 = multiply(%59, 8f);\n",
       "  %61 = round(%60);\n",
       "  %62 = clip(%61, a_min=-127f, a_max=127f);\n",
       "  %63 = cast(%62, dtype=\"int8\");\n",
       "  %64 = annotation.stop_fusion(%63);\n",
       "  %65 = cast(%64, dtype=\"float32\");\n",
       "  %66 = divide(%65, 8f);\n",
       "  %67 = nn.max_pool2d(%66, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
       "  %68 = nn.conv2d(%67, %v_param_49, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %69 = nn.bias_add(%68, %v_param_50);\n",
       "  %70 = nn.batch_norm(%69, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);\n",
       "  %71 = %70.0;\n",
       "  %72 = nn.leaky_relu(%71, alpha=0.2f);\n",
       "  %73 = nn.conv2d(%72, %v_param_55, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
       "  %74 = nn.bias_add(%73, %v_param_56);\n",
       "  %75 = nn.batch_norm(%74, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);\n",
       "  %76 = %75.0;\n",
       "  %77 = nn.conv2d_transpose(%76, %v_param_61, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
       "  %78 = nn.bias_add(%77, %v_param_62);\n",
       "  %79 = nn.batch_norm(%78, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);\n",
       "  %80 = %79.0;\n",
       "  %81 = nn.leaky_relu(%80, alpha=0.2f);\n",
       "  %82 = (%81, %66);\n",
       "  %83 = concatenate(%82, axis=1);\n",
       "  %84 = nn.conv2d(%83, %v_param_67, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %85 = nn.bias_add(%84, %v_param_68);\n",
       "  %86 = nn.batch_norm(%85, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);\n",
       "  %87 = %86.0;\n",
       "  %88 = nn.leaky_relu(%87, alpha=0.2f);\n",
       "  %89 = nn.conv2d(%88, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
       "  %90 = nn.bias_add(%89, %v_param_74);\n",
       "  %91 = nn.batch_norm(%90, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);\n",
       "  %92 = %91.0;\n",
       "  %93 = nn.conv2d_transpose(%92, %v_param_79, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
       "  %94 = nn.bias_add(%93, %v_param_80);\n",
       "  %95 = nn.batch_norm(%94, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);\n",
       "  %96 = %95.0;\n",
       "  %97 = nn.leaky_relu(%96, alpha=0.2f);\n",
       "  %98 = (%97, %49);\n",
       "  %99 = concatenate(%98, axis=1);\n",
       "  %100 = nn.conv2d(%99, %v_param_85, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %101 = nn.bias_add(%100, %v_param_86);\n",
       "  %102 = nn.batch_norm(%101, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);\n",
       "  %103 = %102.0;\n",
       "  %104 = nn.leaky_relu(%103, alpha=0.2f);\n",
       "  %105 = nn.conv2d(%104, %v_param_91, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
       "  %106 = nn.bias_add(%105, %v_param_92);\n",
       "  %107 = nn.batch_norm(%106, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);\n",
       "  %108 = %107.0;\n",
       "  %109 = nn.conv2d_transpose(%108, %v_param_97, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
       "  %110 = nn.bias_add(%109, %v_param_98);\n",
       "  %111 = nn.batch_norm(%110, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);\n",
       "  %112 = %111.0;\n",
       "  %113 = nn.leaky_relu(%112, alpha=0.2f);\n",
       "  %114 = (%113, %32);\n",
       "  %115 = concatenate(%114, axis=1);\n",
       "  %116 = nn.conv2d(%115, %v_param_103, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
       "  %117 = nn.bias_add(%116, %v_param_104);\n",
       "  %118 = nn.batch_norm(%117, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);\n",
       "  %119 = %118.0;\n",
       "  %120 = nn.leaky_relu(%119, alpha=0.2f);\n",
       "  %121 = nn.conv2d(%120, %v_param_109, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
       "  %122 = nn.bias_add(%121, %v_param_110);\n",
       "  %123 = nn.batch_norm(%122, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);\n",
       "  %124 = %123.0;\n",
       "  %125 = nn.conv2d_transpose(%124, %v_param_115, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
       "  %126 = nn.bias_add(%125, %v_param_116);\n",
       "  %127 = nn.batch_norm(%126, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);\n",
       "  %128 = %127.0;\n",
       "  %129 = nn.leaky_relu(%128, alpha=0.2f);\n",
       "  %130 = (%129, %15);\n",
       "  %131 = concatenate(%130, axis=1);\n",
       "  %132 = nn.conv2d(%131, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %133 = nn.bias_add(%132, %v_param_122);\n",
       "  %134 = nn.batch_norm(%133, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);\n",
       "  %135 = %134.0;\n",
       "  %136 = nn.leaky_relu(%135, alpha=0.2f);\n",
       "  %137 = nn.conv2d(%136, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %138 = nn.bias_add(%137, %v_param_128);\n",
       "  %139 = nn.batch_norm(%138, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);\n",
       "  %140 = %139.0;\n",
       "  %141 = nn.conv2d(%140, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);\n",
       "  %142 = nn.bias_add(%141, %v_param_134);\n",
       "  sigmoid(%142)\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetPreProcessCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple([self.var1, self.var2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        self.pattern = concat_node\n",
    "        self.target_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var1 = node_map[self.var1][0]\n",
    "        var2 = node_map[self.var2][0]\n",
    "        self.target_node.append(var2)\n",
    "        cast_to_float32 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.right_shift(\n",
    "                        relay.add(relay.cast(relay.annotation.stop_fusion(var2), dtype='int32'), relay.const(512)),\n",
    "                        relay.const(10)),\n",
    "                    a_min=-127.0, a_max=127.0), \n",
    "                dtype=\"float32\"\n",
    "        )\n",
    "        return relay.concatenate([var1, cast_to_float32], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetPreProcessCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple([self.var1, self.var2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        self.pattern = concat_node\n",
    "        self.target_node = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var1 = node_map[self.var1][0]\n",
    "        var2 = node_map[self.var2][0]\n",
    "        self.target_node.append(var2)\n",
    "        cast_to_float32 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.right_shift(\n",
    "                        relay.add(relay.cast(relay.annotation.stop_fusion(var2), dtype='int32'), relay.const(512)),\n",
    "                        relay.const(10)),\n",
    "                    a_min=-127.0, a_max=127.0), \n",
    "                dtype=\"float32\"\n",
    "        )\n",
    "        return relay.concatenate([var1, cast_to_float32], axis=1)\n",
    "\n",
    "\n",
    "class UnetMidProcessCallback(DFPatternCallback):\n",
    "    def __init__(self, target_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        tuple_node = is_tuple_get_item(wildcard(), 0)\n",
    "        self.pattern = tuple_node\n",
    "        self.target_node = target_node\n",
    "        self.target_node_2 = []\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if pre in self.target_node:\n",
    "            cast_to_int8 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.round(\n",
    "                        relay.multiply(post, relay.const(16.0))\n",
    "                    ), \n",
    "                    a_min=-127.0, a_max=127.0\n",
    "                ),\n",
    "                dtype=\"int8\"\n",
    "            )\n",
    "            self.target_node_2.append(cast_to_int8)\n",
    "            return cast_to_int8\n",
    "        else:\n",
    "            return post\n",
    "\n",
    "\n",
    "class UnetCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, target_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        self.pool_size = is_constant()\n",
    "        self.strides = is_constant()\n",
    "        self.padding = is_constant()\n",
    "        self.padding = [1, 1, 1, 1]\n",
    "        max_pool_node = is_op('nn.max_pool2d')(self.var1)\n",
    "        self.pattern = max_pool_node\n",
    "        self.cnt = 0\n",
    "        self.target = 1\n",
    "        self.target_node = target_node\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        var1 = node_map[self.var1][0]\n",
    "\n",
    "        # if var1 in self.target_node:\n",
    "        if True:\n",
    "            print(\"sex\")\n",
    "            # cast_to_int8 = relay.cast(\n",
    "            #     relay.clip(\n",
    "            #         relay.round(\n",
    "            #             relay.multiply(var1, relay.const(16.0))\n",
    "            #         ), \n",
    "            #         a_min=-127.0, a_max=127.0\n",
    "            #     ),\n",
    "            #     dtype=\"int8\"\n",
    "            # )\n",
    "            cast_to_float32 = relay.cast(\n",
    "                relay.clip(\n",
    "                    relay.right_shift(\n",
    "                        relay.add(relay.cast(relay.annotation.stop_fusion(var1), dtype='int32'), relay.const(512)),\n",
    "                        relay.const(10)),\n",
    "                    a_min=-127.0, a_max=127.0), \n",
    "                dtype=\"float32\"\n",
    "            )\n",
    "            return cast_to_float32\n",
    "        else:\n",
    "            return post\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "[TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 512, 512], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bc93d38), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b962568), []), Var(_param_3, ty=TensorType([16], float32)), Var(_param_4, ty=TensorType([16], float32)), Var(_param_5, ty=TensorType([16], float32)), Var(_param_6, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1be816d8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5882d8), []), Var(_param_7, ty=TensorType([16, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd6cb8), []), Var(_param_8, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b9b67e8), []), Var(_param_9, ty=TensorType([16], float32)), Var(_param_10, ty=TensorType([16], float32)), Var(_param_11, ty=TensorType([16], float32)), Var(_param_12, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1c42aa18), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c591bd8), []), Var(_param_13, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd5de8), []), Var(_param_14, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1be0c7a8), []), Var(_param_15, ty=TensorType([32], float32)), Var(_param_16, ty=TensorType([32], float32)), Var(_param_17, ty=TensorType([32], float32)), Var(_param_18, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beb97c8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5a2dd8), []), Var(_param_19, ty=TensorType([32, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c58c458), []), Var(_param_20, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1c49b448), []), Var(_param_21, ty=TensorType([32], float32)), Var(_param_22, ty=TensorType([32], float32)), Var(_param_23, ty=TensorType([32], float32)), Var(_param_24, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beda5a8), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c278a38), []), Var(_param_25, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c4bfd98), []), Var(_param_26, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x1bd814f8), []), Var(_param_27, ty=TensorType([64], float32)), Var(_param_28, ty=TensorType([64], float32)), Var(_param_29, ty=TensorType([64], float32)), Var(_param_30, ty=TensorType([64], float32))], relay.attrs.BatchNormAttrs(0x1bee87f8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c4fb088), []), Var(_param_31, ty=TensorType([64, 64, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c279398), []), Var(_param_32, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x1c538718), []), Var(_param_33, ty=TensorType([64], float32)), Var(_param_34, ty=TensorType([64], float32)), Var(_param_35, ty=TensorType([64], float32)), Var(_param_36, ty=TensorType([64], float32))], relay.attrs.BatchNormAttrs(0x1bef2358), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c58e7a8), []), Var(_param_37, ty=TensorType([128, 64, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bd723d8), []), Var(_param_38, ty=TensorType([128], float32))], relay.attrs.BiasAddAttrs(0x1c434988), []), Var(_param_39, ty=TensorType([128], float32)), Var(_param_40, ty=TensorType([128], float32)), Var(_param_41, ty=TensorType([128], float32)), Var(_param_42, ty=TensorType([128], float32))], relay.attrs.BatchNormAttrs(0x1bf001d8), []), 0)], relay.attrs.LeakyReluAttrs(0x1bdc5938), []), Var(_param_43, ty=TensorType([128, 128, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c281b58), []), Var(_param_44, ty=TensorType([128], float32))], relay.attrs.BiasAddAttrs(0x1bdbe468), []), Var(_param_45, ty=TensorType([128], float32)), Var(_param_46, ty=TensorType([128], float32)), Var(_param_47, ty=TensorType([128], float32)), Var(_param_48, ty=TensorType([128], float32))], relay.attrs.BatchNormAttrs(0x1bf04d68), []), 0), TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 512, 512], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bc93d38), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b962568), []), Var(_param_3, ty=TensorType([16], float32)), Var(_param_4, ty=TensorType([16], float32)), Var(_param_5, ty=TensorType([16], float32)), Var(_param_6, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1be816d8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5882d8), []), Var(_param_7, ty=TensorType([16, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd6cb8), []), Var(_param_8, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b9b67e8), []), Var(_param_9, ty=TensorType([16], float32)), Var(_param_10, ty=TensorType([16], float32)), Var(_param_11, ty=TensorType([16], float32)), Var(_param_12, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1c42aa18), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c591bd8), []), Var(_param_13, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd5de8), []), Var(_param_14, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1be0c7a8), []), Var(_param_15, ty=TensorType([32], float32)), Var(_param_16, ty=TensorType([32], float32)), Var(_param_17, ty=TensorType([32], float32)), Var(_param_18, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beb97c8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5a2dd8), []), Var(_param_19, ty=TensorType([32, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c58c458), []), Var(_param_20, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1c49b448), []), Var(_param_21, ty=TensorType([32], float32)), Var(_param_22, ty=TensorType([32], float32)), Var(_param_23, ty=TensorType([32], float32)), Var(_param_24, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beda5a8), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c278a38), []), Var(_param_25, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c4bfd98), []), Var(_param_26, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x1bd814f8), []), Var(_param_27, ty=TensorType([64], float32)), Var(_param_28, ty=TensorType([64], float32)), Var(_param_29, ty=TensorType([64], float32)), Var(_param_30, ty=TensorType([64], float32))], relay.attrs.BatchNormAttrs(0x1bee87f8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c4fb088), []), Var(_param_31, ty=TensorType([64, 64, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c279398), []), Var(_param_32, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x1c538718), []), Var(_param_33, ty=TensorType([64], float32)), Var(_param_34, ty=TensorType([64], float32)), Var(_param_35, ty=TensorType([64], float32)), Var(_param_36, ty=TensorType([64], float32))], relay.attrs.BatchNormAttrs(0x1bef2358), []), 0), TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 512, 512], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bc93d38), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b962568), []), Var(_param_3, ty=TensorType([16], float32)), Var(_param_4, ty=TensorType([16], float32)), Var(_param_5, ty=TensorType([16], float32)), Var(_param_6, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1be816d8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5882d8), []), Var(_param_7, ty=TensorType([16, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd6cb8), []), Var(_param_8, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b9b67e8), []), Var(_param_9, ty=TensorType([16], float32)), Var(_param_10, ty=TensorType([16], float32)), Var(_param_11, ty=TensorType([16], float32)), Var(_param_12, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1c42aa18), []), 0)], relay.attrs.MaxPool2DAttrs(0x1c591bd8), []), Var(_param_13, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd5de8), []), Var(_param_14, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1be0c7a8), []), Var(_param_15, ty=TensorType([32], float32)), Var(_param_16, ty=TensorType([32], float32)), Var(_param_17, ty=TensorType([32], float32)), Var(_param_18, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beb97c8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5a2dd8), []), Var(_param_19, ty=TensorType([32, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1c58c458), []), Var(_param_20, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x1c49b448), []), Var(_param_21, ty=TensorType([32], float32)), Var(_param_22, ty=TensorType([32], float32)), Var(_param_23, ty=TensorType([32], float32)), Var(_param_24, ty=TensorType([32], float32))], relay.attrs.BatchNormAttrs(0x1beda5a8), []), 0), TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.leaky_relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 512, 512], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bc93d38), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b962568), []), Var(_param_3, ty=TensorType([16], float32)), Var(_param_4, ty=TensorType([16], float32)), Var(_param_5, ty=TensorType([16], float32)), Var(_param_6, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1be816d8), []), 0)], relay.attrs.LeakyReluAttrs(0x1c5882d8), []), Var(_param_7, ty=TensorType([16, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x1bcd6cb8), []), Var(_param_8, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x1b9b67e8), []), Var(_param_9, ty=TensorType([16], float32)), Var(_param_10, ty=TensorType([16], float32)), Var(_param_11, ty=TensorType([16], float32)), Var(_param_12, ty=TensorType([16], float32))], relay.attrs.BatchNormAttrs(0x1c42aa18), []), 0)]\n"
     ]
    }
   ],
   "source": [
    "upp = UnetPreProcessCallback()\n",
    "out = rewrite(upp, mod['main'])\n",
    "print(\"==============\")\n",
    "print(upp.target_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {\n",
      "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %1 = nn.bias_add(%0, %v_param_2);\n",
      "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
      "  %3 = %2.0;\n",
      "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
      "  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %6 = nn.bias_add(%5, %v_param_8);\n",
      "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
      "  %8 = %7.0;\n",
      "  %9 = nn.max_pool2d(%8, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %10 = nn.conv2d(%9, %v_param_13, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %11 = nn.bias_add(%10, %v_param_14);\n",
      "  %12 = nn.batch_norm(%11, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);\n",
      "  %13 = %12.0;\n",
      "  %14 = nn.leaky_relu(%13, alpha=0.2f);\n",
      "  %15 = nn.conv2d(%14, %v_param_19, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %16 = nn.bias_add(%15, %v_param_20);\n",
      "  %17 = nn.batch_norm(%16, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);\n",
      "  %18 = %17.0;\n",
      "  %19 = nn.max_pool2d(%18, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %20 = nn.conv2d(%19, %v_param_25, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %21 = nn.bias_add(%20, %v_param_26);\n",
      "  %22 = nn.batch_norm(%21, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);\n",
      "  %23 = %22.0;\n",
      "  %24 = nn.leaky_relu(%23, alpha=0.2f);\n",
      "  %25 = nn.conv2d(%24, %v_param_31, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %26 = nn.bias_add(%25, %v_param_32);\n",
      "  %27 = nn.batch_norm(%26, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);\n",
      "  %28 = %27.0;\n",
      "  %29 = nn.max_pool2d(%28, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %30 = nn.conv2d(%29, %v_param_37, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %31 = nn.bias_add(%30, %v_param_38);\n",
      "  %32 = nn.batch_norm(%31, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);\n",
      "  %33 = %32.0;\n",
      "  %34 = nn.leaky_relu(%33, alpha=0.2f);\n",
      "  %35 = nn.conv2d(%34, %v_param_43, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %36 = nn.bias_add(%35, %v_param_44);\n",
      "  %37 = nn.batch_norm(%36, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);\n",
      "  %38 = %37.0;\n",
      "  %39 = nn.max_pool2d(%38, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %40 = nn.conv2d(%39, %v_param_49, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %41 = nn.bias_add(%40, %v_param_50);\n",
      "  %42 = nn.batch_norm(%41, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);\n",
      "  %43 = %42.0;\n",
      "  %44 = nn.leaky_relu(%43, alpha=0.2f);\n",
      "  %45 = nn.conv2d(%44, %v_param_55, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %46 = nn.bias_add(%45, %v_param_56);\n",
      "  %47 = nn.batch_norm(%46, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);\n",
      "  %48 = %47.0;\n",
      "  %49 = nn.conv2d_transpose(%48, %v_param_61, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %50 = nn.bias_add(%49, %v_param_62);\n",
      "  %51 = nn.batch_norm(%50, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);\n",
      "  %52 = %51.0;\n",
      "  %53 = annotation.stop_fusion(%38);\n",
      "  %54 = cast(%53, dtype=\"int32\");\n",
      "  %55 = add(%54, 512);\n",
      "  %56 = right_shift(%55, 10);\n",
      "  %57 = clip(%56, a_min=-127f, a_max=127f);\n",
      "  %58 = nn.leaky_relu(%52, alpha=0.2f);\n",
      "  %59 = cast(%57, dtype=\"float32\");\n",
      "  %60 = (%58, %59);\n",
      "  %61 = concatenate(%60, axis=1);\n",
      "  %62 = nn.conv2d(%61, %v_param_67, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %63 = nn.bias_add(%62, %v_param_68);\n",
      "  %64 = nn.batch_norm(%63, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);\n",
      "  %65 = %64.0;\n",
      "  %66 = nn.leaky_relu(%65, alpha=0.2f);\n",
      "  %67 = nn.conv2d(%66, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %68 = nn.bias_add(%67, %v_param_74);\n",
      "  %69 = nn.batch_norm(%68, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);\n",
      "  %70 = %69.0;\n",
      "  %71 = nn.conv2d_transpose(%70, %v_param_79, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %72 = nn.bias_add(%71, %v_param_80);\n",
      "  %73 = nn.batch_norm(%72, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);\n",
      "  %74 = %73.0;\n",
      "  %75 = annotation.stop_fusion(%28);\n",
      "  %76 = cast(%75, dtype=\"int32\");\n",
      "  %77 = add(%76, 512);\n",
      "  %78 = right_shift(%77, 10);\n",
      "  %79 = clip(%78, a_min=-127f, a_max=127f);\n",
      "  %80 = nn.leaky_relu(%74, alpha=0.2f);\n",
      "  %81 = cast(%79, dtype=\"float32\");\n",
      "  %82 = (%80, %81);\n",
      "  %83 = concatenate(%82, axis=1);\n",
      "  %84 = nn.conv2d(%83, %v_param_85, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %85 = nn.bias_add(%84, %v_param_86);\n",
      "  %86 = nn.batch_norm(%85, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);\n",
      "  %87 = %86.0;\n",
      "  %88 = nn.leaky_relu(%87, alpha=0.2f);\n",
      "  %89 = nn.conv2d(%88, %v_param_91, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %90 = nn.bias_add(%89, %v_param_92);\n",
      "  %91 = nn.batch_norm(%90, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);\n",
      "  %92 = %91.0;\n",
      "  %93 = nn.conv2d_transpose(%92, %v_param_97, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %94 = nn.bias_add(%93, %v_param_98);\n",
      "  %95 = nn.batch_norm(%94, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);\n",
      "  %96 = %95.0;\n",
      "  %97 = annotation.stop_fusion(%18);\n",
      "  %98 = cast(%97, dtype=\"int32\");\n",
      "  %99 = add(%98, 512);\n",
      "  %100 = right_shift(%99, 10);\n",
      "  %101 = clip(%100, a_min=-127f, a_max=127f);\n",
      "  %102 = nn.leaky_relu(%96, alpha=0.2f);\n",
      "  %103 = cast(%101, dtype=\"float32\");\n",
      "  %104 = (%102, %103);\n",
      "  %105 = concatenate(%104, axis=1);\n",
      "  %106 = nn.conv2d(%105, %v_param_103, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %107 = nn.bias_add(%106, %v_param_104);\n",
      "  %108 = nn.batch_norm(%107, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);\n",
      "  %109 = %108.0;\n",
      "  %110 = nn.leaky_relu(%109, alpha=0.2f);\n",
      "  %111 = nn.conv2d(%110, %v_param_109, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %112 = nn.bias_add(%111, %v_param_110);\n",
      "  %113 = nn.batch_norm(%112, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);\n",
      "  %114 = %113.0;\n",
      "  %115 = nn.conv2d_transpose(%114, %v_param_115, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %116 = nn.bias_add(%115, %v_param_116);\n",
      "  %117 = nn.batch_norm(%116, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);\n",
      "  %118 = %117.0;\n",
      "  %119 = annotation.stop_fusion(%8);\n",
      "  %120 = cast(%119, dtype=\"int32\");\n",
      "  %121 = add(%120, 512);\n",
      "  %122 = right_shift(%121, 10);\n",
      "  %123 = clip(%122, a_min=-127f, a_max=127f);\n",
      "  %124 = nn.leaky_relu(%118, alpha=0.2f);\n",
      "  %125 = cast(%123, dtype=\"float32\");\n",
      "  %126 = (%124, %125);\n",
      "  %127 = concatenate(%126, axis=1);\n",
      "  %128 = nn.conv2d(%127, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %129 = nn.bias_add(%128, %v_param_122);\n",
      "  %130 = nn.batch_norm(%129, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);\n",
      "  %131 = %130.0;\n",
      "  %132 = nn.leaky_relu(%131, alpha=0.2f);\n",
      "  %133 = nn.conv2d(%132, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %134 = nn.bias_add(%133, %v_param_128);\n",
      "  %135 = nn.batch_norm(%134, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);\n",
      "  %136 = %135.0;\n",
      "  %137 = nn.conv2d(%136, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);\n",
      "  %138 = nn.bias_add(%137, %v_param_134);\n",
      "  sigmoid(%138)\n",
      "}\n",
      "==============\n",
      "fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {\n",
      "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %1 = nn.bias_add(%0, %v_param_2);\n",
      "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
      "  %3 = %2.0;\n",
      "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
      "  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %6 = nn.bias_add(%5, %v_param_8);\n",
      "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
      "  %8 = %7.0;\n",
      "  %9 = multiply(%8, 16f);\n",
      "  %10 = round(%9);\n",
      "  %11 = clip(%10, a_min=-127f, a_max=127f);\n",
      "  %12 = cast(%11, dtype=\"int8\");\n",
      "  %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %14 = nn.conv2d(%13, %v_param_13, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %15 = nn.bias_add(%14, %v_param_14);\n",
      "  %16 = nn.batch_norm(%15, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);\n",
      "  %17 = %16.0;\n",
      "  %18 = nn.leaky_relu(%17, alpha=0.2f);\n",
      "  %19 = nn.conv2d(%18, %v_param_19, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %20 = nn.bias_add(%19, %v_param_20);\n",
      "  %21 = nn.batch_norm(%20, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);\n",
      "  %22 = %21.0;\n",
      "  %23 = multiply(%22, 16f);\n",
      "  %24 = round(%23);\n",
      "  %25 = clip(%24, a_min=-127f, a_max=127f);\n",
      "  %26 = cast(%25, dtype=\"int8\");\n",
      "  %27 = nn.max_pool2d(%26, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %28 = nn.conv2d(%27, %v_param_25, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %29 = nn.bias_add(%28, %v_param_26);\n",
      "  %30 = nn.batch_norm(%29, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);\n",
      "  %31 = %30.0;\n",
      "  %32 = nn.leaky_relu(%31, alpha=0.2f);\n",
      "  %33 = nn.conv2d(%32, %v_param_31, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %34 = nn.bias_add(%33, %v_param_32);\n",
      "  %35 = nn.batch_norm(%34, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);\n",
      "  %36 = %35.0;\n",
      "  %37 = multiply(%36, 16f);\n",
      "  %38 = round(%37);\n",
      "  %39 = clip(%38, a_min=-127f, a_max=127f);\n",
      "  %40 = cast(%39, dtype=\"int8\");\n",
      "  %41 = nn.max_pool2d(%40, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %42 = nn.conv2d(%41, %v_param_37, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %43 = nn.bias_add(%42, %v_param_38);\n",
      "  %44 = nn.batch_norm(%43, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);\n",
      "  %45 = %44.0;\n",
      "  %46 = nn.leaky_relu(%45, alpha=0.2f);\n",
      "  %47 = nn.conv2d(%46, %v_param_43, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %48 = nn.bias_add(%47, %v_param_44);\n",
      "  %49 = nn.batch_norm(%48, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);\n",
      "  %50 = %49.0;\n",
      "  %51 = multiply(%50, 16f);\n",
      "  %52 = round(%51);\n",
      "  %53 = clip(%52, a_min=-127f, a_max=127f);\n",
      "  %54 = cast(%53, dtype=\"int8\");\n",
      "  %55 = nn.max_pool2d(%54, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %56 = nn.conv2d(%55, %v_param_49, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %57 = nn.bias_add(%56, %v_param_50);\n",
      "  %58 = nn.batch_norm(%57, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);\n",
      "  %59 = %58.0;\n",
      "  %60 = nn.leaky_relu(%59, alpha=0.2f);\n",
      "  %61 = nn.conv2d(%60, %v_param_55, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %62 = nn.bias_add(%61, %v_param_56);\n",
      "  %63 = nn.batch_norm(%62, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);\n",
      "  %64 = %63.0;\n",
      "  %65 = nn.conv2d_transpose(%64, %v_param_61, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %66 = nn.bias_add(%65, %v_param_62);\n",
      "  %67 = nn.batch_norm(%66, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);\n",
      "  %68 = %67.0;\n",
      "  %69 = annotation.stop_fusion(%54);\n",
      "  %70 = cast(%69, dtype=\"int32\");\n",
      "  %71 = add(%70, 512);\n",
      "  %72 = right_shift(%71, 10);\n",
      "  %73 = clip(%72, a_min=-127f, a_max=127f);\n",
      "  %74 = nn.leaky_relu(%68, alpha=0.2f);\n",
      "  %75 = cast(%73, dtype=\"float32\");\n",
      "  %76 = (%74, %75);\n",
      "  %77 = concatenate(%76, axis=1);\n",
      "  %78 = nn.conv2d(%77, %v_param_67, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %79 = nn.bias_add(%78, %v_param_68);\n",
      "  %80 = nn.batch_norm(%79, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);\n",
      "  %81 = %80.0;\n",
      "  %82 = nn.leaky_relu(%81, alpha=0.2f);\n",
      "  %83 = nn.conv2d(%82, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %84 = nn.bias_add(%83, %v_param_74);\n",
      "  %85 = nn.batch_norm(%84, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);\n",
      "  %86 = %85.0;\n",
      "  %87 = nn.conv2d_transpose(%86, %v_param_79, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %88 = nn.bias_add(%87, %v_param_80);\n",
      "  %89 = nn.batch_norm(%88, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);\n",
      "  %90 = %89.0;\n",
      "  %91 = annotation.stop_fusion(%40);\n",
      "  %92 = cast(%91, dtype=\"int32\");\n",
      "  %93 = add(%92, 512);\n",
      "  %94 = right_shift(%93, 10);\n",
      "  %95 = clip(%94, a_min=-127f, a_max=127f);\n",
      "  %96 = nn.leaky_relu(%90, alpha=0.2f);\n",
      "  %97 = cast(%95, dtype=\"float32\");\n",
      "  %98 = (%96, %97);\n",
      "  %99 = concatenate(%98, axis=1);\n",
      "  %100 = nn.conv2d(%99, %v_param_85, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %101 = nn.bias_add(%100, %v_param_86);\n",
      "  %102 = nn.batch_norm(%101, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);\n",
      "  %103 = %102.0;\n",
      "  %104 = nn.leaky_relu(%103, alpha=0.2f);\n",
      "  %105 = nn.conv2d(%104, %v_param_91, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %106 = nn.bias_add(%105, %v_param_92);\n",
      "  %107 = nn.batch_norm(%106, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);\n",
      "  %108 = %107.0;\n",
      "  %109 = nn.conv2d_transpose(%108, %v_param_97, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %110 = nn.bias_add(%109, %v_param_98);\n",
      "  %111 = nn.batch_norm(%110, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);\n",
      "  %112 = %111.0;\n",
      "  %113 = annotation.stop_fusion(%26);\n",
      "  %114 = cast(%113, dtype=\"int32\");\n",
      "  %115 = add(%114, 512);\n",
      "  %116 = right_shift(%115, 10);\n",
      "  %117 = clip(%116, a_min=-127f, a_max=127f);\n",
      "  %118 = nn.leaky_relu(%112, alpha=0.2f);\n",
      "  %119 = cast(%117, dtype=\"float32\");\n",
      "  %120 = (%118, %119);\n",
      "  %121 = concatenate(%120, axis=1);\n",
      "  %122 = nn.conv2d(%121, %v_param_103, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %123 = nn.bias_add(%122, %v_param_104);\n",
      "  %124 = nn.batch_norm(%123, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);\n",
      "  %125 = %124.0;\n",
      "  %126 = nn.leaky_relu(%125, alpha=0.2f);\n",
      "  %127 = nn.conv2d(%126, %v_param_109, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %128 = nn.bias_add(%127, %v_param_110);\n",
      "  %129 = nn.batch_norm(%128, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);\n",
      "  %130 = %129.0;\n",
      "  %131 = nn.conv2d_transpose(%130, %v_param_115, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %132 = nn.bias_add(%131, %v_param_116);\n",
      "  %133 = nn.batch_norm(%132, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);\n",
      "  %134 = %133.0;\n",
      "  %135 = annotation.stop_fusion(%12);\n",
      "  %136 = cast(%135, dtype=\"int32\");\n",
      "  %137 = add(%136, 512);\n",
      "  %138 = right_shift(%137, 10);\n",
      "  %139 = clip(%138, a_min=-127f, a_max=127f);\n",
      "  %140 = nn.leaky_relu(%134, alpha=0.2f);\n",
      "  %141 = cast(%139, dtype=\"float32\");\n",
      "  %142 = (%140, %141);\n",
      "  %143 = concatenate(%142, axis=1);\n",
      "  %144 = nn.conv2d(%143, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %145 = nn.bias_add(%144, %v_param_122);\n",
      "  %146 = nn.batch_norm(%145, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);\n",
      "  %147 = %146.0;\n",
      "  %148 = nn.leaky_relu(%147, alpha=0.2f);\n",
      "  %149 = nn.conv2d(%148, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %150 = nn.bias_add(%149, %v_param_128);\n",
      "  %151 = nn.batch_norm(%150, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);\n",
      "  %152 = %151.0;\n",
      "  %153 = nn.conv2d(%152, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);\n",
      "  %154 = nn.bias_add(%153, %v_param_134);\n",
      "  sigmoid(%154)\n",
      "}\n",
      "==============\n",
      "==============\n",
      "sex\n",
      "sex\n",
      "sex\n",
      "sex\n",
      "fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {\n",
      "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %1 = nn.bias_add(%0, %v_param_2);\n",
      "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
      "  %3 = %2.0;\n",
      "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
      "  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %6 = nn.bias_add(%5, %v_param_8);\n",
      "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
      "  %8 = %7.0;\n",
      "  %9 = multiply(%8, 16f);\n",
      "  %10 = round(%9);\n",
      "  %11 = clip(%10, a_min=-127f, a_max=127f);\n",
      "  %12 = cast(%11, dtype=\"int8\");\n",
      "  %13 = annotation.stop_fusion(%12);\n",
      "  %14 = cast(%13, dtype=\"int32\");\n",
      "  %15 = add(%14, 512);\n",
      "  %16 = right_shift(%15, 10);\n",
      "  %17 = clip(%16, a_min=-127f, a_max=127f);\n",
      "  %18 = cast(%17, dtype=\"float32\");\n",
      "  %19 = nn.conv2d(%18, %v_param_13, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %20 = nn.bias_add(%19, %v_param_14);\n",
      "  %21 = nn.batch_norm(%20, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f);\n",
      "  %22 = %21.0;\n",
      "  %23 = nn.leaky_relu(%22, alpha=0.2f);\n",
      "  %24 = nn.conv2d(%23, %v_param_19, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %25 = nn.bias_add(%24, %v_param_20);\n",
      "  %26 = nn.batch_norm(%25, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f);\n",
      "  %27 = %26.0;\n",
      "  %28 = multiply(%27, 16f);\n",
      "  %29 = round(%28);\n",
      "  %30 = clip(%29, a_min=-127f, a_max=127f);\n",
      "  %31 = cast(%30, dtype=\"int8\");\n",
      "  %32 = annotation.stop_fusion(%31);\n",
      "  %33 = cast(%32, dtype=\"int32\");\n",
      "  %34 = add(%33, 512);\n",
      "  %35 = right_shift(%34, 10);\n",
      "  %36 = clip(%35, a_min=-127f, a_max=127f);\n",
      "  %37 = cast(%36, dtype=\"float32\");\n",
      "  %38 = nn.conv2d(%37, %v_param_25, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %39 = nn.bias_add(%38, %v_param_26);\n",
      "  %40 = nn.batch_norm(%39, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f);\n",
      "  %41 = %40.0;\n",
      "  %42 = nn.leaky_relu(%41, alpha=0.2f);\n",
      "  %43 = nn.conv2d(%42, %v_param_31, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %44 = nn.bias_add(%43, %v_param_32);\n",
      "  %45 = nn.batch_norm(%44, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f);\n",
      "  %46 = %45.0;\n",
      "  %47 = multiply(%46, 16f);\n",
      "  %48 = round(%47);\n",
      "  %49 = clip(%48, a_min=-127f, a_max=127f);\n",
      "  %50 = cast(%49, dtype=\"int8\");\n",
      "  %51 = annotation.stop_fusion(%50);\n",
      "  %52 = cast(%51, dtype=\"int32\");\n",
      "  %53 = add(%52, 512);\n",
      "  %54 = right_shift(%53, 10);\n",
      "  %55 = clip(%54, a_min=-127f, a_max=127f);\n",
      "  %56 = cast(%55, dtype=\"float32\");\n",
      "  %57 = nn.conv2d(%56, %v_param_37, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %58 = nn.bias_add(%57, %v_param_38);\n",
      "  %59 = nn.batch_norm(%58, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f);\n",
      "  %60 = %59.0;\n",
      "  %61 = nn.leaky_relu(%60, alpha=0.2f);\n",
      "  %62 = nn.conv2d(%61, %v_param_43, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %63 = nn.bias_add(%62, %v_param_44);\n",
      "  %64 = nn.batch_norm(%63, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f);\n",
      "  %65 = %64.0;\n",
      "  %66 = multiply(%65, 16f);\n",
      "  %67 = round(%66);\n",
      "  %68 = clip(%67, a_min=-127f, a_max=127f);\n",
      "  %69 = cast(%68, dtype=\"int8\");\n",
      "  %70 = annotation.stop_fusion(%69);\n",
      "  %71 = cast(%70, dtype=\"int32\");\n",
      "  %72 = add(%71, 512);\n",
      "  %73 = right_shift(%72, 10);\n",
      "  %74 = clip(%73, a_min=-127f, a_max=127f);\n",
      "  %75 = cast(%74, dtype=\"float32\");\n",
      "  %76 = nn.conv2d(%75, %v_param_49, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %77 = nn.bias_add(%76, %v_param_50);\n",
      "  %78 = nn.batch_norm(%77, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f);\n",
      "  %79 = %78.0;\n",
      "  %80 = nn.leaky_relu(%79, alpha=0.2f);\n",
      "  %81 = nn.conv2d(%80, %v_param_55, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %82 = nn.bias_add(%81, %v_param_56);\n",
      "  %83 = nn.batch_norm(%82, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f);\n",
      "  %84 = %83.0;\n",
      "  %85 = nn.conv2d_transpose(%84, %v_param_61, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %86 = nn.bias_add(%85, %v_param_62);\n",
      "  %87 = nn.batch_norm(%86, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f);\n",
      "  %88 = %87.0;\n",
      "  %89 = annotation.stop_fusion(%69);\n",
      "  %90 = cast(%89, dtype=\"int32\");\n",
      "  %91 = add(%90, 512);\n",
      "  %92 = right_shift(%91, 10);\n",
      "  %93 = clip(%92, a_min=-127f, a_max=127f);\n",
      "  %94 = nn.leaky_relu(%88, alpha=0.2f);\n",
      "  %95 = cast(%93, dtype=\"float32\");\n",
      "  %96 = (%94, %95);\n",
      "  %97 = concatenate(%96, axis=1);\n",
      "  %98 = nn.conv2d(%97, %v_param_67, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %99 = nn.bias_add(%98, %v_param_68);\n",
      "  %100 = nn.batch_norm(%99, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f);\n",
      "  %101 = %100.0;\n",
      "  %102 = nn.leaky_relu(%101, alpha=0.2f);\n",
      "  %103 = nn.conv2d(%102, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %104 = nn.bias_add(%103, %v_param_74);\n",
      "  %105 = nn.batch_norm(%104, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f);\n",
      "  %106 = %105.0;\n",
      "  %107 = nn.conv2d_transpose(%106, %v_param_79, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %108 = nn.bias_add(%107, %v_param_80);\n",
      "  %109 = nn.batch_norm(%108, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f);\n",
      "  %110 = %109.0;\n",
      "  %111 = annotation.stop_fusion(%50);\n",
      "  %112 = cast(%111, dtype=\"int32\");\n",
      "  %113 = add(%112, 512);\n",
      "  %114 = right_shift(%113, 10);\n",
      "  %115 = clip(%114, a_min=-127f, a_max=127f);\n",
      "  %116 = nn.leaky_relu(%110, alpha=0.2f);\n",
      "  %117 = cast(%115, dtype=\"float32\");\n",
      "  %118 = (%116, %117);\n",
      "  %119 = concatenate(%118, axis=1);\n",
      "  %120 = nn.conv2d(%119, %v_param_85, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %121 = nn.bias_add(%120, %v_param_86);\n",
      "  %122 = nn.batch_norm(%121, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f);\n",
      "  %123 = %122.0;\n",
      "  %124 = nn.leaky_relu(%123, alpha=0.2f);\n",
      "  %125 = nn.conv2d(%124, %v_param_91, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %126 = nn.bias_add(%125, %v_param_92);\n",
      "  %127 = nn.batch_norm(%126, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f);\n",
      "  %128 = %127.0;\n",
      "  %129 = nn.conv2d_transpose(%128, %v_param_97, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %130 = nn.bias_add(%129, %v_param_98);\n",
      "  %131 = nn.batch_norm(%130, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f);\n",
      "  %132 = %131.0;\n",
      "  %133 = annotation.stop_fusion(%31);\n",
      "  %134 = cast(%133, dtype=\"int32\");\n",
      "  %135 = add(%134, 512);\n",
      "  %136 = right_shift(%135, 10);\n",
      "  %137 = clip(%136, a_min=-127f, a_max=127f);\n",
      "  %138 = nn.leaky_relu(%132, alpha=0.2f);\n",
      "  %139 = cast(%137, dtype=\"float32\");\n",
      "  %140 = (%138, %139);\n",
      "  %141 = concatenate(%140, axis=1);\n",
      "  %142 = nn.conv2d(%141, %v_param_103, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %143 = nn.bias_add(%142, %v_param_104);\n",
      "  %144 = nn.batch_norm(%143, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f);\n",
      "  %145 = %144.0;\n",
      "  %146 = nn.leaky_relu(%145, alpha=0.2f);\n",
      "  %147 = nn.conv2d(%146, %v_param_109, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]);\n",
      "  %148 = nn.bias_add(%147, %v_param_110);\n",
      "  %149 = nn.batch_norm(%148, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f);\n",
      "  %150 = %149.0;\n",
      "  %151 = nn.conv2d_transpose(%150, %v_param_115, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout=\"IOHW\");\n",
      "  %152 = nn.bias_add(%151, %v_param_116);\n",
      "  %153 = nn.batch_norm(%152, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f);\n",
      "  %154 = %153.0;\n",
      "  %155 = annotation.stop_fusion(%12);\n",
      "  %156 = cast(%155, dtype=\"int32\");\n",
      "  %157 = add(%156, 512);\n",
      "  %158 = right_shift(%157, 10);\n",
      "  %159 = clip(%158, a_min=-127f, a_max=127f);\n",
      "  %160 = nn.leaky_relu(%154, alpha=0.2f);\n",
      "  %161 = cast(%159, dtype=\"float32\");\n",
      "  %162 = (%160, %161);\n",
      "  %163 = concatenate(%162, axis=1);\n",
      "  %164 = nn.conv2d(%163, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %165 = nn.bias_add(%164, %v_param_122);\n",
      "  %166 = nn.batch_norm(%165, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);\n",
      "  %167 = %166.0;\n",
      "  %168 = nn.leaky_relu(%167, alpha=0.2f);\n",
      "  %169 = nn.conv2d(%168, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
      "  %170 = nn.bias_add(%169, %v_param_128);\n",
      "  %171 = nn.batch_norm(%170, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);\n",
      "  %172 = %171.0;\n",
      "  %173 = nn.conv2d(%172, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);\n",
      "  %174 = nn.bias_add(%173, %v_param_134);\n",
      "  sigmoid(%174)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "upp = UnetPreProcessCallback()\n",
    "out = rewrite(upp, mod['main'])\n",
    "print(out)\n",
    "print(\"==============\")\n",
    "\n",
    "# out = mod['main']\n",
    "ump = UnetMidProcessCallback(upp.target_node)\n",
    "out = rewrite(ump, out)\n",
    "\n",
    "print(out)\n",
    "print(\"==============\")\n",
    "# ump = UnetMidProcessCallback(upp.target_node)\n",
    "# out = rewrite(ump, out)\n",
    "# upp = UnetPreProcessCallback()\n",
    "# rewrite(upp, out)\n",
    "print(\"==============\")\n",
    "\n",
    "out = rewrite(UnetCallback(ump.target_node_2), out)\n",
    "print(out)\n",
    "\n",
    "\n",
    "# for target_node in list(reversed(upp.target_node)):\n",
    "    # out = rewrite(UnetCallback([target_node]), out)\n",
    "\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%input_1: Tensor[(1, 3, 224, 224), float32], %v_param_1: Tensor[(64, 3, 7, 7), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_19: Tensor[(256, 64, 1, 1), float32], %v_param_20: Tensor[(256), float32], %v_param_23: Tensor[(256), float32], %v_param_24: Tensor[(256), float32], %v_param_25: Tensor[(256), float32], %v_param_26: Tensor[(256), float32], %v_param_7: Tensor[(64, 64, 1, 1), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(64, 64, 3, 3), float32], %v_param_14: Tensor[(64), float32], %v_param_15: Tensor[(64), float32], %v_param_16: Tensor[(64), float32], %v_param_17: Tensor[(64), float32], %v_param_18: Tensor[(64), float32], %v_param_21: Tensor[(256, 64, 1, 1), float32], %v_param_22: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(64, 256, 1, 1), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(64, 64, 3, 3), float32], %v_param_38: Tensor[(64), float32], %v_param_39: Tensor[(64), float32], %v_param_40: Tensor[(64), float32], %v_param_41: Tensor[(64), float32], %v_param_42: Tensor[(64), float32], %v_param_43: Tensor[(256, 64, 1, 1), float32], %v_param_44: Tensor[(256), float32], %v_param_45: Tensor[(256), float32], %v_param_46: Tensor[(256), float32], %v_param_47: Tensor[(256), float32], %v_param_48: Tensor[(256), float32], %v_param_49: Tensor[(64, 256, 1, 1), float32], %v_param_50: Tensor[(64), float32], %v_param_51: Tensor[(64), float32], %v_param_52: Tensor[(64), float32], %v_param_53: Tensor[(64), float32], %v_param_54: Tensor[(64), float32], %v_param_55: Tensor[(64, 64, 3, 3), float32], %v_param_56: Tensor[(64), float32], %v_param_57: Tensor[(64), float32], %v_param_58: Tensor[(64), float32], %v_param_59: Tensor[(64), float32], %v_param_60: Tensor[(64), float32], %v_param_61: Tensor[(256, 64, 1, 1), float32], %v_param_62: Tensor[(256), float32], %v_param_63: Tensor[(256), float32], %v_param_64: Tensor[(256), float32], %v_param_65: Tensor[(256), float32], %v_param_66: Tensor[(256), float32], %v_param_79: Tensor[(512, 256, 1, 1), float32], %v_param_80: Tensor[(512), float32], %v_param_83: Tensor[(512), float32], %v_param_84: Tensor[(512), float32], %v_param_85: Tensor[(512), float32], %v_param_86: Tensor[(512), float32], %v_param_67: Tensor[(128, 256, 1, 1), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_81: Tensor[(512, 128, 1, 1), float32], %v_param_82: Tensor[(512), float32], %v_param_87: Tensor[(512), float32], %v_param_88: Tensor[(512), float32], %v_param_89: Tensor[(512), float32], %v_param_90: Tensor[(512), float32], %v_param_91: Tensor[(128, 512, 1, 1), float32], %v_param_92: Tensor[(128), float32], %v_param_93: Tensor[(128), float32], %v_param_94: Tensor[(128), float32], %v_param_95: Tensor[(128), float32], %v_param_96: Tensor[(128), float32], %v_param_97: Tensor[(128, 128, 3, 3), float32], %v_param_98: Tensor[(128), float32], %v_param_99: Tensor[(128), float32], %v_param_100: Tensor[(128), float32], %v_param_101: Tensor[(128), float32], %v_param_102: Tensor[(128), float32], %v_param_103: Tensor[(512, 128, 1, 1), float32], %v_param_104: Tensor[(512), float32], %v_param_105: Tensor[(512), float32], %v_param_106: Tensor[(512), float32], %v_param_107: Tensor[(512), float32], %v_param_108: Tensor[(512), float32], %v_param_109: Tensor[(128, 512, 1, 1), float32], %v_param_110: Tensor[(128), float32], %v_param_111: Tensor[(128), float32], %v_param_112: Tensor[(128), float32], %v_param_113: Tensor[(128), float32], %v_param_114: Tensor[(128), float32], %v_param_115: Tensor[(128, 128, 3, 3), float32], %v_param_116: Tensor[(128), float32], %v_param_117: Tensor[(128), float32], %v_param_118: Tensor[(128), float32], %v_param_119: Tensor[(128), float32], %v_param_120: Tensor[(128), float32], %v_param_121: Tensor[(512, 128, 1, 1), float32], %v_param_122: Tensor[(512), float32], %v_param_123: Tensor[(512), float32], %v_param_124: Tensor[(512), float32], %v_param_125: Tensor[(512), float32], %v_param_126: Tensor[(512), float32], %v_param_127: Tensor[(128, 512, 1, 1), float32], %v_param_128: Tensor[(128), float32], %v_param_129: Tensor[(128), float32], %v_param_130: Tensor[(128), float32], %v_param_131: Tensor[(128), float32], %v_param_132: Tensor[(128), float32], %v_param_133: Tensor[(128, 128, 3, 3), float32], %v_param_134: Tensor[(128), float32], %v_param_135: Tensor[(128), float32], %v_param_136: Tensor[(128), float32], %v_param_137: Tensor[(128), float32], %v_param_138: Tensor[(128), float32], %v_param_139: Tensor[(512, 128, 1, 1), float32], %v_param_140: Tensor[(512), float32], %v_param_141: Tensor[(512), float32], %v_param_142: Tensor[(512), float32], %v_param_143: Tensor[(512), float32], %v_param_144: Tensor[(512), float32], %v_param_145: Tensor[(128, 512, 1, 1), float32], %v_param_146: Tensor[(128), float32], %v_param_147: Tensor[(128), float32], %v_param_148: Tensor[(128), float32], %v_param_149: Tensor[(128), float32], %v_param_150: Tensor[(128), float32], %v_param_151: Tensor[(128, 128, 3, 3), float32], %v_param_152: Tensor[(128), float32], %v_param_153: Tensor[(128), float32], %v_param_154: Tensor[(128), float32], %v_param_155: Tensor[(128), float32], %v_param_156: Tensor[(128), float32], %v_param_157: Tensor[(512, 128, 1, 1), float32], %v_param_158: Tensor[(512), float32], %v_param_159: Tensor[(512), float32], %v_param_160: Tensor[(512), float32], %v_param_161: Tensor[(512), float32], %v_param_162: Tensor[(512), float32], %v_param_163: Tensor[(128, 512, 1, 1), float32], %v_param_164: Tensor[(128), float32], %v_param_165: Tensor[(128), float32], %v_param_166: Tensor[(128), float32], %v_param_167: Tensor[(128), float32], %v_param_168: Tensor[(128), float32], %v_param_169: Tensor[(128, 128, 3, 3), float32], %v_param_170: Tensor[(128), float32], %v_param_171: Tensor[(128), float32], %v_param_172: Tensor[(128), float32], %v_param_173: Tensor[(128), float32], %v_param_174: Tensor[(128), float32], %v_param_175: Tensor[(512, 128, 1, 1), float32], %v_param_176: Tensor[(512), float32], %v_param_177: Tensor[(512), float32], %v_param_178: Tensor[(512), float32], %v_param_179: Tensor[(512), float32], %v_param_180: Tensor[(512), float32], %v_param_181: Tensor[(128, 512, 1, 1), float32], %v_param_182: Tensor[(128), float32], %v_param_183: Tensor[(128), float32], %v_param_184: Tensor[(128), float32], %v_param_185: Tensor[(128), float32], %v_param_186: Tensor[(128), float32], %v_param_187: Tensor[(128, 128, 3, 3), float32], %v_param_188: Tensor[(128), float32], %v_param_189: Tensor[(128), float32], %v_param_190: Tensor[(128), float32], %v_param_191: Tensor[(128), float32], %v_param_192: Tensor[(128), float32], %v_param_193: Tensor[(512, 128, 1, 1), float32], %v_param_194: Tensor[(512), float32], %v_param_195: Tensor[(512), float32], %v_param_196: Tensor[(512), float32], %v_param_197: Tensor[(512), float32], %v_param_198: Tensor[(512), float32], %v_param_199: Tensor[(128, 512, 1, 1), float32], %v_param_200: Tensor[(128), float32], %v_param_201: Tensor[(128), float32], %v_param_202: Tensor[(128), float32], %v_param_203: Tensor[(128), float32], %v_param_204: Tensor[(128), float32], %v_param_205: Tensor[(128, 128, 3, 3), float32], %v_param_206: Tensor[(128), float32], %v_param_207: Tensor[(128), float32], %v_param_208: Tensor[(128), float32], %v_param_209: Tensor[(128), float32], %v_param_210: Tensor[(128), float32], %v_param_211: Tensor[(512, 128, 1, 1), float32], %v_param_212: Tensor[(512), float32], %v_param_213: Tensor[(512), float32], %v_param_214: Tensor[(512), float32], %v_param_215: Tensor[(512), float32], %v_param_216: Tensor[(512), float32], %v_param_229: Tensor[(1024, 512, 1, 1), float32], %v_param_230: Tensor[(1024), float32], %v_param_233: Tensor[(1024), float32], %v_param_234: Tensor[(1024), float32], %v_param_235: Tensor[(1024), float32], %v_param_236: Tensor[(1024), float32], %v_param_217: Tensor[(256, 512, 1, 1), float32], %v_param_218: Tensor[(256), float32], %v_param_219: Tensor[(256), float32], %v_param_220: Tensor[(256), float32], %v_param_221: Tensor[(256), float32], %v_param_222: Tensor[(256), float32], %v_param_223: Tensor[(256, 256, 3, 3), float32], %v_param_224: Tensor[(256), float32], %v_param_225: Tensor[(256), float32], %v_param_226: Tensor[(256), float32], %v_param_227: Tensor[(256), float32], %v_param_228: Tensor[(256), float32], %v_param_231: Tensor[(1024, 256, 1, 1), float32], %v_param_232: Tensor[(1024), float32], %v_param_237: Tensor[(1024), float32], %v_param_238: Tensor[(1024), float32], %v_param_239: Tensor[(1024), float32], %v_param_240: Tensor[(1024), float32], %v_param_241: Tensor[(256, 1024, 1, 1), float32], %v_param_242: Tensor[(256), float32], %v_param_243: Tensor[(256), float32], %v_param_244: Tensor[(256), float32], %v_param_245: Tensor[(256), float32], %v_param_246: Tensor[(256), float32], %v_param_247: Tensor[(256, 256, 3, 3), float32], %v_param_248: Tensor[(256), float32], %v_param_249: Tensor[(256), float32], %v_param_250: Tensor[(256), float32], %v_param_251: Tensor[(256), float32], %v_param_252: Tensor[(256), float32], %v_param_253: Tensor[(1024, 256, 1, 1), float32], %v_param_254: Tensor[(1024), float32], %v_param_255: Tensor[(1024), float32], %v_param_256: Tensor[(1024), float32], %v_param_257: Tensor[(1024), float32], %v_param_258: Tensor[(1024), float32], %v_param_259: Tensor[(256, 1024, 1, 1), float32], %v_param_260: Tensor[(256), float32], %v_param_261: Tensor[(256), float32], %v_param_262: Tensor[(256), float32], %v_param_263: Tensor[(256), float32], %v_param_264: Tensor[(256), float32], %v_param_265: Tensor[(256, 256, 3, 3), float32], %v_param_266: Tensor[(256), float32], %v_param_267: Tensor[(256), float32], %v_param_268: Tensor[(256), float32], %v_param_269: Tensor[(256), float32], %v_param_270: Tensor[(256), float32], %v_param_271: Tensor[(1024, 256, 1, 1), float32], %v_param_272: Tensor[(1024), float32], %v_param_273: Tensor[(1024), float32], %v_param_274: Tensor[(1024), float32], %v_param_275: Tensor[(1024), float32], %v_param_276: Tensor[(1024), float32], %v_param_277: Tensor[(256, 1024, 1, 1), float32], %v_param_278: Tensor[(256), float32], %v_param_279: Tensor[(256), float32], %v_param_280: Tensor[(256), float32], %v_param_281: Tensor[(256), float32], %v_param_282: Tensor[(256), float32], %v_param_283: Tensor[(256, 256, 3, 3), float32], %v_param_284: Tensor[(256), float32], %v_param_285: Tensor[(256), float32], %v_param_286: Tensor[(256), float32], %v_param_287: Tensor[(256), float32], %v_param_288: Tensor[(256), float32], %v_param_289: Tensor[(1024, 256, 1, 1), float32], %v_param_290: Tensor[(1024), float32], %v_param_291: Tensor[(1024), float32], %v_param_292: Tensor[(1024), float32], %v_param_293: Tensor[(1024), float32], %v_param_294: Tensor[(1024), float32], %v_param_295: Tensor[(256, 1024, 1, 1), float32], %v_param_296: Tensor[(256), float32], %v_param_297: Tensor[(256), float32], %v_param_298: Tensor[(256), float32], %v_param_299: Tensor[(256), float32], %v_param_300: Tensor[(256), float32], %v_param_301: Tensor[(256, 256, 3, 3), float32], %v_param_302: Tensor[(256), float32], %v_param_303: Tensor[(256), float32], %v_param_304: Tensor[(256), float32], %v_param_305: Tensor[(256), float32], %v_param_306: Tensor[(256), float32], %v_param_307: Tensor[(1024, 256, 1, 1), float32], %v_param_308: Tensor[(1024), float32], %v_param_309: Tensor[(1024), float32], %v_param_310: Tensor[(1024), float32], %v_param_311: Tensor[(1024), float32], %v_param_312: Tensor[(1024), float32], %v_param_313: Tensor[(256, 1024, 1, 1), float32], %v_param_314: Tensor[(256), float32], %v_param_315: Tensor[(256), float32], %v_param_316: Tensor[(256), float32], %v_param_317: Tensor[(256), float32], %v_param_318: Tensor[(256), float32], %v_param_319: Tensor[(256, 256, 3, 3), float32], %v_param_320: Tensor[(256), float32], %v_param_321: Tensor[(256), float32], %v_param_322: Tensor[(256), float32], %v_param_323: Tensor[(256), float32], %v_param_324: Tensor[(256), float32], %v_param_325: Tensor[(1024, 256, 1, 1), float32], %v_param_326: Tensor[(1024), float32], %v_param_327: Tensor[(1024), float32], %v_param_328: Tensor[(1024), float32], %v_param_329: Tensor[(1024), float32], %v_param_330: Tensor[(1024), float32], %v_param_331: Tensor[(256, 1024, 1, 1), float32], %v_param_332: Tensor[(256), float32], %v_param_333: Tensor[(256), float32], %v_param_334: Tensor[(256), float32], %v_param_335: Tensor[(256), float32], %v_param_336: Tensor[(256), float32], %v_param_337: Tensor[(256, 256, 3, 3), float32], %v_param_338: Tensor[(256), float32], %v_param_339: Tensor[(256), float32], %v_param_340: Tensor[(256), float32], %v_param_341: Tensor[(256), float32], %v_param_342: Tensor[(256), float32], %v_param_343: Tensor[(1024, 256, 1, 1), float32], %v_param_344: Tensor[(1024), float32], %v_param_345: Tensor[(1024), float32], %v_param_346: Tensor[(1024), float32], %v_param_347: Tensor[(1024), float32], %v_param_348: Tensor[(1024), float32], %v_param_349: Tensor[(256, 1024, 1, 1), float32], %v_param_350: Tensor[(256), float32], %v_param_351: Tensor[(256), float32], %v_param_352: Tensor[(256), float32], %v_param_353: Tensor[(256), float32], %v_param_354: Tensor[(256), float32], %v_param_355: Tensor[(256, 256, 3, 3), float32], %v_param_356: Tensor[(256), float32], %v_param_357: Tensor[(256), float32], %v_param_358: Tensor[(256), float32], %v_param_359: Tensor[(256), float32], %v_param_360: Tensor[(256), float32], %v_param_361: Tensor[(1024, 256, 1, 1), float32], %v_param_362: Tensor[(1024), float32], %v_param_363: Tensor[(1024), float32], %v_param_364: Tensor[(1024), float32], %v_param_365: Tensor[(1024), float32], %v_param_366: Tensor[(1024), float32], %v_param_367: Tensor[(256, 1024, 1, 1), float32], %v_param_368: Tensor[(256), float32], %v_param_369: Tensor[(256), float32], %v_param_370: Tensor[(256), float32], %v_param_371: Tensor[(256), float32], %v_param_372: Tensor[(256), float32], %v_param_373: Tensor[(256, 256, 3, 3), float32], %v_param_374: Tensor[(256), float32], %v_param_375: Tensor[(256), float32], %v_param_376: Tensor[(256), float32], %v_param_377: Tensor[(256), float32], %v_param_378: Tensor[(256), float32], %v_param_379: Tensor[(1024, 256, 1, 1), float32], %v_param_380: Tensor[(1024), float32], %v_param_381: Tensor[(1024), float32], %v_param_382: Tensor[(1024), float32], %v_param_383: Tensor[(1024), float32], %v_param_384: Tensor[(1024), float32], %v_param_385: Tensor[(256, 1024, 1, 1), float32], %v_param_386: Tensor[(256), float32], %v_param_387: Tensor[(256), float32], %v_param_388: Tensor[(256), float32], %v_param_389: Tensor[(256), float32], %v_param_390: Tensor[(256), float32], %v_param_391: Tensor[(256, 256, 3, 3), float32], %v_param_392: Tensor[(256), float32], %v_param_393: Tensor[(256), float32], %v_param_394: Tensor[(256), float32], %v_param_395: Tensor[(256), float32], %v_param_396: Tensor[(256), float32], %v_param_397: Tensor[(1024, 256, 1, 1), float32], %v_param_398: Tensor[(1024), float32], %v_param_399: Tensor[(1024), float32], %v_param_400: Tensor[(1024), float32], %v_param_401: Tensor[(1024), float32], %v_param_402: Tensor[(1024), float32], %v_param_403: Tensor[(256, 1024, 1, 1), float32], %v_param_404: Tensor[(256), float32], %v_param_405: Tensor[(256), float32], %v_param_406: Tensor[(256), float32], %v_param_407: Tensor[(256), float32], %v_param_408: Tensor[(256), float32], %v_param_409: Tensor[(256, 256, 3, 3), float32], %v_param_410: Tensor[(256), float32], %v_param_411: Tensor[(256), float32], %v_param_412: Tensor[(256), float32], %v_param_413: Tensor[(256), float32], %v_param_414: Tensor[(256), float32], %v_param_415: Tensor[(1024, 256, 1, 1), float32], %v_param_416: Tensor[(1024), float32], %v_param_417: Tensor[(1024), float32], %v_param_418: Tensor[(1024), float32], %v_param_419: Tensor[(1024), float32], %v_param_420: Tensor[(1024), float32], %v_param_421: Tensor[(256, 1024, 1, 1), float32], %v_param_422: Tensor[(256), float32], %v_param_423: Tensor[(256), float32], %v_param_424: Tensor[(256), float32], %v_param_425: Tensor[(256), float32], %v_param_426: Tensor[(256), float32], %v_param_427: Tensor[(256, 256, 3, 3), float32], %v_param_428: Tensor[(256), float32], %v_param_429: Tensor[(256), float32], %v_param_430: Tensor[(256), float32], %v_param_431: Tensor[(256), float32], %v_param_432: Tensor[(256), float32], %v_param_433: Tensor[(1024, 256, 1, 1), float32], %v_param_434: Tensor[(1024), float32], %v_param_435: Tensor[(1024), float32], %v_param_436: Tensor[(1024), float32], %v_param_437: Tensor[(1024), float32], %v_param_438: Tensor[(1024), float32], %v_param_439: Tensor[(256, 1024, 1, 1), float32], %v_param_440: Tensor[(256), float32], %v_param_441: Tensor[(256), float32], %v_param_442: Tensor[(256), float32], %v_param_443: Tensor[(256), float32], %v_param_444: Tensor[(256), float32], %v_param_445: Tensor[(256, 256, 3, 3), float32], %v_param_446: Tensor[(256), float32], %v_param_447: Tensor[(256), float32], %v_param_448: Tensor[(256), float32], %v_param_449: Tensor[(256), float32], %v_param_450: Tensor[(256), float32], %v_param_451: Tensor[(1024, 256, 1, 1), float32], %v_param_452: Tensor[(1024), float32], %v_param_453: Tensor[(1024), float32], %v_param_454: Tensor[(1024), float32], %v_param_455: Tensor[(1024), float32], %v_param_456: Tensor[(1024), float32], %v_param_457: Tensor[(256, 1024, 1, 1), float32], %v_param_458: Tensor[(256), float32], %v_param_459: Tensor[(256), float32], %v_param_460: Tensor[(256), float32], %v_param_461: Tensor[(256), float32], %v_param_462: Tensor[(256), float32], %v_param_463: Tensor[(256, 256, 3, 3), float32], %v_param_464: Tensor[(256), float32], %v_param_465: Tensor[(256), float32], %v_param_466: Tensor[(256), float32], %v_param_467: Tensor[(256), float32], %v_param_468: Tensor[(256), float32], %v_param_469: Tensor[(1024, 256, 1, 1), float32], %v_param_470: Tensor[(1024), float32], %v_param_471: Tensor[(1024), float32], %v_param_472: Tensor[(1024), float32], %v_param_473: Tensor[(1024), float32], %v_param_474: Tensor[(1024), float32], %v_param_475: Tensor[(256, 1024, 1, 1), float32], %v_param_476: Tensor[(256), float32], %v_param_477: Tensor[(256), float32], %v_param_478: Tensor[(256), float32], %v_param_479: Tensor[(256), float32], %v_param_480: Tensor[(256), float32], %v_param_481: Tensor[(256, 256, 3, 3), float32], %v_param_482: Tensor[(256), float32], %v_param_483: Tensor[(256), float32], %v_param_484: Tensor[(256), float32], %v_param_485: Tensor[(256), float32], %v_param_486: Tensor[(256), float32], %v_param_487: Tensor[(1024, 256, 1, 1), float32], %v_param_488: Tensor[(1024), float32], %v_param_489: Tensor[(1024), float32], %v_param_490: Tensor[(1024), float32], %v_param_491: Tensor[(1024), float32], %v_param_492: Tensor[(1024), float32], %v_param_493: Tensor[(256, 1024, 1, 1), float32], %v_param_494: Tensor[(256), float32], %v_param_495: Tensor[(256), float32], %v_param_496: Tensor[(256), float32], %v_param_497: Tensor[(256), float32], %v_param_498: Tensor[(256), float32], %v_param_499: Tensor[(256, 256, 3, 3), float32], %v_param_500: Tensor[(256), float32], %v_param_501: Tensor[(256), float32], %v_param_502: Tensor[(256), float32], %v_param_503: Tensor[(256), float32], %v_param_504: Tensor[(256), float32], %v_param_505: Tensor[(1024, 256, 1, 1), float32], %v_param_506: Tensor[(1024), float32], %v_param_507: Tensor[(1024), float32], %v_param_508: Tensor[(1024), float32], %v_param_509: Tensor[(1024), float32], %v_param_510: Tensor[(1024), float32], %v_param_511: Tensor[(256, 1024, 1, 1), float32], %v_param_512: Tensor[(256), float32], %v_param_513: Tensor[(256), float32], %v_param_514: Tensor[(256), float32], %v_param_515: Tensor[(256), float32], %v_param_516: Tensor[(256), float32], %v_param_517: Tensor[(256, 256, 3, 3), float32], %v_param_518: Tensor[(256), float32], %v_param_519: Tensor[(256), float32], %v_param_520: Tensor[(256), float32], %v_param_521: Tensor[(256), float32], %v_param_522: Tensor[(256), float32], %v_param_523: Tensor[(1024, 256, 1, 1), float32], %v_param_524: Tensor[(1024), float32], %v_param_525: Tensor[(1024), float32], %v_param_526: Tensor[(1024), float32], %v_param_527: Tensor[(1024), float32], %v_param_528: Tensor[(1024), float32], %v_param_529: Tensor[(256, 1024, 1, 1), float32], %v_param_530: Tensor[(256), float32], %v_param_531: Tensor[(256), float32], %v_param_532: Tensor[(256), float32], %v_param_533: Tensor[(256), float32], %v_param_534: Tensor[(256), float32], %v_param_535: Tensor[(256, 256, 3, 3), float32], %v_param_536: Tensor[(256), float32], %v_param_537: Tensor[(256), float32], %v_param_538: Tensor[(256), float32], %v_param_539: Tensor[(256), float32], %v_param_540: Tensor[(256), float32], %v_param_541: Tensor[(1024, 256, 1, 1), float32], %v_param_542: Tensor[(1024), float32], %v_param_543: Tensor[(1024), float32], %v_param_544: Tensor[(1024), float32], %v_param_545: Tensor[(1024), float32], %v_param_546: Tensor[(1024), float32], %v_param_547: Tensor[(256, 1024, 1, 1), float32], %v_param_548: Tensor[(256), float32], %v_param_549: Tensor[(256), float32], %v_param_550: Tensor[(256), float32], %v_param_551: Tensor[(256), float32], %v_param_552: Tensor[(256), float32], %v_param_553: Tensor[(256, 256, 3, 3), float32], %v_param_554: Tensor[(256), float32], %v_param_555: Tensor[(256), float32], %v_param_556: Tensor[(256), float32], %v_param_557: Tensor[(256), float32], %v_param_558: Tensor[(256), float32], %v_param_559: Tensor[(1024, 256, 1, 1), float32], %v_param_560: Tensor[(1024), float32], %v_param_561: Tensor[(1024), float32], %v_param_562: Tensor[(1024), float32], %v_param_563: Tensor[(1024), float32], %v_param_564: Tensor[(1024), float32], %v_param_565: Tensor[(256, 1024, 1, 1), float32], %v_param_566: Tensor[(256), float32], %v_param_567: Tensor[(256), float32], %v_param_568: Tensor[(256), float32], %v_param_569: Tensor[(256), float32], %v_param_570: Tensor[(256), float32], %v_param_571: Tensor[(256, 256, 3, 3), float32], %v_param_572: Tensor[(256), float32], %v_param_573: Tensor[(256), float32], %v_param_574: Tensor[(256), float32], %v_param_575: Tensor[(256), float32], %v_param_576: Tensor[(256), float32], %v_param_577: Tensor[(1024, 256, 1, 1), float32], %v_param_578: Tensor[(1024), float32], %v_param_579: Tensor[(1024), float32], %v_param_580: Tensor[(1024), float32], %v_param_581: Tensor[(1024), float32], %v_param_582: Tensor[(1024), float32], %v_param_583: Tensor[(256, 1024, 1, 1), float32], %v_param_584: Tensor[(256), float32], %v_param_585: Tensor[(256), float32], %v_param_586: Tensor[(256), float32], %v_param_587: Tensor[(256), float32], %v_param_588: Tensor[(256), float32], %v_param_589: Tensor[(256, 256, 3, 3), float32], %v_param_590: Tensor[(256), float32], %v_param_591: Tensor[(256), float32], %v_param_592: Tensor[(256), float32], %v_param_593: Tensor[(256), float32], %v_param_594: Tensor[(256), float32], %v_param_595: Tensor[(1024, 256, 1, 1), float32], %v_param_596: Tensor[(1024), float32], %v_param_597: Tensor[(1024), float32], %v_param_598: Tensor[(1024), float32], %v_param_599: Tensor[(1024), float32], %v_param_600: Tensor[(1024), float32], %v_param_601: Tensor[(256, 1024, 1, 1), float32], %v_param_602: Tensor[(256), float32], %v_param_603: Tensor[(256), float32], %v_param_604: Tensor[(256), float32], %v_param_605: Tensor[(256), float32], %v_param_606: Tensor[(256), float32], %v_param_607: Tensor[(256, 256, 3, 3), float32], %v_param_608: Tensor[(256), float32], %v_param_609: Tensor[(256), float32], %v_param_610: Tensor[(256), float32], %v_param_611: Tensor[(256), float32], %v_param_612: Tensor[(256), float32], %v_param_613: Tensor[(1024, 256, 1, 1), float32], %v_param_614: Tensor[(1024), float32], %v_param_615: Tensor[(1024), float32], %v_param_616: Tensor[(1024), float32], %v_param_617: Tensor[(1024), float32], %v_param_618: Tensor[(1024), float32], %v_param_619: Tensor[(256, 1024, 1, 1), float32], %v_param_620: Tensor[(256), float32], %v_param_621: Tensor[(256), float32], %v_param_622: Tensor[(256), float32], %v_param_623: Tensor[(256), float32], %v_param_624: Tensor[(256), float32], %v_param_625: Tensor[(256, 256, 3, 3), float32], %v_param_626: Tensor[(256), float32], %v_param_627: Tensor[(256), float32], %v_param_628: Tensor[(256), float32], %v_param_629: Tensor[(256), float32], %v_param_630: Tensor[(256), float32], %v_param_631: Tensor[(1024, 256, 1, 1), float32], %v_param_632: Tensor[(1024), float32], %v_param_633: Tensor[(1024), float32], %v_param_634: Tensor[(1024), float32], %v_param_635: Tensor[(1024), float32], %v_param_636: Tensor[(1024), float32], %v_param_637: Tensor[(256, 1024, 1, 1), float32], %v_param_638: Tensor[(256), float32], %v_param_639: Tensor[(256), float32], %v_param_640: Tensor[(256), float32], %v_param_641: Tensor[(256), float32], %v_param_642: Tensor[(256), float32], %v_param_643: Tensor[(256, 256, 3, 3), float32], %v_param_644: Tensor[(256), float32], %v_param_645: Tensor[(256), float32], %v_param_646: Tensor[(256), float32], %v_param_647: Tensor[(256), float32], %v_param_648: Tensor[(256), float32], %v_param_649: Tensor[(1024, 256, 1, 1), float32], %v_param_650: Tensor[(1024), float32], %v_param_651: Tensor[(1024), float32], %v_param_652: Tensor[(1024), float32], %v_param_653: Tensor[(1024), float32], %v_param_654: Tensor[(1024), float32], %v_param_655: Tensor[(256, 1024, 1, 1), float32], %v_param_656: Tensor[(256), float32], %v_param_657: Tensor[(256), float32], %v_param_658: Tensor[(256), float32], %v_param_659: Tensor[(256), float32], %v_param_660: Tensor[(256), float32], %v_param_661: Tensor[(256, 256, 3, 3), float32], %v_param_662: Tensor[(256), float32], %v_param_663: Tensor[(256), float32], %v_param_664: Tensor[(256), float32], %v_param_665: Tensor[(256), float32], %v_param_666: Tensor[(256), float32], %v_param_667: Tensor[(1024, 256, 1, 1), float32], %v_param_668: Tensor[(1024), float32], %v_param_669: Tensor[(1024), float32], %v_param_670: Tensor[(1024), float32], %v_param_671: Tensor[(1024), float32], %v_param_672: Tensor[(1024), float32], %v_param_673: Tensor[(256, 1024, 1, 1), float32], %v_param_674: Tensor[(256), float32], %v_param_675: Tensor[(256), float32], %v_param_676: Tensor[(256), float32], %v_param_677: Tensor[(256), float32], %v_param_678: Tensor[(256), float32], %v_param_679: Tensor[(256, 256, 3, 3), float32], %v_param_680: Tensor[(256), float32], %v_param_681: Tensor[(256), float32], %v_param_682: Tensor[(256), float32], %v_param_683: Tensor[(256), float32], %v_param_684: Tensor[(256), float32], %v_param_685: Tensor[(1024, 256, 1, 1), float32], %v_param_686: Tensor[(1024), float32], %v_param_687: Tensor[(1024), float32], %v_param_688: Tensor[(1024), float32], %v_param_689: Tensor[(1024), float32], %v_param_690: Tensor[(1024), float32], %v_param_691: Tensor[(256, 1024, 1, 1), float32], %v_param_692: Tensor[(256), float32], %v_param_693: Tensor[(256), float32], %v_param_694: Tensor[(256), float32], %v_param_695: Tensor[(256), float32], %v_param_696: Tensor[(256), float32], %v_param_697: Tensor[(256, 256, 3, 3), float32], %v_param_698: Tensor[(256), float32], %v_param_699: Tensor[(256), float32], %v_param_700: Tensor[(256), float32], %v_param_701: Tensor[(256), float32], %v_param_702: Tensor[(256), float32], %v_param_703: Tensor[(1024, 256, 1, 1), float32], %v_param_704: Tensor[(1024), float32], %v_param_705: Tensor[(1024), float32], %v_param_706: Tensor[(1024), float32], %v_param_707: Tensor[(1024), float32], %v_param_708: Tensor[(1024), float32], %v_param_709: Tensor[(256, 1024, 1, 1), float32], %v_param_710: Tensor[(256), float32], %v_param_711: Tensor[(256), float32], %v_param_712: Tensor[(256), float32], %v_param_713: Tensor[(256), float32], %v_param_714: Tensor[(256), float32], %v_param_715: Tensor[(256, 256, 3, 3), float32], %v_param_716: Tensor[(256), float32], %v_param_717: Tensor[(256), float32], %v_param_718: Tensor[(256), float32], %v_param_719: Tensor[(256), float32], %v_param_720: Tensor[(256), float32], %v_param_721: Tensor[(1024, 256, 1, 1), float32], %v_param_722: Tensor[(1024), float32], %v_param_723: Tensor[(1024), float32], %v_param_724: Tensor[(1024), float32], %v_param_725: Tensor[(1024), float32], %v_param_726: Tensor[(1024), float32], %v_param_727: Tensor[(256, 1024, 1, 1), float32], %v_param_728: Tensor[(256), float32], %v_param_729: Tensor[(256), float32], %v_param_730: Tensor[(256), float32], %v_param_731: Tensor[(256), float32], %v_param_732: Tensor[(256), float32], %v_param_733: Tensor[(256, 256, 3, 3), float32], %v_param_734: Tensor[(256), float32], %v_param_735: Tensor[(256), float32], %v_param_736: Tensor[(256), float32], %v_param_737: Tensor[(256), float32], %v_param_738: Tensor[(256), float32], %v_param_739: Tensor[(1024, 256, 1, 1), float32], %v_param_740: Tensor[(1024), float32], %v_param_741: Tensor[(1024), float32], %v_param_742: Tensor[(1024), float32], %v_param_743: Tensor[(1024), float32], %v_param_744: Tensor[(1024), float32], %v_param_745: Tensor[(256, 1024, 1, 1), float32], %v_param_746: Tensor[(256), float32], %v_param_747: Tensor[(256), float32], %v_param_748: Tensor[(256), float32], %v_param_749: Tensor[(256), float32], %v_param_750: Tensor[(256), float32], %v_param_751: Tensor[(256, 256, 3, 3), float32], %v_param_752: Tensor[(256), float32], %v_param_753: Tensor[(256), float32], %v_param_754: Tensor[(256), float32], %v_param_755: Tensor[(256), float32], %v_param_756: Tensor[(256), float32], %v_param_757: Tensor[(1024, 256, 1, 1), float32], %v_param_758: Tensor[(1024), float32], %v_param_759: Tensor[(1024), float32], %v_param_760: Tensor[(1024), float32], %v_param_761: Tensor[(1024), float32], %v_param_762: Tensor[(1024), float32], %v_param_763: Tensor[(256, 1024, 1, 1), float32], %v_param_764: Tensor[(256), float32], %v_param_765: Tensor[(256), float32], %v_param_766: Tensor[(256), float32], %v_param_767: Tensor[(256), float32], %v_param_768: Tensor[(256), float32], %v_param_769: Tensor[(256, 256, 3, 3), float32], %v_param_770: Tensor[(256), float32], %v_param_771: Tensor[(256), float32], %v_param_772: Tensor[(256), float32], %v_param_773: Tensor[(256), float32], %v_param_774: Tensor[(256), float32], %v_param_775: Tensor[(1024, 256, 1, 1), float32], %v_param_776: Tensor[(1024), float32], %v_param_777: Tensor[(1024), float32], %v_param_778: Tensor[(1024), float32], %v_param_779: Tensor[(1024), float32], %v_param_780: Tensor[(1024), float32], %v_param_781: Tensor[(256, 1024, 1, 1), float32], %v_param_782: Tensor[(256), float32], %v_param_783: Tensor[(256), float32], %v_param_784: Tensor[(256), float32], %v_param_785: Tensor[(256), float32], %v_param_786: Tensor[(256), float32], %v_param_787: Tensor[(256, 256, 3, 3), float32], %v_param_788: Tensor[(256), float32], %v_param_789: Tensor[(256), float32], %v_param_790: Tensor[(256), float32], %v_param_791: Tensor[(256), float32], %v_param_792: Tensor[(256), float32], %v_param_793: Tensor[(1024, 256, 1, 1), float32], %v_param_794: Tensor[(1024), float32], %v_param_795: Tensor[(1024), float32], %v_param_796: Tensor[(1024), float32], %v_param_797: Tensor[(1024), float32], %v_param_798: Tensor[(1024), float32], %v_param_799: Tensor[(256, 1024, 1, 1), float32], %v_param_800: Tensor[(256), float32], %v_param_801: Tensor[(256), float32], %v_param_802: Tensor[(256), float32], %v_param_803: Tensor[(256), float32], %v_param_804: Tensor[(256), float32], %v_param_805: Tensor[(256, 256, 3, 3), float32], %v_param_806: Tensor[(256), float32], %v_param_807: Tensor[(256), float32], %v_param_808: Tensor[(256), float32], %v_param_809: Tensor[(256), float32], %v_param_810: Tensor[(256), float32], %v_param_811: Tensor[(1024, 256, 1, 1), float32], %v_param_812: Tensor[(1024), float32], %v_param_813: Tensor[(1024), float32], %v_param_814: Tensor[(1024), float32], %v_param_815: Tensor[(1024), float32], %v_param_816: Tensor[(1024), float32], %v_param_817: Tensor[(256, 1024, 1, 1), float32], %v_param_818: Tensor[(256), float32], %v_param_819: Tensor[(256), float32], %v_param_820: Tensor[(256), float32], %v_param_821: Tensor[(256), float32], %v_param_822: Tensor[(256), float32], %v_param_823: Tensor[(256, 256, 3, 3), float32], %v_param_824: Tensor[(256), float32], %v_param_825: Tensor[(256), float32], %v_param_826: Tensor[(256), float32], %v_param_827: Tensor[(256), float32], %v_param_828: Tensor[(256), float32], %v_param_829: Tensor[(1024, 256, 1, 1), float32], %v_param_830: Tensor[(1024), float32], %v_param_831: Tensor[(1024), float32], %v_param_832: Tensor[(1024), float32], %v_param_833: Tensor[(1024), float32], %v_param_834: Tensor[(1024), float32], %v_param_835: Tensor[(256, 1024, 1, 1), float32], %v_param_836: Tensor[(256), float32], %v_param_837: Tensor[(256), float32], %v_param_838: Tensor[(256), float32], %v_param_839: Tensor[(256), float32], %v_param_840: Tensor[(256), float32], %v_param_841: Tensor[(256, 256, 3, 3), float32], %v_param_842: Tensor[(256), float32], %v_param_843: Tensor[(256), float32], %v_param_844: Tensor[(256), float32], %v_param_845: Tensor[(256), float32], %v_param_846: Tensor[(256), float32], %v_param_847: Tensor[(1024, 256, 1, 1), float32], %v_param_848: Tensor[(1024), float32], %v_param_849: Tensor[(1024), float32], %v_param_850: Tensor[(1024), float32], %v_param_851: Tensor[(1024), float32], %v_param_852: Tensor[(1024), float32], %v_param_853: Tensor[(256, 1024, 1, 1), float32], %v_param_854: Tensor[(256), float32], %v_param_855: Tensor[(256), float32], %v_param_856: Tensor[(256), float32], %v_param_857: Tensor[(256), float32], %v_param_858: Tensor[(256), float32], %v_param_859: Tensor[(256, 256, 3, 3), float32], %v_param_860: Tensor[(256), float32], %v_param_861: Tensor[(256), float32], %v_param_862: Tensor[(256), float32], %v_param_863: Tensor[(256), float32], %v_param_864: Tensor[(256), float32], %v_param_865: Tensor[(1024, 256, 1, 1), float32], %v_param_866: Tensor[(1024), float32], %v_param_867: Tensor[(1024), float32], %v_param_868: Tensor[(1024), float32], %v_param_869: Tensor[(1024), float32], %v_param_870: Tensor[(1024), float32], %v_param_883: Tensor[(2048, 1024, 1, 1), float32], %v_param_884: Tensor[(2048), float32], %v_param_887: Tensor[(2048), float32], %v_param_888: Tensor[(2048), float32], %v_param_889: Tensor[(2048), float32], %v_param_890: Tensor[(2048), float32], %v_param_871: Tensor[(512, 1024, 1, 1), float32], %v_param_872: Tensor[(512), float32], %v_param_873: Tensor[(512), float32], %v_param_874: Tensor[(512), float32], %v_param_875: Tensor[(512), float32], %v_param_876: Tensor[(512), float32], %v_param_877: Tensor[(512, 512, 3, 3), float32], %v_param_878: Tensor[(512), float32], %v_param_879: Tensor[(512), float32], %v_param_880: Tensor[(512), float32], %v_param_881: Tensor[(512), float32], %v_param_882: Tensor[(512), float32], %v_param_885: Tensor[(2048, 512, 1, 1), float32], %v_param_886: Tensor[(2048), float32], %v_param_891: Tensor[(2048), float32], %v_param_892: Tensor[(2048), float32], %v_param_893: Tensor[(2048), float32], %v_param_894: Tensor[(2048), float32], %v_param_895: Tensor[(512, 2048, 1, 1), float32], %v_param_896: Tensor[(512), float32], %v_param_897: Tensor[(512), float32], %v_param_898: Tensor[(512), float32], %v_param_899: Tensor[(512), float32], %v_param_900: Tensor[(512), float32], %v_param_901: Tensor[(512, 512, 3, 3), float32], %v_param_902: Tensor[(512), float32], %v_param_903: Tensor[(512), float32], %v_param_904: Tensor[(512), float32], %v_param_905: Tensor[(512), float32], %v_param_906: Tensor[(512), float32], %v_param_907: Tensor[(2048, 512, 1, 1), float32], %v_param_908: Tensor[(2048), float32], %v_param_909: Tensor[(2048), float32], %v_param_910: Tensor[(2048), float32], %v_param_911: Tensor[(2048), float32], %v_param_912: Tensor[(2048), float32], %v_param_913: Tensor[(512, 2048, 1, 1), float32], %v_param_914: Tensor[(512), float32], %v_param_915: Tensor[(512), float32], %v_param_916: Tensor[(512), float32], %v_param_917: Tensor[(512), float32], %v_param_918: Tensor[(512), float32], %v_param_919: Tensor[(512, 512, 3, 3), float32], %v_param_920: Tensor[(512), float32], %v_param_921: Tensor[(512), float32], %v_param_922: Tensor[(512), float32], %v_param_923: Tensor[(512), float32], %v_param_924: Tensor[(512), float32], %v_param_925: Tensor[(2048, 512, 1, 1), float32], %v_param_926: Tensor[(2048), float32], %v_param_927: Tensor[(2048), float32], %v_param_928: Tensor[(2048), float32], %v_param_929: Tensor[(2048), float32], %v_param_930: Tensor[(2048), float32], %v_param_931: Tensor[(1000, 2048), float32], %v_param_932: Tensor[(1000), float32]) {\n",
      "  %0 = nn.pad(%input_1, 0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);\n",
      "  %1 = nn.conv2d(%0, %v_param_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7]);\n",
      "  %2 = nn.bias_add(%1, %v_param_2);\n",
      "  %3 = nn.batch_norm(%2, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=1.001e-05f);\n",
      "  %4 = %3.0;\n",
      "  %5 = nn.relu(%4);\n",
      "  %6 = nn.pad(%5, 0, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %8 = nn.conv2d(%7, %v_param_19, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %9 = nn.bias_add(%8, %v_param_20);\n",
      "  %10 = nn.batch_norm(%9, %v_param_23, %v_param_24, %v_param_25, %v_param_26, epsilon=1.001e-05f);\n",
      "  %11 = nn.conv2d(%7, %v_param_7, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %12 = nn.bias_add(%11, %v_param_8);\n",
      "  %13 = nn.batch_norm(%12, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=1.001e-05f);\n",
      "  %14 = %13.0;\n",
      "  %15 = nn.relu(%14);\n",
      "  %16 = nn.conv2d(%15, %v_param_13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %17 = nn.bias_add(%16, %v_param_14);\n",
      "  %18 = nn.batch_norm(%17, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=1.001e-05f);\n",
      "  %19 = %18.0;\n",
      "  %20 = nn.relu(%19);\n",
      "  %21 = nn.conv2d(%20, %v_param_21, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %22 = nn.bias_add(%21, %v_param_22);\n",
      "  %23 = nn.batch_norm(%22, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=1.001e-05f);\n",
      "  %24 = %10.0;\n",
      "  %25 = %23.0;\n",
      "  %26 = add(%24, %25);\n",
      "  %27 = nn.relu(%26);\n",
      "  %28 = multiply(%27, 8f);\n",
      "  %29 = round(%28);\n",
      "  %30 = clip(%29, a_min=-127f, a_max=127f);\n",
      "  %31 = cast(%30, dtype=\"int8\");\n",
      "  %32 = annotation.stop_fusion(%31);\n",
      "  %33 = cast(%32, dtype=\"float32\");\n",
      "  %34 = divide(%33, 8f);\n",
      "  %35 = nn.conv2d(%34, %v_param_31, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %36 = nn.bias_add(%35, %v_param_32);\n",
      "  %37 = nn.batch_norm(%36, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=1.001e-05f);\n",
      "  %38 = %37.0;\n",
      "  %39 = nn.relu(%38);\n",
      "  %40 = nn.conv2d(%39, %v_param_37, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %41 = nn.bias_add(%40, %v_param_38);\n",
      "  %42 = nn.batch_norm(%41, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=1.001e-05f);\n",
      "  %43 = %42.0;\n",
      "  %44 = nn.relu(%43);\n",
      "  %45 = nn.conv2d(%44, %v_param_43, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %46 = nn.bias_add(%45, %v_param_44);\n",
      "  %47 = nn.batch_norm(%46, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=1.001e-05f);\n",
      "  %48 = %47.0;\n",
      "  %49 = add(%34, %48);\n",
      "  %50 = nn.relu(%49);\n",
      "  %51 = nn.conv2d(%50, %v_param_49, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %52 = nn.bias_add(%51, %v_param_50);\n",
      "  %53 = nn.batch_norm(%52, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=1.001e-05f);\n",
      "  %54 = %53.0;\n",
      "  %55 = nn.relu(%54);\n",
      "  %56 = nn.conv2d(%55, %v_param_55, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %57 = nn.bias_add(%56, %v_param_56);\n",
      "  %58 = nn.batch_norm(%57, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=1.001e-05f);\n",
      "  %59 = %58.0;\n",
      "  %60 = nn.relu(%59);\n",
      "  %61 = nn.conv2d(%60, %v_param_61, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %62 = nn.bias_add(%61, %v_param_62);\n",
      "  %63 = nn.batch_norm(%62, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=1.001e-05f);\n",
      "  %64 = %63.0;\n",
      "  %65 = add(%50, %64);\n",
      "  %66 = nn.relu(%65);\n",
      "  %67 = nn.conv2d(%66, %v_param_79, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %68 = nn.bias_add(%67, %v_param_80);\n",
      "  %69 = nn.batch_norm(%68, %v_param_83, %v_param_84, %v_param_85, %v_param_86, epsilon=1.001e-05f);\n",
      "  %70 = nn.conv2d(%66, %v_param_67, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %71 = nn.bias_add(%70, %v_param_68);\n",
      "  %72 = nn.batch_norm(%71, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=1.001e-05f);\n",
      "  %73 = %72.0;\n",
      "  %74 = nn.relu(%73);\n",
      "  %75 = nn.conv2d(%74, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %76 = nn.bias_add(%75, %v_param_74);\n",
      "  %77 = nn.batch_norm(%76, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=1.001e-05f);\n",
      "  %78 = %77.0;\n",
      "  %79 = nn.relu(%78);\n",
      "  %80 = nn.conv2d(%79, %v_param_81, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %81 = nn.bias_add(%80, %v_param_82);\n",
      "  %82 = nn.batch_norm(%81, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=1.001e-05f);\n",
      "  %83 = %69.0;\n",
      "  %84 = %82.0;\n",
      "  %85 = add(%83, %84);\n",
      "  %86 = nn.relu(%85);\n",
      "  %87 = multiply(%86, 8f);\n",
      "  %88 = round(%87);\n",
      "  %89 = clip(%88, a_min=-127f, a_max=127f);\n",
      "  %90 = cast(%89, dtype=\"int8\");\n",
      "  %91 = annotation.stop_fusion(%90);\n",
      "  %92 = cast(%91, dtype=\"float32\");\n",
      "  %93 = divide(%92, 8f);\n",
      "  %94 = nn.conv2d(%93, %v_param_91, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %95 = nn.bias_add(%94, %v_param_92);\n",
      "  %96 = nn.batch_norm(%95, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=1.001e-05f);\n",
      "  %97 = %96.0;\n",
      "  %98 = nn.relu(%97);\n",
      "  %99 = nn.conv2d(%98, %v_param_97, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %100 = nn.bias_add(%99, %v_param_98);\n",
      "  %101 = nn.batch_norm(%100, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=1.001e-05f);\n",
      "  %102 = %101.0;\n",
      "  %103 = nn.relu(%102);\n",
      "  %104 = nn.conv2d(%103, %v_param_103, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %105 = nn.bias_add(%104, %v_param_104);\n",
      "  %106 = nn.batch_norm(%105, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=1.001e-05f);\n",
      "  %107 = %106.0;\n",
      "  %108 = add(%93, %107);\n",
      "  %109 = nn.relu(%108);\n",
      "  %110 = nn.conv2d(%109, %v_param_109, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %111 = nn.bias_add(%110, %v_param_110);\n",
      "  %112 = nn.batch_norm(%111, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=1.001e-05f);\n",
      "  %113 = %112.0;\n",
      "  %114 = nn.relu(%113);\n",
      "  %115 = nn.conv2d(%114, %v_param_115, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %116 = nn.bias_add(%115, %v_param_116);\n",
      "  %117 = nn.batch_norm(%116, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=1.001e-05f);\n",
      "  %118 = %117.0;\n",
      "  %119 = nn.relu(%118);\n",
      "  %120 = nn.conv2d(%119, %v_param_121, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %121 = nn.bias_add(%120, %v_param_122);\n",
      "  %122 = nn.batch_norm(%121, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=1.001e-05f);\n",
      "  %123 = %122.0;\n",
      "  %124 = add(%109, %123);\n",
      "  %125 = nn.relu(%124);\n",
      "  %126 = nn.conv2d(%125, %v_param_127, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %127 = nn.bias_add(%126, %v_param_128);\n",
      "  %128 = nn.batch_norm(%127, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=1.001e-05f);\n",
      "  %129 = %128.0;\n",
      "  %130 = nn.relu(%129);\n",
      "  %131 = nn.conv2d(%130, %v_param_133, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %132 = nn.bias_add(%131, %v_param_134);\n",
      "  %133 = nn.batch_norm(%132, %v_param_135, %v_param_136, %v_param_137, %v_param_138, epsilon=1.001e-05f);\n",
      "  %134 = %133.0;\n",
      "  %135 = nn.relu(%134);\n",
      "  %136 = nn.conv2d(%135, %v_param_139, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %137 = nn.bias_add(%136, %v_param_140);\n",
      "  %138 = nn.batch_norm(%137, %v_param_141, %v_param_142, %v_param_143, %v_param_144, epsilon=1.001e-05f);\n",
      "  %139 = %138.0;\n",
      "  %140 = add(%125, %139);\n",
      "  %141 = nn.relu(%140);\n",
      "  %142 = multiply(%141, 8f);\n",
      "  %143 = round(%142);\n",
      "  %144 = clip(%143, a_min=-127f, a_max=127f);\n",
      "  %145 = cast(%144, dtype=\"int8\");\n",
      "  %146 = annotation.stop_fusion(%145);\n",
      "  %147 = cast(%146, dtype=\"float32\");\n",
      "  %148 = divide(%147, 8f);\n",
      "  %149 = nn.conv2d(%148, %v_param_145, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %150 = nn.bias_add(%149, %v_param_146);\n",
      "  %151 = nn.batch_norm(%150, %v_param_147, %v_param_148, %v_param_149, %v_param_150, epsilon=1.001e-05f);\n",
      "  %152 = %151.0;\n",
      "  %153 = nn.relu(%152);\n",
      "  %154 = nn.conv2d(%153, %v_param_151, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %155 = nn.bias_add(%154, %v_param_152);\n",
      "  %156 = nn.batch_norm(%155, %v_param_153, %v_param_154, %v_param_155, %v_param_156, epsilon=1.001e-05f);\n",
      "  %157 = %156.0;\n",
      "  %158 = nn.relu(%157);\n",
      "  %159 = nn.conv2d(%158, %v_param_157, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %160 = nn.bias_add(%159, %v_param_158);\n",
      "  %161 = nn.batch_norm(%160, %v_param_159, %v_param_160, %v_param_161, %v_param_162, epsilon=1.001e-05f);\n",
      "  %162 = %161.0;\n",
      "  %163 = add(%148, %162);\n",
      "  %164 = nn.relu(%163);\n",
      "  %165 = nn.conv2d(%164, %v_param_163, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %166 = nn.bias_add(%165, %v_param_164);\n",
      "  %167 = nn.batch_norm(%166, %v_param_165, %v_param_166, %v_param_167, %v_param_168, epsilon=1.001e-05f);\n",
      "  %168 = %167.0;\n",
      "  %169 = nn.relu(%168);\n",
      "  %170 = nn.conv2d(%169, %v_param_169, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %171 = nn.bias_add(%170, %v_param_170);\n",
      "  %172 = nn.batch_norm(%171, %v_param_171, %v_param_172, %v_param_173, %v_param_174, epsilon=1.001e-05f);\n",
      "  %173 = %172.0;\n",
      "  %174 = nn.relu(%173);\n",
      "  %175 = nn.conv2d(%174, %v_param_175, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %176 = nn.bias_add(%175, %v_param_176);\n",
      "  %177 = nn.batch_norm(%176, %v_param_177, %v_param_178, %v_param_179, %v_param_180, epsilon=1.001e-05f);\n",
      "  %178 = %177.0;\n",
      "  %179 = add(%164, %178);\n",
      "  %180 = nn.relu(%179);\n",
      "  %181 = nn.conv2d(%180, %v_param_181, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %182 = nn.bias_add(%181, %v_param_182);\n",
      "  %183 = nn.batch_norm(%182, %v_param_183, %v_param_184, %v_param_185, %v_param_186, epsilon=1.001e-05f);\n",
      "  %184 = %183.0;\n",
      "  %185 = nn.relu(%184);\n",
      "  %186 = nn.conv2d(%185, %v_param_187, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %187 = nn.bias_add(%186, %v_param_188);\n",
      "  %188 = nn.batch_norm(%187, %v_param_189, %v_param_190, %v_param_191, %v_param_192, epsilon=1.001e-05f);\n",
      "  %189 = %188.0;\n",
      "  %190 = nn.relu(%189);\n",
      "  %191 = nn.conv2d(%190, %v_param_193, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %192 = nn.bias_add(%191, %v_param_194);\n",
      "  %193 = nn.batch_norm(%192, %v_param_195, %v_param_196, %v_param_197, %v_param_198, epsilon=1.001e-05f);\n",
      "  %194 = %193.0;\n",
      "  %195 = add(%180, %194);\n",
      "  %196 = nn.relu(%195);\n",
      "  %197 = multiply(%196, 8f);\n",
      "  %198 = round(%197);\n",
      "  %199 = clip(%198, a_min=-127f, a_max=127f);\n",
      "  %200 = cast(%199, dtype=\"int8\");\n",
      "  %201 = annotation.stop_fusion(%200);\n",
      "  %202 = cast(%201, dtype=\"float32\");\n",
      "  %203 = divide(%202, 8f);\n",
      "  %204 = nn.conv2d(%203, %v_param_199, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %205 = nn.bias_add(%204, %v_param_200);\n",
      "  %206 = nn.batch_norm(%205, %v_param_201, %v_param_202, %v_param_203, %v_param_204, epsilon=1.001e-05f);\n",
      "  %207 = %206.0;\n",
      "  %208 = nn.relu(%207);\n",
      "  %209 = nn.conv2d(%208, %v_param_205, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %210 = nn.bias_add(%209, %v_param_206);\n",
      "  %211 = nn.batch_norm(%210, %v_param_207, %v_param_208, %v_param_209, %v_param_210, epsilon=1.001e-05f);\n",
      "  %212 = %211.0;\n",
      "  %213 = nn.relu(%212);\n",
      "  %214 = nn.conv2d(%213, %v_param_211, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %215 = nn.bias_add(%214, %v_param_212);\n",
      "  %216 = nn.batch_norm(%215, %v_param_213, %v_param_214, %v_param_215, %v_param_216, epsilon=1.001e-05f);\n",
      "  %217 = %216.0;\n",
      "  %218 = add(%203, %217);\n",
      "  %219 = nn.relu(%218);\n",
      "  %220 = nn.conv2d(%219, %v_param_229, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %221 = nn.bias_add(%220, %v_param_230);\n",
      "  %222 = nn.batch_norm(%221, %v_param_233, %v_param_234, %v_param_235, %v_param_236, epsilon=1.001e-05f);\n",
      "  %223 = nn.conv2d(%219, %v_param_217, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %224 = nn.bias_add(%223, %v_param_218);\n",
      "  %225 = nn.batch_norm(%224, %v_param_219, %v_param_220, %v_param_221, %v_param_222, epsilon=1.001e-05f);\n",
      "  %226 = %225.0;\n",
      "  %227 = nn.relu(%226);\n",
      "  %228 = nn.conv2d(%227, %v_param_223, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %229 = nn.bias_add(%228, %v_param_224);\n",
      "  %230 = nn.batch_norm(%229, %v_param_225, %v_param_226, %v_param_227, %v_param_228, epsilon=1.001e-05f);\n",
      "  %231 = %230.0;\n",
      "  %232 = nn.relu(%231);\n",
      "  %233 = nn.conv2d(%232, %v_param_231, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %234 = nn.bias_add(%233, %v_param_232);\n",
      "  %235 = nn.batch_norm(%234, %v_param_237, %v_param_238, %v_param_239, %v_param_240, epsilon=1.001e-05f);\n",
      "  %236 = %222.0;\n",
      "  %237 = %235.0;\n",
      "  %238 = add(%236, %237);\n",
      "  %239 = nn.relu(%238);\n",
      "  %240 = nn.conv2d(%239, %v_param_241, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %241 = nn.bias_add(%240, %v_param_242);\n",
      "  %242 = nn.batch_norm(%241, %v_param_243, %v_param_244, %v_param_245, %v_param_246, epsilon=1.001e-05f);\n",
      "  %243 = %242.0;\n",
      "  %244 = nn.relu(%243);\n",
      "  %245 = nn.conv2d(%244, %v_param_247, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %246 = nn.bias_add(%245, %v_param_248);\n",
      "  %247 = nn.batch_norm(%246, %v_param_249, %v_param_250, %v_param_251, %v_param_252, epsilon=1.001e-05f);\n",
      "  %248 = %247.0;\n",
      "  %249 = nn.relu(%248);\n",
      "  %250 = nn.conv2d(%249, %v_param_253, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %251 = nn.bias_add(%250, %v_param_254);\n",
      "  %252 = nn.batch_norm(%251, %v_param_255, %v_param_256, %v_param_257, %v_param_258, epsilon=1.001e-05f);\n",
      "  %253 = %252.0;\n",
      "  %254 = add(%239, %253);\n",
      "  %255 = nn.relu(%254);\n",
      "  %256 = multiply(%255, 8f);\n",
      "  %257 = round(%256);\n",
      "  %258 = clip(%257, a_min=-127f, a_max=127f);\n",
      "  %259 = cast(%258, dtype=\"int8\");\n",
      "  %260 = annotation.stop_fusion(%259);\n",
      "  %261 = cast(%260, dtype=\"float32\");\n",
      "  %262 = divide(%261, 8f);\n",
      "  %263 = nn.conv2d(%262, %v_param_259, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %264 = nn.bias_add(%263, %v_param_260);\n",
      "  %265 = nn.batch_norm(%264, %v_param_261, %v_param_262, %v_param_263, %v_param_264, epsilon=1.001e-05f);\n",
      "  %266 = %265.0;\n",
      "  %267 = nn.relu(%266);\n",
      "  %268 = nn.conv2d(%267, %v_param_265, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %269 = nn.bias_add(%268, %v_param_266);\n",
      "  %270 = nn.batch_norm(%269, %v_param_267, %v_param_268, %v_param_269, %v_param_270, epsilon=1.001e-05f);\n",
      "  %271 = %270.0;\n",
      "  %272 = nn.relu(%271);\n",
      "  %273 = nn.conv2d(%272, %v_param_271, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %274 = nn.bias_add(%273, %v_param_272);\n",
      "  %275 = nn.batch_norm(%274, %v_param_273, %v_param_274, %v_param_275, %v_param_276, epsilon=1.001e-05f);\n",
      "  %276 = %275.0;\n",
      "  %277 = add(%262, %276);\n",
      "  %278 = nn.relu(%277);\n",
      "  %279 = nn.conv2d(%278, %v_param_277, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %280 = nn.bias_add(%279, %v_param_278);\n",
      "  %281 = nn.batch_norm(%280, %v_param_279, %v_param_280, %v_param_281, %v_param_282, epsilon=1.001e-05f);\n",
      "  %282 = %281.0;\n",
      "  %283 = nn.relu(%282);\n",
      "  %284 = nn.conv2d(%283, %v_param_283, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %285 = nn.bias_add(%284, %v_param_284);\n",
      "  %286 = nn.batch_norm(%285, %v_param_285, %v_param_286, %v_param_287, %v_param_288, epsilon=1.001e-05f);\n",
      "  %287 = %286.0;\n",
      "  %288 = nn.relu(%287);\n",
      "  %289 = nn.conv2d(%288, %v_param_289, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %290 = nn.bias_add(%289, %v_param_290);\n",
      "  %291 = nn.batch_norm(%290, %v_param_291, %v_param_292, %v_param_293, %v_param_294, epsilon=1.001e-05f);\n",
      "  %292 = %291.0;\n",
      "  %293 = add(%278, %292);\n",
      "  %294 = nn.relu(%293);\n",
      "  %295 = nn.conv2d(%294, %v_param_295, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %296 = nn.bias_add(%295, %v_param_296);\n",
      "  %297 = nn.batch_norm(%296, %v_param_297, %v_param_298, %v_param_299, %v_param_300, epsilon=1.001e-05f);\n",
      "  %298 = %297.0;\n",
      "  %299 = nn.relu(%298);\n",
      "  %300 = nn.conv2d(%299, %v_param_301, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %301 = nn.bias_add(%300, %v_param_302);\n",
      "  %302 = nn.batch_norm(%301, %v_param_303, %v_param_304, %v_param_305, %v_param_306, epsilon=1.001e-05f);\n",
      "  %303 = %302.0;\n",
      "  %304 = nn.relu(%303);\n",
      "  %305 = nn.conv2d(%304, %v_param_307, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %306 = nn.bias_add(%305, %v_param_308);\n",
      "  %307 = nn.batch_norm(%306, %v_param_309, %v_param_310, %v_param_311, %v_param_312, epsilon=1.001e-05f);\n",
      "  %308 = %307.0;\n",
      "  %309 = add(%294, %308);\n",
      "  %310 = nn.relu(%309);\n",
      "  %311 = multiply(%310, 8f);\n",
      "  %312 = round(%311);\n",
      "  %313 = clip(%312, a_min=-127f, a_max=127f);\n",
      "  %314 = cast(%313, dtype=\"int8\");\n",
      "  %315 = annotation.stop_fusion(%314);\n",
      "  %316 = cast(%315, dtype=\"float32\");\n",
      "  %317 = divide(%316, 8f);\n",
      "  %318 = nn.conv2d(%317, %v_param_313, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %319 = nn.bias_add(%318, %v_param_314);\n",
      "  %320 = nn.batch_norm(%319, %v_param_315, %v_param_316, %v_param_317, %v_param_318, epsilon=1.001e-05f);\n",
      "  %321 = %320.0;\n",
      "  %322 = nn.relu(%321);\n",
      "  %323 = nn.conv2d(%322, %v_param_319, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %324 = nn.bias_add(%323, %v_param_320);\n",
      "  %325 = nn.batch_norm(%324, %v_param_321, %v_param_322, %v_param_323, %v_param_324, epsilon=1.001e-05f);\n",
      "  %326 = %325.0;\n",
      "  %327 = nn.relu(%326);\n",
      "  %328 = nn.conv2d(%327, %v_param_325, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %329 = nn.bias_add(%328, %v_param_326);\n",
      "  %330 = nn.batch_norm(%329, %v_param_327, %v_param_328, %v_param_329, %v_param_330, epsilon=1.001e-05f);\n",
      "  %331 = %330.0;\n",
      "  %332 = add(%317, %331);\n",
      "  %333 = nn.relu(%332);\n",
      "  %334 = nn.conv2d(%333, %v_param_331, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %335 = nn.bias_add(%334, %v_param_332);\n",
      "  %336 = nn.batch_norm(%335, %v_param_333, %v_param_334, %v_param_335, %v_param_336, epsilon=1.001e-05f);\n",
      "  %337 = %336.0;\n",
      "  %338 = nn.relu(%337);\n",
      "  %339 = nn.conv2d(%338, %v_param_337, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %340 = nn.bias_add(%339, %v_param_338);\n",
      "  %341 = nn.batch_norm(%340, %v_param_339, %v_param_340, %v_param_341, %v_param_342, epsilon=1.001e-05f);\n",
      "  %342 = %341.0;\n",
      "  %343 = nn.relu(%342);\n",
      "  %344 = nn.conv2d(%343, %v_param_343, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %345 = nn.bias_add(%344, %v_param_344);\n",
      "  %346 = nn.batch_norm(%345, %v_param_345, %v_param_346, %v_param_347, %v_param_348, epsilon=1.001e-05f);\n",
      "  %347 = %346.0;\n",
      "  %348 = add(%333, %347);\n",
      "  %349 = nn.relu(%348);\n",
      "  %350 = nn.conv2d(%349, %v_param_349, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %351 = nn.bias_add(%350, %v_param_350);\n",
      "  %352 = nn.batch_norm(%351, %v_param_351, %v_param_352, %v_param_353, %v_param_354, epsilon=1.001e-05f);\n",
      "  %353 = %352.0;\n",
      "  %354 = nn.relu(%353);\n",
      "  %355 = nn.conv2d(%354, %v_param_355, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %356 = nn.bias_add(%355, %v_param_356);\n",
      "  %357 = nn.batch_norm(%356, %v_param_357, %v_param_358, %v_param_359, %v_param_360, epsilon=1.001e-05f);\n",
      "  %358 = %357.0;\n",
      "  %359 = nn.relu(%358);\n",
      "  %360 = nn.conv2d(%359, %v_param_361, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %361 = nn.bias_add(%360, %v_param_362);\n",
      "  %362 = nn.batch_norm(%361, %v_param_363, %v_param_364, %v_param_365, %v_param_366, epsilon=1.001e-05f);\n",
      "  %363 = %362.0;\n",
      "  %364 = add(%349, %363);\n",
      "  %365 = nn.relu(%364);\n",
      "  %366 = nn.conv2d(%365, %v_param_367, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %367 = nn.bias_add(%366, %v_param_368);\n",
      "  %368 = nn.batch_norm(%367, %v_param_369, %v_param_370, %v_param_371, %v_param_372, epsilon=1.001e-05f);\n",
      "  %369 = %368.0;\n",
      "  %370 = nn.relu(%369);\n",
      "  %371 = nn.conv2d(%370, %v_param_373, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %372 = nn.bias_add(%371, %v_param_374);\n",
      "  %373 = nn.batch_norm(%372, %v_param_375, %v_param_376, %v_param_377, %v_param_378, epsilon=1.001e-05f);\n",
      "  %374 = %373.0;\n",
      "  %375 = nn.relu(%374);\n",
      "  %376 = nn.conv2d(%375, %v_param_379, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %377 = nn.bias_add(%376, %v_param_380);\n",
      "  %378 = nn.batch_norm(%377, %v_param_381, %v_param_382, %v_param_383, %v_param_384, epsilon=1.001e-05f);\n",
      "  %379 = %378.0;\n",
      "  %380 = add(%365, %379);\n",
      "  %381 = nn.relu(%380);\n",
      "  %382 = nn.conv2d(%381, %v_param_385, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %383 = nn.bias_add(%382, %v_param_386);\n",
      "  %384 = nn.batch_norm(%383, %v_param_387, %v_param_388, %v_param_389, %v_param_390, epsilon=1.001e-05f);\n",
      "  %385 = %384.0;\n",
      "  %386 = nn.relu(%385);\n",
      "  %387 = nn.conv2d(%386, %v_param_391, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %388 = nn.bias_add(%387, %v_param_392);\n",
      "  %389 = nn.batch_norm(%388, %v_param_393, %v_param_394, %v_param_395, %v_param_396, epsilon=1.001e-05f);\n",
      "  %390 = %389.0;\n",
      "  %391 = nn.relu(%390);\n",
      "  %392 = nn.conv2d(%391, %v_param_397, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %393 = nn.bias_add(%392, %v_param_398);\n",
      "  %394 = nn.batch_norm(%393, %v_param_399, %v_param_400, %v_param_401, %v_param_402, epsilon=1.001e-05f);\n",
      "  %395 = %394.0;\n",
      "  %396 = add(%381, %395);\n",
      "  %397 = nn.relu(%396);\n",
      "  %398 = nn.conv2d(%397, %v_param_403, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %399 = nn.bias_add(%398, %v_param_404);\n",
      "  %400 = nn.batch_norm(%399, %v_param_405, %v_param_406, %v_param_407, %v_param_408, epsilon=1.001e-05f);\n",
      "  %401 = %400.0;\n",
      "  %402 = nn.relu(%401);\n",
      "  %403 = nn.conv2d(%402, %v_param_409, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %404 = nn.bias_add(%403, %v_param_410);\n",
      "  %405 = nn.batch_norm(%404, %v_param_411, %v_param_412, %v_param_413, %v_param_414, epsilon=1.001e-05f);\n",
      "  %406 = %405.0;\n",
      "  %407 = nn.relu(%406);\n",
      "  %408 = nn.conv2d(%407, %v_param_415, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %409 = nn.bias_add(%408, %v_param_416);\n",
      "  %410 = nn.batch_norm(%409, %v_param_417, %v_param_418, %v_param_419, %v_param_420, epsilon=1.001e-05f);\n",
      "  %411 = %410.0;\n",
      "  %412 = add(%397, %411);\n",
      "  %413 = nn.relu(%412);\n",
      "  %414 = nn.conv2d(%413, %v_param_421, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %415 = nn.bias_add(%414, %v_param_422);\n",
      "  %416 = nn.batch_norm(%415, %v_param_423, %v_param_424, %v_param_425, %v_param_426, epsilon=1.001e-05f);\n",
      "  %417 = %416.0;\n",
      "  %418 = nn.relu(%417);\n",
      "  %419 = nn.conv2d(%418, %v_param_427, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %420 = nn.bias_add(%419, %v_param_428);\n",
      "  %421 = nn.batch_norm(%420, %v_param_429, %v_param_430, %v_param_431, %v_param_432, epsilon=1.001e-05f);\n",
      "  %422 = %421.0;\n",
      "  %423 = nn.relu(%422);\n",
      "  %424 = nn.conv2d(%423, %v_param_433, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %425 = nn.bias_add(%424, %v_param_434);\n",
      "  %426 = nn.batch_norm(%425, %v_param_435, %v_param_436, %v_param_437, %v_param_438, epsilon=1.001e-05f);\n",
      "  %427 = %426.0;\n",
      "  %428 = add(%413, %427);\n",
      "  %429 = nn.relu(%428);\n",
      "  %430 = nn.conv2d(%429, %v_param_439, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %431 = nn.bias_add(%430, %v_param_440);\n",
      "  %432 = nn.batch_norm(%431, %v_param_441, %v_param_442, %v_param_443, %v_param_444, epsilon=1.001e-05f);\n",
      "  %433 = %432.0;\n",
      "  %434 = nn.relu(%433);\n",
      "  %435 = nn.conv2d(%434, %v_param_445, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %436 = nn.bias_add(%435, %v_param_446);\n",
      "  %437 = nn.batch_norm(%436, %v_param_447, %v_param_448, %v_param_449, %v_param_450, epsilon=1.001e-05f);\n",
      "  %438 = %437.0;\n",
      "  %439 = nn.relu(%438);\n",
      "  %440 = nn.conv2d(%439, %v_param_451, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %441 = nn.bias_add(%440, %v_param_452);\n",
      "  %442 = nn.batch_norm(%441, %v_param_453, %v_param_454, %v_param_455, %v_param_456, epsilon=1.001e-05f);\n",
      "  %443 = %442.0;\n",
      "  %444 = add(%429, %443);\n",
      "  %445 = nn.relu(%444);\n",
      "  %446 = nn.conv2d(%445, %v_param_457, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %447 = nn.bias_add(%446, %v_param_458);\n",
      "  %448 = nn.batch_norm(%447, %v_param_459, %v_param_460, %v_param_461, %v_param_462, epsilon=1.001e-05f);\n",
      "  %449 = %448.0;\n",
      "  %450 = nn.relu(%449);\n",
      "  %451 = nn.conv2d(%450, %v_param_463, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %452 = nn.bias_add(%451, %v_param_464);\n",
      "  %453 = nn.batch_norm(%452, %v_param_465, %v_param_466, %v_param_467, %v_param_468, epsilon=1.001e-05f);\n",
      "  %454 = %453.0;\n",
      "  %455 = nn.relu(%454);\n",
      "  %456 = nn.conv2d(%455, %v_param_469, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %457 = nn.bias_add(%456, %v_param_470);\n",
      "  %458 = nn.batch_norm(%457, %v_param_471, %v_param_472, %v_param_473, %v_param_474, epsilon=1.001e-05f);\n",
      "  %459 = %458.0;\n",
      "  %460 = add(%445, %459);\n",
      "  %461 = nn.relu(%460);\n",
      "  %462 = nn.conv2d(%461, %v_param_475, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %463 = nn.bias_add(%462, %v_param_476);\n",
      "  %464 = nn.batch_norm(%463, %v_param_477, %v_param_478, %v_param_479, %v_param_480, epsilon=1.001e-05f);\n",
      "  %465 = %464.0;\n",
      "  %466 = nn.relu(%465);\n",
      "  %467 = nn.conv2d(%466, %v_param_481, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %468 = nn.bias_add(%467, %v_param_482);\n",
      "  %469 = nn.batch_norm(%468, %v_param_483, %v_param_484, %v_param_485, %v_param_486, epsilon=1.001e-05f);\n",
      "  %470 = %469.0;\n",
      "  %471 = nn.relu(%470);\n",
      "  %472 = nn.conv2d(%471, %v_param_487, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %473 = nn.bias_add(%472, %v_param_488);\n",
      "  %474 = nn.batch_norm(%473, %v_param_489, %v_param_490, %v_param_491, %v_param_492, epsilon=1.001e-05f);\n",
      "  %475 = %474.0;\n",
      "  %476 = add(%461, %475);\n",
      "  %477 = nn.relu(%476);\n",
      "  %478 = nn.conv2d(%477, %v_param_493, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %479 = nn.bias_add(%478, %v_param_494);\n",
      "  %480 = nn.batch_norm(%479, %v_param_495, %v_param_496, %v_param_497, %v_param_498, epsilon=1.001e-05f);\n",
      "  %481 = %480.0;\n",
      "  %482 = nn.relu(%481);\n",
      "  %483 = nn.conv2d(%482, %v_param_499, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %484 = nn.bias_add(%483, %v_param_500);\n",
      "  %485 = nn.batch_norm(%484, %v_param_501, %v_param_502, %v_param_503, %v_param_504, epsilon=1.001e-05f);\n",
      "  %486 = %485.0;\n",
      "  %487 = nn.relu(%486);\n",
      "  %488 = nn.conv2d(%487, %v_param_505, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %489 = nn.bias_add(%488, %v_param_506);\n",
      "  %490 = nn.batch_norm(%489, %v_param_507, %v_param_508, %v_param_509, %v_param_510, epsilon=1.001e-05f);\n",
      "  %491 = %490.0;\n",
      "  %492 = add(%477, %491);\n",
      "  %493 = nn.relu(%492);\n",
      "  %494 = nn.conv2d(%493, %v_param_511, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %495 = nn.bias_add(%494, %v_param_512);\n",
      "  %496 = nn.batch_norm(%495, %v_param_513, %v_param_514, %v_param_515, %v_param_516, epsilon=1.001e-05f);\n",
      "  %497 = %496.0;\n",
      "  %498 = nn.relu(%497);\n",
      "  %499 = nn.conv2d(%498, %v_param_517, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %500 = nn.bias_add(%499, %v_param_518);\n",
      "  %501 = nn.batch_norm(%500, %v_param_519, %v_param_520, %v_param_521, %v_param_522, epsilon=1.001e-05f);\n",
      "  %502 = %501.0;\n",
      "  %503 = nn.relu(%502);\n",
      "  %504 = nn.conv2d(%503, %v_param_523, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %505 = nn.bias_add(%504, %v_param_524);\n",
      "  %506 = nn.batch_norm(%505, %v_param_525, %v_param_526, %v_param_527, %v_param_528, epsilon=1.001e-05f);\n",
      "  %507 = %506.0;\n",
      "  %508 = add(%493, %507);\n",
      "  %509 = nn.relu(%508);\n",
      "  %510 = nn.conv2d(%509, %v_param_529, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %511 = nn.bias_add(%510, %v_param_530);\n",
      "  %512 = nn.batch_norm(%511, %v_param_531, %v_param_532, %v_param_533, %v_param_534, epsilon=1.001e-05f);\n",
      "  %513 = %512.0;\n",
      "  %514 = nn.relu(%513);\n",
      "  %515 = nn.conv2d(%514, %v_param_535, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %516 = nn.bias_add(%515, %v_param_536);\n",
      "  %517 = nn.batch_norm(%516, %v_param_537, %v_param_538, %v_param_539, %v_param_540, epsilon=1.001e-05f);\n",
      "  %518 = %517.0;\n",
      "  %519 = nn.relu(%518);\n",
      "  %520 = nn.conv2d(%519, %v_param_541, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %521 = nn.bias_add(%520, %v_param_542);\n",
      "  %522 = nn.batch_norm(%521, %v_param_543, %v_param_544, %v_param_545, %v_param_546, epsilon=1.001e-05f);\n",
      "  %523 = %522.0;\n",
      "  %524 = add(%509, %523);\n",
      "  %525 = nn.relu(%524);\n",
      "  %526 = nn.conv2d(%525, %v_param_547, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %527 = nn.bias_add(%526, %v_param_548);\n",
      "  %528 = nn.batch_norm(%527, %v_param_549, %v_param_550, %v_param_551, %v_param_552, epsilon=1.001e-05f);\n",
      "  %529 = %528.0;\n",
      "  %530 = nn.relu(%529);\n",
      "  %531 = nn.conv2d(%530, %v_param_553, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %532 = nn.bias_add(%531, %v_param_554);\n",
      "  %533 = nn.batch_norm(%532, %v_param_555, %v_param_556, %v_param_557, %v_param_558, epsilon=1.001e-05f);\n",
      "  %534 = %533.0;\n",
      "  %535 = nn.relu(%534);\n",
      "  %536 = nn.conv2d(%535, %v_param_559, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %537 = nn.bias_add(%536, %v_param_560);\n",
      "  %538 = nn.batch_norm(%537, %v_param_561, %v_param_562, %v_param_563, %v_param_564, epsilon=1.001e-05f);\n",
      "  %539 = %538.0;\n",
      "  %540 = add(%525, %539);\n",
      "  %541 = nn.relu(%540);\n",
      "  %542 = nn.conv2d(%541, %v_param_565, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %543 = nn.bias_add(%542, %v_param_566);\n",
      "  %544 = nn.batch_norm(%543, %v_param_567, %v_param_568, %v_param_569, %v_param_570, epsilon=1.001e-05f);\n",
      "  %545 = %544.0;\n",
      "  %546 = nn.relu(%545);\n",
      "  %547 = nn.conv2d(%546, %v_param_571, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %548 = nn.bias_add(%547, %v_param_572);\n",
      "  %549 = nn.batch_norm(%548, %v_param_573, %v_param_574, %v_param_575, %v_param_576, epsilon=1.001e-05f);\n",
      "  %550 = %549.0;\n",
      "  %551 = nn.relu(%550);\n",
      "  %552 = nn.conv2d(%551, %v_param_577, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %553 = nn.bias_add(%552, %v_param_578);\n",
      "  %554 = nn.batch_norm(%553, %v_param_579, %v_param_580, %v_param_581, %v_param_582, epsilon=1.001e-05f);\n",
      "  %555 = %554.0;\n",
      "  %556 = add(%541, %555);\n",
      "  %557 = nn.relu(%556);\n",
      "  %558 = nn.conv2d(%557, %v_param_583, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %559 = nn.bias_add(%558, %v_param_584);\n",
      "  %560 = nn.batch_norm(%559, %v_param_585, %v_param_586, %v_param_587, %v_param_588, epsilon=1.001e-05f);\n",
      "  %561 = %560.0;\n",
      "  %562 = nn.relu(%561);\n",
      "  %563 = nn.conv2d(%562, %v_param_589, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %564 = nn.bias_add(%563, %v_param_590);\n",
      "  %565 = nn.batch_norm(%564, %v_param_591, %v_param_592, %v_param_593, %v_param_594, epsilon=1.001e-05f);\n",
      "  %566 = %565.0;\n",
      "  %567 = nn.relu(%566);\n",
      "  %568 = nn.conv2d(%567, %v_param_595, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %569 = nn.bias_add(%568, %v_param_596);\n",
      "  %570 = nn.batch_norm(%569, %v_param_597, %v_param_598, %v_param_599, %v_param_600, epsilon=1.001e-05f);\n",
      "  %571 = %570.0;\n",
      "  %572 = add(%557, %571);\n",
      "  %573 = nn.relu(%572);\n",
      "  %574 = nn.conv2d(%573, %v_param_601, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %575 = nn.bias_add(%574, %v_param_602);\n",
      "  %576 = nn.batch_norm(%575, %v_param_603, %v_param_604, %v_param_605, %v_param_606, epsilon=1.001e-05f);\n",
      "  %577 = %576.0;\n",
      "  %578 = nn.relu(%577);\n",
      "  %579 = nn.conv2d(%578, %v_param_607, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %580 = nn.bias_add(%579, %v_param_608);\n",
      "  %581 = nn.batch_norm(%580, %v_param_609, %v_param_610, %v_param_611, %v_param_612, epsilon=1.001e-05f);\n",
      "  %582 = %581.0;\n",
      "  %583 = nn.relu(%582);\n",
      "  %584 = nn.conv2d(%583, %v_param_613, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %585 = nn.bias_add(%584, %v_param_614);\n",
      "  %586 = nn.batch_norm(%585, %v_param_615, %v_param_616, %v_param_617, %v_param_618, epsilon=1.001e-05f);\n",
      "  %587 = %586.0;\n",
      "  %588 = add(%573, %587);\n",
      "  %589 = nn.relu(%588);\n",
      "  %590 = nn.conv2d(%589, %v_param_619, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %591 = nn.bias_add(%590, %v_param_620);\n",
      "  %592 = nn.batch_norm(%591, %v_param_621, %v_param_622, %v_param_623, %v_param_624, epsilon=1.001e-05f);\n",
      "  %593 = %592.0;\n",
      "  %594 = nn.relu(%593);\n",
      "  %595 = nn.conv2d(%594, %v_param_625, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %596 = nn.bias_add(%595, %v_param_626);\n",
      "  %597 = nn.batch_norm(%596, %v_param_627, %v_param_628, %v_param_629, %v_param_630, epsilon=1.001e-05f);\n",
      "  %598 = %597.0;\n",
      "  %599 = nn.relu(%598);\n",
      "  %600 = nn.conv2d(%599, %v_param_631, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %601 = nn.bias_add(%600, %v_param_632);\n",
      "  %602 = nn.batch_norm(%601, %v_param_633, %v_param_634, %v_param_635, %v_param_636, epsilon=1.001e-05f);\n",
      "  %603 = %602.0;\n",
      "  %604 = add(%589, %603);\n",
      "  %605 = nn.relu(%604);\n",
      "  %606 = nn.conv2d(%605, %v_param_637, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %607 = nn.bias_add(%606, %v_param_638);\n",
      "  %608 = nn.batch_norm(%607, %v_param_639, %v_param_640, %v_param_641, %v_param_642, epsilon=1.001e-05f);\n",
      "  %609 = %608.0;\n",
      "  %610 = nn.relu(%609);\n",
      "  %611 = nn.conv2d(%610, %v_param_643, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %612 = nn.bias_add(%611, %v_param_644);\n",
      "  %613 = nn.batch_norm(%612, %v_param_645, %v_param_646, %v_param_647, %v_param_648, epsilon=1.001e-05f);\n",
      "  %614 = %613.0;\n",
      "  %615 = nn.relu(%614);\n",
      "  %616 = nn.conv2d(%615, %v_param_649, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %617 = nn.bias_add(%616, %v_param_650);\n",
      "  %618 = nn.batch_norm(%617, %v_param_651, %v_param_652, %v_param_653, %v_param_654, epsilon=1.001e-05f);\n",
      "  %619 = %618.0;\n",
      "  %620 = add(%605, %619);\n",
      "  %621 = nn.relu(%620);\n",
      "  %622 = nn.conv2d(%621, %v_param_655, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %623 = nn.bias_add(%622, %v_param_656);\n",
      "  %624 = nn.batch_norm(%623, %v_param_657, %v_param_658, %v_param_659, %v_param_660, epsilon=1.001e-05f);\n",
      "  %625 = %624.0;\n",
      "  %626 = nn.relu(%625);\n",
      "  %627 = nn.conv2d(%626, %v_param_661, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %628 = nn.bias_add(%627, %v_param_662);\n",
      "  %629 = nn.batch_norm(%628, %v_param_663, %v_param_664, %v_param_665, %v_param_666, epsilon=1.001e-05f);\n",
      "  %630 = %629.0;\n",
      "  %631 = nn.relu(%630);\n",
      "  %632 = nn.conv2d(%631, %v_param_667, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %633 = nn.bias_add(%632, %v_param_668);\n",
      "  %634 = nn.batch_norm(%633, %v_param_669, %v_param_670, %v_param_671, %v_param_672, epsilon=1.001e-05f);\n",
      "  %635 = %634.0;\n",
      "  %636 = add(%621, %635);\n",
      "  %637 = nn.relu(%636);\n",
      "  %638 = nn.conv2d(%637, %v_param_673, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %639 = nn.bias_add(%638, %v_param_674);\n",
      "  %640 = nn.batch_norm(%639, %v_param_675, %v_param_676, %v_param_677, %v_param_678, epsilon=1.001e-05f);\n",
      "  %641 = %640.0;\n",
      "  %642 = nn.relu(%641);\n",
      "  %643 = nn.conv2d(%642, %v_param_679, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %644 = nn.bias_add(%643, %v_param_680);\n",
      "  %645 = nn.batch_norm(%644, %v_param_681, %v_param_682, %v_param_683, %v_param_684, epsilon=1.001e-05f);\n",
      "  %646 = %645.0;\n",
      "  %647 = nn.relu(%646);\n",
      "  %648 = nn.conv2d(%647, %v_param_685, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %649 = nn.bias_add(%648, %v_param_686);\n",
      "  %650 = nn.batch_norm(%649, %v_param_687, %v_param_688, %v_param_689, %v_param_690, epsilon=1.001e-05f);\n",
      "  %651 = %650.0;\n",
      "  %652 = add(%637, %651);\n",
      "  %653 = nn.relu(%652);\n",
      "  %654 = nn.conv2d(%653, %v_param_691, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %655 = nn.bias_add(%654, %v_param_692);\n",
      "  %656 = nn.batch_norm(%655, %v_param_693, %v_param_694, %v_param_695, %v_param_696, epsilon=1.001e-05f);\n",
      "  %657 = %656.0;\n",
      "  %658 = nn.relu(%657);\n",
      "  %659 = nn.conv2d(%658, %v_param_697, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %660 = nn.bias_add(%659, %v_param_698);\n",
      "  %661 = nn.batch_norm(%660, %v_param_699, %v_param_700, %v_param_701, %v_param_702, epsilon=1.001e-05f);\n",
      "  %662 = %661.0;\n",
      "  %663 = nn.relu(%662);\n",
      "  %664 = nn.conv2d(%663, %v_param_703, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %665 = nn.bias_add(%664, %v_param_704);\n",
      "  %666 = nn.batch_norm(%665, %v_param_705, %v_param_706, %v_param_707, %v_param_708, epsilon=1.001e-05f);\n",
      "  %667 = %666.0;\n",
      "  %668 = add(%653, %667);\n",
      "  %669 = nn.relu(%668);\n",
      "  %670 = nn.conv2d(%669, %v_param_709, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %671 = nn.bias_add(%670, %v_param_710);\n",
      "  %672 = nn.batch_norm(%671, %v_param_711, %v_param_712, %v_param_713, %v_param_714, epsilon=1.001e-05f);\n",
      "  %673 = %672.0;\n",
      "  %674 = nn.relu(%673);\n",
      "  %675 = nn.conv2d(%674, %v_param_715, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %676 = nn.bias_add(%675, %v_param_716);\n",
      "  %677 = nn.batch_norm(%676, %v_param_717, %v_param_718, %v_param_719, %v_param_720, epsilon=1.001e-05f);\n",
      "  %678 = %677.0;\n",
      "  %679 = nn.relu(%678);\n",
      "  %680 = nn.conv2d(%679, %v_param_721, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %681 = nn.bias_add(%680, %v_param_722);\n",
      "  %682 = nn.batch_norm(%681, %v_param_723, %v_param_724, %v_param_725, %v_param_726, epsilon=1.001e-05f);\n",
      "  %683 = %682.0;\n",
      "  %684 = add(%669, %683);\n",
      "  %685 = nn.relu(%684);\n",
      "  %686 = nn.conv2d(%685, %v_param_727, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %687 = nn.bias_add(%686, %v_param_728);\n",
      "  %688 = nn.batch_norm(%687, %v_param_729, %v_param_730, %v_param_731, %v_param_732, epsilon=1.001e-05f);\n",
      "  %689 = %688.0;\n",
      "  %690 = nn.relu(%689);\n",
      "  %691 = nn.conv2d(%690, %v_param_733, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %692 = nn.bias_add(%691, %v_param_734);\n",
      "  %693 = nn.batch_norm(%692, %v_param_735, %v_param_736, %v_param_737, %v_param_738, epsilon=1.001e-05f);\n",
      "  %694 = %693.0;\n",
      "  %695 = nn.relu(%694);\n",
      "  %696 = nn.conv2d(%695, %v_param_739, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %697 = nn.bias_add(%696, %v_param_740);\n",
      "  %698 = nn.batch_norm(%697, %v_param_741, %v_param_742, %v_param_743, %v_param_744, epsilon=1.001e-05f);\n",
      "  %699 = %698.0;\n",
      "  %700 = add(%685, %699);\n",
      "  %701 = nn.relu(%700);\n",
      "  %702 = nn.conv2d(%701, %v_param_745, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %703 = nn.bias_add(%702, %v_param_746);\n",
      "  %704 = nn.batch_norm(%703, %v_param_747, %v_param_748, %v_param_749, %v_param_750, epsilon=1.001e-05f);\n",
      "  %705 = %704.0;\n",
      "  %706 = nn.relu(%705);\n",
      "  %707 = nn.conv2d(%706, %v_param_751, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %708 = nn.bias_add(%707, %v_param_752);\n",
      "  %709 = nn.batch_norm(%708, %v_param_753, %v_param_754, %v_param_755, %v_param_756, epsilon=1.001e-05f);\n",
      "  %710 = %709.0;\n",
      "  %711 = nn.relu(%710);\n",
      "  %712 = nn.conv2d(%711, %v_param_757, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %713 = nn.bias_add(%712, %v_param_758);\n",
      "  %714 = nn.batch_norm(%713, %v_param_759, %v_param_760, %v_param_761, %v_param_762, epsilon=1.001e-05f);\n",
      "  %715 = %714.0;\n",
      "  %716 = add(%701, %715);\n",
      "  %717 = nn.relu(%716);\n",
      "  %718 = nn.conv2d(%717, %v_param_763, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %719 = nn.bias_add(%718, %v_param_764);\n",
      "  %720 = nn.batch_norm(%719, %v_param_765, %v_param_766, %v_param_767, %v_param_768, epsilon=1.001e-05f);\n",
      "  %721 = %720.0;\n",
      "  %722 = nn.relu(%721);\n",
      "  %723 = nn.conv2d(%722, %v_param_769, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %724 = nn.bias_add(%723, %v_param_770);\n",
      "  %725 = nn.batch_norm(%724, %v_param_771, %v_param_772, %v_param_773, %v_param_774, epsilon=1.001e-05f);\n",
      "  %726 = %725.0;\n",
      "  %727 = nn.relu(%726);\n",
      "  %728 = nn.conv2d(%727, %v_param_775, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %729 = nn.bias_add(%728, %v_param_776);\n",
      "  %730 = nn.batch_norm(%729, %v_param_777, %v_param_778, %v_param_779, %v_param_780, epsilon=1.001e-05f);\n",
      "  %731 = %730.0;\n",
      "  %732 = add(%717, %731);\n",
      "  %733 = nn.relu(%732);\n",
      "  %734 = nn.conv2d(%733, %v_param_781, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %735 = nn.bias_add(%734, %v_param_782);\n",
      "  %736 = nn.batch_norm(%735, %v_param_783, %v_param_784, %v_param_785, %v_param_786, epsilon=1.001e-05f);\n",
      "  %737 = %736.0;\n",
      "  %738 = nn.relu(%737);\n",
      "  %739 = nn.conv2d(%738, %v_param_787, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %740 = nn.bias_add(%739, %v_param_788);\n",
      "  %741 = nn.batch_norm(%740, %v_param_789, %v_param_790, %v_param_791, %v_param_792, epsilon=1.001e-05f);\n",
      "  %742 = %741.0;\n",
      "  %743 = nn.relu(%742);\n",
      "  %744 = nn.conv2d(%743, %v_param_793, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %745 = nn.bias_add(%744, %v_param_794);\n",
      "  %746 = nn.batch_norm(%745, %v_param_795, %v_param_796, %v_param_797, %v_param_798, epsilon=1.001e-05f);\n",
      "  %747 = %746.0;\n",
      "  %748 = add(%733, %747);\n",
      "  %749 = nn.relu(%748);\n",
      "  %750 = nn.conv2d(%749, %v_param_799, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %751 = nn.bias_add(%750, %v_param_800);\n",
      "  %752 = nn.batch_norm(%751, %v_param_801, %v_param_802, %v_param_803, %v_param_804, epsilon=1.001e-05f);\n",
      "  %753 = %752.0;\n",
      "  %754 = nn.relu(%753);\n",
      "  %755 = nn.conv2d(%754, %v_param_805, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %756 = nn.bias_add(%755, %v_param_806);\n",
      "  %757 = nn.batch_norm(%756, %v_param_807, %v_param_808, %v_param_809, %v_param_810, epsilon=1.001e-05f);\n",
      "  %758 = %757.0;\n",
      "  %759 = nn.relu(%758);\n",
      "  %760 = nn.conv2d(%759, %v_param_811, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %761 = nn.bias_add(%760, %v_param_812);\n",
      "  %762 = nn.batch_norm(%761, %v_param_813, %v_param_814, %v_param_815, %v_param_816, epsilon=1.001e-05f);\n",
      "  %763 = %762.0;\n",
      "  %764 = add(%749, %763);\n",
      "  %765 = nn.relu(%764);\n",
      "  %766 = nn.conv2d(%765, %v_param_817, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %767 = nn.bias_add(%766, %v_param_818);\n",
      "  %768 = nn.batch_norm(%767, %v_param_819, %v_param_820, %v_param_821, %v_param_822, epsilon=1.001e-05f);\n",
      "  %769 = %768.0;\n",
      "  %770 = nn.relu(%769);\n",
      "  %771 = nn.conv2d(%770, %v_param_823, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %772 = nn.bias_add(%771, %v_param_824);\n",
      "  %773 = nn.batch_norm(%772, %v_param_825, %v_param_826, %v_param_827, %v_param_828, epsilon=1.001e-05f);\n",
      "  %774 = %773.0;\n",
      "  %775 = nn.relu(%774);\n",
      "  %776 = nn.conv2d(%775, %v_param_829, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %777 = nn.bias_add(%776, %v_param_830);\n",
      "  %778 = nn.batch_norm(%777, %v_param_831, %v_param_832, %v_param_833, %v_param_834, epsilon=1.001e-05f);\n",
      "  %779 = %778.0;\n",
      "  %780 = add(%765, %779);\n",
      "  %781 = nn.relu(%780);\n",
      "  %782 = nn.conv2d(%781, %v_param_835, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %783 = nn.bias_add(%782, %v_param_836);\n",
      "  %784 = nn.batch_norm(%783, %v_param_837, %v_param_838, %v_param_839, %v_param_840, epsilon=1.001e-05f);\n",
      "  %785 = %784.0;\n",
      "  %786 = nn.relu(%785);\n",
      "  %787 = nn.conv2d(%786, %v_param_841, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %788 = nn.bias_add(%787, %v_param_842);\n",
      "  %789 = nn.batch_norm(%788, %v_param_843, %v_param_844, %v_param_845, %v_param_846, epsilon=1.001e-05f);\n",
      "  %790 = %789.0;\n",
      "  %791 = nn.relu(%790);\n",
      "  %792 = nn.conv2d(%791, %v_param_847, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %793 = nn.bias_add(%792, %v_param_848);\n",
      "  %794 = nn.batch_norm(%793, %v_param_849, %v_param_850, %v_param_851, %v_param_852, epsilon=1.001e-05f);\n",
      "  %795 = %794.0;\n",
      "  %796 = add(%781, %795);\n",
      "  %797 = nn.relu(%796);\n",
      "  %798 = nn.conv2d(%797, %v_param_853, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %799 = nn.bias_add(%798, %v_param_854);\n",
      "  %800 = nn.batch_norm(%799, %v_param_855, %v_param_856, %v_param_857, %v_param_858, epsilon=1.001e-05f);\n",
      "  %801 = %800.0;\n",
      "  %802 = nn.relu(%801);\n",
      "  %803 = nn.conv2d(%802, %v_param_859, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %804 = nn.bias_add(%803, %v_param_860);\n",
      "  %805 = nn.batch_norm(%804, %v_param_861, %v_param_862, %v_param_863, %v_param_864, epsilon=1.001e-05f);\n",
      "  %806 = %805.0;\n",
      "  %807 = nn.relu(%806);\n",
      "  %808 = nn.conv2d(%807, %v_param_865, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %809 = nn.bias_add(%808, %v_param_866);\n",
      "  %810 = nn.batch_norm(%809, %v_param_867, %v_param_868, %v_param_869, %v_param_870, epsilon=1.001e-05f);\n",
      "  %811 = %810.0;\n",
      "  %812 = add(%797, %811);\n",
      "  %813 = nn.relu(%812);\n",
      "  %814 = nn.conv2d(%813, %v_param_883, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %815 = nn.bias_add(%814, %v_param_884);\n",
      "  %816 = nn.batch_norm(%815, %v_param_887, %v_param_888, %v_param_889, %v_param_890, epsilon=1.001e-05f);\n",
      "  %817 = nn.conv2d(%813, %v_param_871, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %818 = nn.bias_add(%817, %v_param_872);\n",
      "  %819 = nn.batch_norm(%818, %v_param_873, %v_param_874, %v_param_875, %v_param_876, epsilon=1.001e-05f);\n",
      "  %820 = %819.0;\n",
      "  %821 = nn.relu(%820);\n",
      "  %822 = nn.conv2d(%821, %v_param_877, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %823 = nn.bias_add(%822, %v_param_878);\n",
      "  %824 = nn.batch_norm(%823, %v_param_879, %v_param_880, %v_param_881, %v_param_882, epsilon=1.001e-05f);\n",
      "  %825 = %824.0;\n",
      "  %826 = nn.relu(%825);\n",
      "  %827 = nn.conv2d(%826, %v_param_885, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %828 = nn.bias_add(%827, %v_param_886);\n",
      "  %829 = nn.batch_norm(%828, %v_param_891, %v_param_892, %v_param_893, %v_param_894, epsilon=1.001e-05f);\n",
      "  %830 = %816.0;\n",
      "  %831 = %829.0;\n",
      "  %832 = add(%830, %831);\n",
      "  %833 = nn.relu(%832);\n",
      "  %834 = nn.conv2d(%833, %v_param_895, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %835 = nn.bias_add(%834, %v_param_896);\n",
      "  %836 = nn.batch_norm(%835, %v_param_897, %v_param_898, %v_param_899, %v_param_900, epsilon=1.001e-05f);\n",
      "  %837 = %836.0;\n",
      "  %838 = nn.relu(%837);\n",
      "  %839 = nn.conv2d(%838, %v_param_901, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %840 = nn.bias_add(%839, %v_param_902);\n",
      "  %841 = nn.batch_norm(%840, %v_param_903, %v_param_904, %v_param_905, %v_param_906, epsilon=1.001e-05f);\n",
      "  %842 = %841.0;\n",
      "  %843 = nn.relu(%842);\n",
      "  %844 = nn.conv2d(%843, %v_param_907, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %845 = nn.bias_add(%844, %v_param_908);\n",
      "  %846 = nn.batch_norm(%845, %v_param_909, %v_param_910, %v_param_911, %v_param_912, epsilon=1.001e-05f);\n",
      "  %847 = %846.0;\n",
      "  %848 = add(%833, %847);\n",
      "  %849 = nn.relu(%848);\n",
      "  %850 = nn.conv2d(%849, %v_param_913, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %851 = nn.bias_add(%850, %v_param_914);\n",
      "  %852 = nn.batch_norm(%851, %v_param_915, %v_param_916, %v_param_917, %v_param_918, epsilon=1.001e-05f);\n",
      "  %853 = %852.0;\n",
      "  %854 = nn.relu(%853);\n",
      "  %855 = nn.conv2d(%854, %v_param_919, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %856 = nn.bias_add(%855, %v_param_920);\n",
      "  %857 = nn.batch_norm(%856, %v_param_921, %v_param_922, %v_param_923, %v_param_924, epsilon=1.001e-05f);\n",
      "  %858 = %857.0;\n",
      "  %859 = nn.relu(%858);\n",
      "  %860 = nn.conv2d(%859, %v_param_925, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %861 = nn.bias_add(%860, %v_param_926);\n",
      "  %862 = nn.batch_norm(%861, %v_param_927, %v_param_928, %v_param_929, %v_param_930, epsilon=1.001e-05f);\n",
      "  %863 = %862.0;\n",
      "  %864 = add(%849, %863);\n",
      "  %865 = nn.relu(%864);\n",
      "  %866 = nn.global_avg_pool2d(%865);\n",
      "  %867 = transpose(%866, axes=[0, 2, 3, 1]);\n",
      "  %868 = nn.batch_flatten(%867);\n",
      "  %869 = nn.dense(%868, %v_param_931, units=1000);\n",
      "  %870 = nn.bias_add(%869, %v_param_932);\n",
      "  nn.softmax(%870, axis=1)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "out = rewrite(Resnet152Callback(), mod['main'])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JunoCallback(DFPatternCallback):\n",
    "#     # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "#     def __init__(self, require_type=False):\n",
    "#         super().__init__(require_type)\n",
    "#         super().__init__(rewrite_once=True)\n",
    "#         # self.x = wildcard()\n",
    "#         self.var1 = wildcard()\n",
    "#         self.var2 = wildcard()\n",
    "#         self.pool_size = is_constant()\n",
    "#         self.strides = is_constant()\n",
    "#         self.padding = is_constant()\n",
    "#         self.padding = [1, 1, 1, 1]\n",
    "#         bn_node = is_op('nn.batch_norm')(wildcard(), wildcard(), wildcard(), wildcard(), wildcard())\n",
    "#         tuple_get_item_node = is_tuple_get_item(bn_node, 0)\n",
    "#         tupling = is_tuple([wildcard(), self.var2])\n",
    "#         self.pattern = dominates(tuple_get_item_node, wildcard(), tupling)\n",
    "#         # self.pattern = is_op('nn.batch_norm')(wildcard(), wildcard(),wildcard(),wildcard(),wildcard())\n",
    "#         self.cnt = 0\n",
    "#         self.target = 1\n",
    "#         self.target_node = []\n",
    "\n",
    "#     def callback(self, pre, post, node_map):\n",
    "#         # var1 = node_map[self.var1][0]\n",
    "#         var2 = node_map[self.var2][0]\n",
    "#         # self.target_node.append(var2)\n",
    "#         print(post)        # return post\n",
    "#         # return post\n",
    "#         # original = post\n",
    "#         if self.cnt != self.target:\n",
    "#             self.cnt += 1\n",
    "#             return post\n",
    "#         else:\n",
    "#             self.cnt += 1\n",
    "#             cast_to_int8 = relay.cast(\n",
    "#                 relay.clip(\n",
    "#                     relay.round(\n",
    "#                         relay.multiply(post, relay.const(16.0))\n",
    "#                     ), \n",
    "#                     a_min=-127.0, a_max=127.0\n",
    "#                 ),\n",
    "#                 dtype=\"int8\"\n",
    "#             )\n",
    "#             cast_to_float32 = relay.cast(\n",
    "#                 relay.clip(\n",
    "#                     relay.right_shift(\n",
    "#                         relay.add(relay.cast(relay.annotation.stop_fusion(cast_to_int8), dtype='int32'), relay.const(512)),\n",
    "#                         relay.const(10)),\n",
    "#                     a_min=-127.0, a_max=127.0), \n",
    "#                 dtype=\"float32\"\n",
    "#             )\n",
    "#             print(type(var1))\n",
    "#             print(type(cast_to_float32))\n",
    "#             print(type(post))\n",
    "#             return relay.op.Tuple([var1, cast_to_float32])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = JunoCallback()\n",
    "out = rewrite(jc, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Juno2Callback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, target_pat, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        self.var1 = wildcard()\n",
    "        self.var2 = wildcard()\n",
    "        self.pool_size = is_constant()\n",
    "        self.strides = is_constant()\n",
    "        self.padding = is_constant()\n",
    "        self.padding = [1, 1, 1, 1]\n",
    "        self.pattern = TupleGetItemPattern(target_pat)\n",
    "        # self.pattern = is_op('nn.batch_norm')(wildcard(), wildcard(),wildcard(),wildcard(),wildcard())\n",
    "        self.cnt = 0\n",
    "        self.target = 1\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(post, relay.const(16.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        cast_to_float32 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.right_shift(\n",
    "                    relay.add(relay.cast(relay.annotation.stop_fusion(cast_to_int8), dtype='int32'), relay.const(512)),\n",
    "                    relay.const(10)),\n",
    "                a_min=-127.0, a_max=127.0), \n",
    "            dtype=\"float32\"\n",
    "        )\n",
    "        print(type(cast_to_float32))\n",
    "        print(type(post))\n",
    "        return cast_to_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  2: TVMFuncCall\n  1: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::TupleGetItemPattern (tvm::relay::DFPattern, int)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}>(tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  3: TVMFuncCall\n  2: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::TupleGetItemPattern (tvm::relay::DFPattern, int)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}>(tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  0: tvm::relay::DFPattern tvm::runtime::TVMPODValue_::AsObjectRef<tvm::relay::DFPattern>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function relay.dataflow_pattern.TupleGetItemPattern: error while converting argument 0: [16:58:43] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected DFPatternNode, but got relay.TupleGetItem\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m jc2 \u001b[39m=\u001b[39m Juno2Callback(jc\u001b[39m.\u001b[39;49mtarget_node[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 7'\u001b[0m in \u001b[0;36mJuno2Callback.__init__\u001b[0;34m(self, target_pat, require_type)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000006vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding \u001b[39m=\u001b[39m is_constant()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000006vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000006vscode-remote?line=12'>13</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpattern \u001b[39m=\u001b[39m TupleGetItemPattern(target_pat)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000006vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# self.pattern = is_op('nn.batch_norm')(wildcard(), wildcard(),wildcard(),wildcard(),wildcard())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000006vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnt \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py:670\u001b[0m, in \u001b[0;36mTupleGetItemPattern.__init__\u001b[0;34m(self, tuple_value, index)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=667'>668</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, tuple_value: \u001b[39m\"\u001b[39m\u001b[39mDFPattern\u001b[39m\u001b[39m\"\u001b[39m, index: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=668'>669</a>\u001b[0m     match_index \u001b[39m=\u001b[39m index \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=669'>670</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__init_handle_by_constructor__(ffi\u001b[39m.\u001b[39;49mTupleGetItemPattern, tuple_value, match_index)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py:136\u001b[0m, in \u001b[0;36mObjectBase.__init_handle_by_constructor__\u001b[0;34m(self, fconstructor, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=132'>133</a>\u001b[0m \u001b[39m# assign handle first to avoid error raising\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=133'>134</a>\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=134'>135</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=135'>136</a>\u001b[0m handle \u001b[39m=\u001b[39m __init_by_constructor__(fconstructor, args)\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=136'>137</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, ObjectHandle):\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=137'>138</a>\u001b[0m     handle \u001b[39m=\u001b[39m ObjectHandle(handle)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py:260\u001b[0m, in \u001b[0;36m__init_handle_by_constructor__\u001b[0;34m(fconstructor, args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=247'>248</a>\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=248'>249</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=249'>250</a>\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=250'>251</a>\u001b[0m         fconstructor\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=257'>258</a>\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=258'>259</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=259'>260</a>\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=260'>261</a>\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=261'>262</a>\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  2: TVMFuncCall\n  1: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::TupleGetItemPattern (tvm::relay::DFPattern, int)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}>(tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  3: TVMFuncCall\n  2: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::relay::TupleGetItemPattern (tvm::relay::DFPattern, int)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}>(tvm::relay::{lambda(tvm::relay::DFPattern, int)#26}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  0: tvm::relay::DFPattern tvm::runtime::TVMPODValue_::AsObjectRef<tvm::relay::DFPattern>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function relay.dataflow_pattern.TupleGetItemPattern: error while converting argument 0: [16:58:43] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected DFPatternNode, but got relay.TupleGetItem\n"
     ]
    }
   ],
   "source": [
    "jc2 = Juno2Callback(jc.target_node[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::TypedPackedFunc<tvm::relay::DFPatternCallback (tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}>(tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  3: TVMFuncCall\n  2: tvm::runtime::TypedPackedFunc<tvm::relay::DFPatternCallback (tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}>(tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  0: tvm::relay::DFPattern tvm::runtime::TVMPODValue_::AsObjectRef<tvm::relay::DFPattern>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function relay.dataflow_pattern.DFPatternCallback: error while converting argument 0: [16:58:01] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected DFPatternNode, but got relay.TupleGetItem\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bj-server/home/j/tvm-slicer/tvm-slicer/src/quantize_test.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m rewrite(jc2, mod[\u001b[39m'\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py:880\u001b[0m, in \u001b[0;36mrewrite\u001b[0;34m(callbacks, expr, mod)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=876'>877</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m callbacks:\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=877'>878</a>\u001b[0m     \u001b[39massert\u001b[39;00m callback\u001b[39m.\u001b[39mpattern \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=878'>879</a>\u001b[0m     tmp\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=879'>880</a>\u001b[0m         _DFPatternCallback(\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=880'>881</a>\u001b[0m             callback\u001b[39m.\u001b[39;49mpattern, callback\u001b[39m.\u001b[39;49mcallback, callback\u001b[39m.\u001b[39;49mrequire_type, callback\u001b[39m.\u001b[39;49mrewrite_once\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=881'>882</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=882'>883</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=884'>885</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ffi\u001b[39m.\u001b[39mrewrite(tmp, expr, mod)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py:850\u001b[0m, in \u001b[0;36m_DFPatternCallback.__init__\u001b[0;34m(self, pattern, callback, require_type, rewrite_once)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=848'>849</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, pattern, callback, require_type, rewrite_once):\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=849'>850</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__init_handle_by_constructor__(\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=850'>851</a>\u001b[0m         ffi\u001b[39m.\u001b[39;49mDFPatternCallback, pattern, callback, require_type, rewrite_once\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/relay/dataflow_pattern/__init__.py?line=851'>852</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py:136\u001b[0m, in \u001b[0;36mObjectBase.__init_handle_by_constructor__\u001b[0;34m(self, fconstructor, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=132'>133</a>\u001b[0m \u001b[39m# assign handle first to avoid error raising\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=133'>134</a>\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=134'>135</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=135'>136</a>\u001b[0m handle \u001b[39m=\u001b[39m __init_by_constructor__(fconstructor, args)\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=136'>137</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, ObjectHandle):\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/object.py?line=137'>138</a>\u001b[0m     handle \u001b[39m=\u001b[39m ObjectHandle(handle)\n",
      "File \u001b[0;32m~/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py:260\u001b[0m, in \u001b[0;36m__init_handle_by_constructor__\u001b[0;34m(fconstructor, args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=247'>248</a>\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=248'>249</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=249'>250</a>\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=250'>251</a>\u001b[0m         fconstructor\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=257'>258</a>\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=258'>259</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=259'>260</a>\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=260'>261</a>\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    <a href='file:///home/j/tvm-slicer/include/tvm/python/tvm/_ffi/_ctypes/packed_func.py?line=261'>262</a>\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::TypedPackedFunc<tvm::relay::DFPatternCallback (tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}>(tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  3: TVMFuncCall\n  2: tvm::runtime::TypedPackedFunc<tvm::relay::DFPatternCallback (tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)>::AssignTypedLambda<tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}>(tvm::relay::{lambda(tvm::relay::DFPattern, tvm::runtime::PackedFunc, bool, bool)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::relay::DFPattern<tvm::relay::DFPattern>() const\n  0: tvm::relay::DFPattern tvm::runtime::TVMPODValue_::AsObjectRef<tvm::relay::DFPattern>() const\n  File \"/home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h\", line 714\nTVMError: In function relay.dataflow_pattern.DFPatternCallback: error while converting argument 0: [16:58:01] /home/j/tvm-slicer/include/tvm/include/tvm/runtime/packed_func.h:1591: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected DFPatternNode, but got relay.TupleGetItem\n"
     ]
    }
   ],
   "source": [
    "out = rewrite(jc2, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 11:25:55.544997: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-24 11:25:55.548184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-24 11:25:55.579905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.583478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-04-24 11:25:55.583497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-24 11:25:55.646990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-24 11:25:55.647141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-04-24 11:25:55.682625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-24 11:25:55.695959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-24 11:25:55.753031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-24 11:25:55.767618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-04-24 11:25:55.767761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-24 11:25:55.767951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.769437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.772385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-24 11:25:55.773281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 11:25:55.774788: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-24 11:25:55.775021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.776386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-04-24 11:25:55.776449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-24 11:25:55.776503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-24 11:25:55.776547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-04-24 11:25:55.776590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-24 11:25:55.776632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-24 11:25:55.776674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-24 11:25:55.776720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-04-24 11:25:55.776752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-24 11:25:55.776882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.778299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:55.779596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-24 11:25:57.983115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-24 11:25:57.983160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-24 11:25:57.983173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-24 11:25:57.986238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:57.987137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:57.987955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 11:25:57.988731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9961 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model_keras = tf.keras.models.load_model(PATH_MODEL + '{}_{}.h5'.format(\"resnet152\", 224))\n",
    "\n",
    "input_data = (np.random.randint(0,256,(1,224,224,3)) / 255).astype(np.float32)\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "shape_dict = {\"input_1\": input_data.shape}\n",
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%input_1: Tensor[(1, 3, 224, 224), float32], %v_param_1: Tensor[(64, 3, 7, 7), float32], %v_param_2: Tensor[(64), float32], %v_param_3: Tensor[(64), float32], %v_param_4: Tensor[(64), float32], %v_param_5: Tensor[(64), float32], %v_param_6: Tensor[(64), float32], %v_param_19: Tensor[(256, 64, 1, 1), float32], %v_param_20: Tensor[(256), float32], %v_param_23: Tensor[(256), float32], %v_param_24: Tensor[(256), float32], %v_param_25: Tensor[(256), float32], %v_param_26: Tensor[(256), float32], %v_param_7: Tensor[(64, 64, 1, 1), float32], %v_param_8: Tensor[(64), float32], %v_param_9: Tensor[(64), float32], %v_param_10: Tensor[(64), float32], %v_param_11: Tensor[(64), float32], %v_param_12: Tensor[(64), float32], %v_param_13: Tensor[(64, 64, 3, 3), float32], %v_param_14: Tensor[(64), float32], %v_param_15: Tensor[(64), float32], %v_param_16: Tensor[(64), float32], %v_param_17: Tensor[(64), float32], %v_param_18: Tensor[(64), float32], %v_param_21: Tensor[(256, 64, 1, 1), float32], %v_param_22: Tensor[(256), float32], %v_param_27: Tensor[(256), float32], %v_param_28: Tensor[(256), float32], %v_param_29: Tensor[(256), float32], %v_param_30: Tensor[(256), float32], %v_param_31: Tensor[(64, 256, 1, 1), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(64, 64, 3, 3), float32], %v_param_38: Tensor[(64), float32], %v_param_39: Tensor[(64), float32], %v_param_40: Tensor[(64), float32], %v_param_41: Tensor[(64), float32], %v_param_42: Tensor[(64), float32], %v_param_43: Tensor[(256, 64, 1, 1), float32], %v_param_44: Tensor[(256), float32], %v_param_45: Tensor[(256), float32], %v_param_46: Tensor[(256), float32], %v_param_47: Tensor[(256), float32], %v_param_48: Tensor[(256), float32], %v_param_49: Tensor[(64, 256, 1, 1), float32], %v_param_50: Tensor[(64), float32], %v_param_51: Tensor[(64), float32], %v_param_52: Tensor[(64), float32], %v_param_53: Tensor[(64), float32], %v_param_54: Tensor[(64), float32], %v_param_55: Tensor[(64, 64, 3, 3), float32], %v_param_56: Tensor[(64), float32], %v_param_57: Tensor[(64), float32], %v_param_58: Tensor[(64), float32], %v_param_59: Tensor[(64), float32], %v_param_60: Tensor[(64), float32], %v_param_61: Tensor[(256, 64, 1, 1), float32], %v_param_62: Tensor[(256), float32], %v_param_63: Tensor[(256), float32], %v_param_64: Tensor[(256), float32], %v_param_65: Tensor[(256), float32], %v_param_66: Tensor[(256), float32], %v_param_79: Tensor[(512, 256, 1, 1), float32], %v_param_80: Tensor[(512), float32], %v_param_83: Tensor[(512), float32], %v_param_84: Tensor[(512), float32], %v_param_85: Tensor[(512), float32], %v_param_86: Tensor[(512), float32], %v_param_67: Tensor[(128, 256, 1, 1), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_81: Tensor[(512, 128, 1, 1), float32], %v_param_82: Tensor[(512), float32], %v_param_87: Tensor[(512), float32], %v_param_88: Tensor[(512), float32], %v_param_89: Tensor[(512), float32], %v_param_90: Tensor[(512), float32], %v_param_91: Tensor[(128, 512, 1, 1), float32], %v_param_92: Tensor[(128), float32], %v_param_93: Tensor[(128), float32], %v_param_94: Tensor[(128), float32], %v_param_95: Tensor[(128), float32], %v_param_96: Tensor[(128), float32], %v_param_97: Tensor[(128, 128, 3, 3), float32], %v_param_98: Tensor[(128), float32], %v_param_99: Tensor[(128), float32], %v_param_100: Tensor[(128), float32], %v_param_101: Tensor[(128), float32], %v_param_102: Tensor[(128), float32], %v_param_103: Tensor[(512, 128, 1, 1), float32], %v_param_104: Tensor[(512), float32], %v_param_105: Tensor[(512), float32], %v_param_106: Tensor[(512), float32], %v_param_107: Tensor[(512), float32], %v_param_108: Tensor[(512), float32], %v_param_109: Tensor[(128, 512, 1, 1), float32], %v_param_110: Tensor[(128), float32], %v_param_111: Tensor[(128), float32], %v_param_112: Tensor[(128), float32], %v_param_113: Tensor[(128), float32], %v_param_114: Tensor[(128), float32], %v_param_115: Tensor[(128, 128, 3, 3), float32], %v_param_116: Tensor[(128), float32], %v_param_117: Tensor[(128), float32], %v_param_118: Tensor[(128), float32], %v_param_119: Tensor[(128), float32], %v_param_120: Tensor[(128), float32], %v_param_121: Tensor[(512, 128, 1, 1), float32], %v_param_122: Tensor[(512), float32], %v_param_123: Tensor[(512), float32], %v_param_124: Tensor[(512), float32], %v_param_125: Tensor[(512), float32], %v_param_126: Tensor[(512), float32], %v_param_127: Tensor[(128, 512, 1, 1), float32], %v_param_128: Tensor[(128), float32], %v_param_129: Tensor[(128), float32], %v_param_130: Tensor[(128), float32], %v_param_131: Tensor[(128), float32], %v_param_132: Tensor[(128), float32], %v_param_133: Tensor[(128, 128, 3, 3), float32], %v_param_134: Tensor[(128), float32], %v_param_135: Tensor[(128), float32], %v_param_136: Tensor[(128), float32], %v_param_137: Tensor[(128), float32], %v_param_138: Tensor[(128), float32], %v_param_139: Tensor[(512, 128, 1, 1), float32], %v_param_140: Tensor[(512), float32], %v_param_141: Tensor[(512), float32], %v_param_142: Tensor[(512), float32], %v_param_143: Tensor[(512), float32], %v_param_144: Tensor[(512), float32], %v_param_145: Tensor[(128, 512, 1, 1), float32], %v_param_146: Tensor[(128), float32], %v_param_147: Tensor[(128), float32], %v_param_148: Tensor[(128), float32], %v_param_149: Tensor[(128), float32], %v_param_150: Tensor[(128), float32], %v_param_151: Tensor[(128, 128, 3, 3), float32], %v_param_152: Tensor[(128), float32], %v_param_153: Tensor[(128), float32], %v_param_154: Tensor[(128), float32], %v_param_155: Tensor[(128), float32], %v_param_156: Tensor[(128), float32], %v_param_157: Tensor[(512, 128, 1, 1), float32], %v_param_158: Tensor[(512), float32], %v_param_159: Tensor[(512), float32], %v_param_160: Tensor[(512), float32], %v_param_161: Tensor[(512), float32], %v_param_162: Tensor[(512), float32], %v_param_163: Tensor[(128, 512, 1, 1), float32], %v_param_164: Tensor[(128), float32], %v_param_165: Tensor[(128), float32], %v_param_166: Tensor[(128), float32], %v_param_167: Tensor[(128), float32], %v_param_168: Tensor[(128), float32], %v_param_169: Tensor[(128, 128, 3, 3), float32], %v_param_170: Tensor[(128), float32], %v_param_171: Tensor[(128), float32], %v_param_172: Tensor[(128), float32], %v_param_173: Tensor[(128), float32], %v_param_174: Tensor[(128), float32], %v_param_175: Tensor[(512, 128, 1, 1), float32], %v_param_176: Tensor[(512), float32], %v_param_177: Tensor[(512), float32], %v_param_178: Tensor[(512), float32], %v_param_179: Tensor[(512), float32], %v_param_180: Tensor[(512), float32], %v_param_181: Tensor[(128, 512, 1, 1), float32], %v_param_182: Tensor[(128), float32], %v_param_183: Tensor[(128), float32], %v_param_184: Tensor[(128), float32], %v_param_185: Tensor[(128), float32], %v_param_186: Tensor[(128), float32], %v_param_187: Tensor[(128, 128, 3, 3), float32], %v_param_188: Tensor[(128), float32], %v_param_189: Tensor[(128), float32], %v_param_190: Tensor[(128), float32], %v_param_191: Tensor[(128), float32], %v_param_192: Tensor[(128), float32], %v_param_193: Tensor[(512, 128, 1, 1), float32], %v_param_194: Tensor[(512), float32], %v_param_195: Tensor[(512), float32], %v_param_196: Tensor[(512), float32], %v_param_197: Tensor[(512), float32], %v_param_198: Tensor[(512), float32], %v_param_199: Tensor[(128, 512, 1, 1), float32], %v_param_200: Tensor[(128), float32], %v_param_201: Tensor[(128), float32], %v_param_202: Tensor[(128), float32], %v_param_203: Tensor[(128), float32], %v_param_204: Tensor[(128), float32], %v_param_205: Tensor[(128, 128, 3, 3), float32], %v_param_206: Tensor[(128), float32], %v_param_207: Tensor[(128), float32], %v_param_208: Tensor[(128), float32], %v_param_209: Tensor[(128), float32], %v_param_210: Tensor[(128), float32], %v_param_211: Tensor[(512, 128, 1, 1), float32], %v_param_212: Tensor[(512), float32], %v_param_213: Tensor[(512), float32], %v_param_214: Tensor[(512), float32], %v_param_215: Tensor[(512), float32], %v_param_216: Tensor[(512), float32], %v_param_229: Tensor[(1024, 512, 1, 1), float32], %v_param_230: Tensor[(1024), float32], %v_param_233: Tensor[(1024), float32], %v_param_234: Tensor[(1024), float32], %v_param_235: Tensor[(1024), float32], %v_param_236: Tensor[(1024), float32], %v_param_217: Tensor[(256, 512, 1, 1), float32], %v_param_218: Tensor[(256), float32], %v_param_219: Tensor[(256), float32], %v_param_220: Tensor[(256), float32], %v_param_221: Tensor[(256), float32], %v_param_222: Tensor[(256), float32], %v_param_223: Tensor[(256, 256, 3, 3), float32], %v_param_224: Tensor[(256), float32], %v_param_225: Tensor[(256), float32], %v_param_226: Tensor[(256), float32], %v_param_227: Tensor[(256), float32], %v_param_228: Tensor[(256), float32], %v_param_231: Tensor[(1024, 256, 1, 1), float32], %v_param_232: Tensor[(1024), float32], %v_param_237: Tensor[(1024), float32], %v_param_238: Tensor[(1024), float32], %v_param_239: Tensor[(1024), float32], %v_param_240: Tensor[(1024), float32], %v_param_241: Tensor[(256, 1024, 1, 1), float32], %v_param_242: Tensor[(256), float32], %v_param_243: Tensor[(256), float32], %v_param_244: Tensor[(256), float32], %v_param_245: Tensor[(256), float32], %v_param_246: Tensor[(256), float32], %v_param_247: Tensor[(256, 256, 3, 3), float32], %v_param_248: Tensor[(256), float32], %v_param_249: Tensor[(256), float32], %v_param_250: Tensor[(256), float32], %v_param_251: Tensor[(256), float32], %v_param_252: Tensor[(256), float32], %v_param_253: Tensor[(1024, 256, 1, 1), float32], %v_param_254: Tensor[(1024), float32], %v_param_255: Tensor[(1024), float32], %v_param_256: Tensor[(1024), float32], %v_param_257: Tensor[(1024), float32], %v_param_258: Tensor[(1024), float32], %v_param_259: Tensor[(256, 1024, 1, 1), float32], %v_param_260: Tensor[(256), float32], %v_param_261: Tensor[(256), float32], %v_param_262: Tensor[(256), float32], %v_param_263: Tensor[(256), float32], %v_param_264: Tensor[(256), float32], %v_param_265: Tensor[(256, 256, 3, 3), float32], %v_param_266: Tensor[(256), float32], %v_param_267: Tensor[(256), float32], %v_param_268: Tensor[(256), float32], %v_param_269: Tensor[(256), float32], %v_param_270: Tensor[(256), float32], %v_param_271: Tensor[(1024, 256, 1, 1), float32], %v_param_272: Tensor[(1024), float32], %v_param_273: Tensor[(1024), float32], %v_param_274: Tensor[(1024), float32], %v_param_275: Tensor[(1024), float32], %v_param_276: Tensor[(1024), float32], %v_param_277: Tensor[(256, 1024, 1, 1), float32], %v_param_278: Tensor[(256), float32], %v_param_279: Tensor[(256), float32], %v_param_280: Tensor[(256), float32], %v_param_281: Tensor[(256), float32], %v_param_282: Tensor[(256), float32], %v_param_283: Tensor[(256, 256, 3, 3), float32], %v_param_284: Tensor[(256), float32], %v_param_285: Tensor[(256), float32], %v_param_286: Tensor[(256), float32], %v_param_287: Tensor[(256), float32], %v_param_288: Tensor[(256), float32], %v_param_289: Tensor[(1024, 256, 1, 1), float32], %v_param_290: Tensor[(1024), float32], %v_param_291: Tensor[(1024), float32], %v_param_292: Tensor[(1024), float32], %v_param_293: Tensor[(1024), float32], %v_param_294: Tensor[(1024), float32], %v_param_295: Tensor[(256, 1024, 1, 1), float32], %v_param_296: Tensor[(256), float32], %v_param_297: Tensor[(256), float32], %v_param_298: Tensor[(256), float32], %v_param_299: Tensor[(256), float32], %v_param_300: Tensor[(256), float32], %v_param_301: Tensor[(256, 256, 3, 3), float32], %v_param_302: Tensor[(256), float32], %v_param_303: Tensor[(256), float32], %v_param_304: Tensor[(256), float32], %v_param_305: Tensor[(256), float32], %v_param_306: Tensor[(256), float32], %v_param_307: Tensor[(1024, 256, 1, 1), float32], %v_param_308: Tensor[(1024), float32], %v_param_309: Tensor[(1024), float32], %v_param_310: Tensor[(1024), float32], %v_param_311: Tensor[(1024), float32], %v_param_312: Tensor[(1024), float32], %v_param_313: Tensor[(256, 1024, 1, 1), float32], %v_param_314: Tensor[(256), float32], %v_param_315: Tensor[(256), float32], %v_param_316: Tensor[(256), float32], %v_param_317: Tensor[(256), float32], %v_param_318: Tensor[(256), float32], %v_param_319: Tensor[(256, 256, 3, 3), float32], %v_param_320: Tensor[(256), float32], %v_param_321: Tensor[(256), float32], %v_param_322: Tensor[(256), float32], %v_param_323: Tensor[(256), float32], %v_param_324: Tensor[(256), float32], %v_param_325: Tensor[(1024, 256, 1, 1), float32], %v_param_326: Tensor[(1024), float32], %v_param_327: Tensor[(1024), float32], %v_param_328: Tensor[(1024), float32], %v_param_329: Tensor[(1024), float32], %v_param_330: Tensor[(1024), float32], %v_param_331: Tensor[(256, 1024, 1, 1), float32], %v_param_332: Tensor[(256), float32], %v_param_333: Tensor[(256), float32], %v_param_334: Tensor[(256), float32], %v_param_335: Tensor[(256), float32], %v_param_336: Tensor[(256), float32], %v_param_337: Tensor[(256, 256, 3, 3), float32], %v_param_338: Tensor[(256), float32], %v_param_339: Tensor[(256), float32], %v_param_340: Tensor[(256), float32], %v_param_341: Tensor[(256), float32], %v_param_342: Tensor[(256), float32], %v_param_343: Tensor[(1024, 256, 1, 1), float32], %v_param_344: Tensor[(1024), float32], %v_param_345: Tensor[(1024), float32], %v_param_346: Tensor[(1024), float32], %v_param_347: Tensor[(1024), float32], %v_param_348: Tensor[(1024), float32], %v_param_349: Tensor[(256, 1024, 1, 1), float32], %v_param_350: Tensor[(256), float32], %v_param_351: Tensor[(256), float32], %v_param_352: Tensor[(256), float32], %v_param_353: Tensor[(256), float32], %v_param_354: Tensor[(256), float32], %v_param_355: Tensor[(256, 256, 3, 3), float32], %v_param_356: Tensor[(256), float32], %v_param_357: Tensor[(256), float32], %v_param_358: Tensor[(256), float32], %v_param_359: Tensor[(256), float32], %v_param_360: Tensor[(256), float32], %v_param_361: Tensor[(1024, 256, 1, 1), float32], %v_param_362: Tensor[(1024), float32], %v_param_363: Tensor[(1024), float32], %v_param_364: Tensor[(1024), float32], %v_param_365: Tensor[(1024), float32], %v_param_366: Tensor[(1024), float32], %v_param_367: Tensor[(256, 1024, 1, 1), float32], %v_param_368: Tensor[(256), float32], %v_param_369: Tensor[(256), float32], %v_param_370: Tensor[(256), float32], %v_param_371: Tensor[(256), float32], %v_param_372: Tensor[(256), float32], %v_param_373: Tensor[(256, 256, 3, 3), float32], %v_param_374: Tensor[(256), float32], %v_param_375: Tensor[(256), float32], %v_param_376: Tensor[(256), float32], %v_param_377: Tensor[(256), float32], %v_param_378: Tensor[(256), float32], %v_param_379: Tensor[(1024, 256, 1, 1), float32], %v_param_380: Tensor[(1024), float32], %v_param_381: Tensor[(1024), float32], %v_param_382: Tensor[(1024), float32], %v_param_383: Tensor[(1024), float32], %v_param_384: Tensor[(1024), float32], %v_param_385: Tensor[(256, 1024, 1, 1), float32], %v_param_386: Tensor[(256), float32], %v_param_387: Tensor[(256), float32], %v_param_388: Tensor[(256), float32], %v_param_389: Tensor[(256), float32], %v_param_390: Tensor[(256), float32], %v_param_391: Tensor[(256, 256, 3, 3), float32], %v_param_392: Tensor[(256), float32], %v_param_393: Tensor[(256), float32], %v_param_394: Tensor[(256), float32], %v_param_395: Tensor[(256), float32], %v_param_396: Tensor[(256), float32], %v_param_397: Tensor[(1024, 256, 1, 1), float32], %v_param_398: Tensor[(1024), float32], %v_param_399: Tensor[(1024), float32], %v_param_400: Tensor[(1024), float32], %v_param_401: Tensor[(1024), float32], %v_param_402: Tensor[(1024), float32], %v_param_403: Tensor[(256, 1024, 1, 1), float32], %v_param_404: Tensor[(256), float32], %v_param_405: Tensor[(256), float32], %v_param_406: Tensor[(256), float32], %v_param_407: Tensor[(256), float32], %v_param_408: Tensor[(256), float32], %v_param_409: Tensor[(256, 256, 3, 3), float32], %v_param_410: Tensor[(256), float32], %v_param_411: Tensor[(256), float32], %v_param_412: Tensor[(256), float32], %v_param_413: Tensor[(256), float32], %v_param_414: Tensor[(256), float32], %v_param_415: Tensor[(1024, 256, 1, 1), float32], %v_param_416: Tensor[(1024), float32], %v_param_417: Tensor[(1024), float32], %v_param_418: Tensor[(1024), float32], %v_param_419: Tensor[(1024), float32], %v_param_420: Tensor[(1024), float32], %v_param_421: Tensor[(256, 1024, 1, 1), float32], %v_param_422: Tensor[(256), float32], %v_param_423: Tensor[(256), float32], %v_param_424: Tensor[(256), float32], %v_param_425: Tensor[(256), float32], %v_param_426: Tensor[(256), float32], %v_param_427: Tensor[(256, 256, 3, 3), float32], %v_param_428: Tensor[(256), float32], %v_param_429: Tensor[(256), float32], %v_param_430: Tensor[(256), float32], %v_param_431: Tensor[(256), float32], %v_param_432: Tensor[(256), float32], %v_param_433: Tensor[(1024, 256, 1, 1), float32], %v_param_434: Tensor[(1024), float32], %v_param_435: Tensor[(1024), float32], %v_param_436: Tensor[(1024), float32], %v_param_437: Tensor[(1024), float32], %v_param_438: Tensor[(1024), float32], %v_param_439: Tensor[(256, 1024, 1, 1), float32], %v_param_440: Tensor[(256), float32], %v_param_441: Tensor[(256), float32], %v_param_442: Tensor[(256), float32], %v_param_443: Tensor[(256), float32], %v_param_444: Tensor[(256), float32], %v_param_445: Tensor[(256, 256, 3, 3), float32], %v_param_446: Tensor[(256), float32], %v_param_447: Tensor[(256), float32], %v_param_448: Tensor[(256), float32], %v_param_449: Tensor[(256), float32], %v_param_450: Tensor[(256), float32], %v_param_451: Tensor[(1024, 256, 1, 1), float32], %v_param_452: Tensor[(1024), float32], %v_param_453: Tensor[(1024), float32], %v_param_454: Tensor[(1024), float32], %v_param_455: Tensor[(1024), float32], %v_param_456: Tensor[(1024), float32], %v_param_457: Tensor[(256, 1024, 1, 1), float32], %v_param_458: Tensor[(256), float32], %v_param_459: Tensor[(256), float32], %v_param_460: Tensor[(256), float32], %v_param_461: Tensor[(256), float32], %v_param_462: Tensor[(256), float32], %v_param_463: Tensor[(256, 256, 3, 3), float32], %v_param_464: Tensor[(256), float32], %v_param_465: Tensor[(256), float32], %v_param_466: Tensor[(256), float32], %v_param_467: Tensor[(256), float32], %v_param_468: Tensor[(256), float32], %v_param_469: Tensor[(1024, 256, 1, 1), float32], %v_param_470: Tensor[(1024), float32], %v_param_471: Tensor[(1024), float32], %v_param_472: Tensor[(1024), float32], %v_param_473: Tensor[(1024), float32], %v_param_474: Tensor[(1024), float32], %v_param_475: Tensor[(256, 1024, 1, 1), float32], %v_param_476: Tensor[(256), float32], %v_param_477: Tensor[(256), float32], %v_param_478: Tensor[(256), float32], %v_param_479: Tensor[(256), float32], %v_param_480: Tensor[(256), float32], %v_param_481: Tensor[(256, 256, 3, 3), float32], %v_param_482: Tensor[(256), float32], %v_param_483: Tensor[(256), float32], %v_param_484: Tensor[(256), float32], %v_param_485: Tensor[(256), float32], %v_param_486: Tensor[(256), float32], %v_param_487: Tensor[(1024, 256, 1, 1), float32], %v_param_488: Tensor[(1024), float32], %v_param_489: Tensor[(1024), float32], %v_param_490: Tensor[(1024), float32], %v_param_491: Tensor[(1024), float32], %v_param_492: Tensor[(1024), float32], %v_param_493: Tensor[(256, 1024, 1, 1), float32], %v_param_494: Tensor[(256), float32], %v_param_495: Tensor[(256), float32], %v_param_496: Tensor[(256), float32], %v_param_497: Tensor[(256), float32], %v_param_498: Tensor[(256), float32], %v_param_499: Tensor[(256, 256, 3, 3), float32], %v_param_500: Tensor[(256), float32], %v_param_501: Tensor[(256), float32], %v_param_502: Tensor[(256), float32], %v_param_503: Tensor[(256), float32], %v_param_504: Tensor[(256), float32], %v_param_505: Tensor[(1024, 256, 1, 1), float32], %v_param_506: Tensor[(1024), float32], %v_param_507: Tensor[(1024), float32], %v_param_508: Tensor[(1024), float32], %v_param_509: Tensor[(1024), float32], %v_param_510: Tensor[(1024), float32], %v_param_511: Tensor[(256, 1024, 1, 1), float32], %v_param_512: Tensor[(256), float32], %v_param_513: Tensor[(256), float32], %v_param_514: Tensor[(256), float32], %v_param_515: Tensor[(256), float32], %v_param_516: Tensor[(256), float32], %v_param_517: Tensor[(256, 256, 3, 3), float32], %v_param_518: Tensor[(256), float32], %v_param_519: Tensor[(256), float32], %v_param_520: Tensor[(256), float32], %v_param_521: Tensor[(256), float32], %v_param_522: Tensor[(256), float32], %v_param_523: Tensor[(1024, 256, 1, 1), float32], %v_param_524: Tensor[(1024), float32], %v_param_525: Tensor[(1024), float32], %v_param_526: Tensor[(1024), float32], %v_param_527: Tensor[(1024), float32], %v_param_528: Tensor[(1024), float32], %v_param_529: Tensor[(256, 1024, 1, 1), float32], %v_param_530: Tensor[(256), float32], %v_param_531: Tensor[(256), float32], %v_param_532: Tensor[(256), float32], %v_param_533: Tensor[(256), float32], %v_param_534: Tensor[(256), float32], %v_param_535: Tensor[(256, 256, 3, 3), float32], %v_param_536: Tensor[(256), float32], %v_param_537: Tensor[(256), float32], %v_param_538: Tensor[(256), float32], %v_param_539: Tensor[(256), float32], %v_param_540: Tensor[(256), float32], %v_param_541: Tensor[(1024, 256, 1, 1), float32], %v_param_542: Tensor[(1024), float32], %v_param_543: Tensor[(1024), float32], %v_param_544: Tensor[(1024), float32], %v_param_545: Tensor[(1024), float32], %v_param_546: Tensor[(1024), float32], %v_param_547: Tensor[(256, 1024, 1, 1), float32], %v_param_548: Tensor[(256), float32], %v_param_549: Tensor[(256), float32], %v_param_550: Tensor[(256), float32], %v_param_551: Tensor[(256), float32], %v_param_552: Tensor[(256), float32], %v_param_553: Tensor[(256, 256, 3, 3), float32], %v_param_554: Tensor[(256), float32], %v_param_555: Tensor[(256), float32], %v_param_556: Tensor[(256), float32], %v_param_557: Tensor[(256), float32], %v_param_558: Tensor[(256), float32], %v_param_559: Tensor[(1024, 256, 1, 1), float32], %v_param_560: Tensor[(1024), float32], %v_param_561: Tensor[(1024), float32], %v_param_562: Tensor[(1024), float32], %v_param_563: Tensor[(1024), float32], %v_param_564: Tensor[(1024), float32], %v_param_565: Tensor[(256, 1024, 1, 1), float32], %v_param_566: Tensor[(256), float32], %v_param_567: Tensor[(256), float32], %v_param_568: Tensor[(256), float32], %v_param_569: Tensor[(256), float32], %v_param_570: Tensor[(256), float32], %v_param_571: Tensor[(256, 256, 3, 3), float32], %v_param_572: Tensor[(256), float32], %v_param_573: Tensor[(256), float32], %v_param_574: Tensor[(256), float32], %v_param_575: Tensor[(256), float32], %v_param_576: Tensor[(256), float32], %v_param_577: Tensor[(1024, 256, 1, 1), float32], %v_param_578: Tensor[(1024), float32], %v_param_579: Tensor[(1024), float32], %v_param_580: Tensor[(1024), float32], %v_param_581: Tensor[(1024), float32], %v_param_582: Tensor[(1024), float32], %v_param_583: Tensor[(256, 1024, 1, 1), float32], %v_param_584: Tensor[(256), float32], %v_param_585: Tensor[(256), float32], %v_param_586: Tensor[(256), float32], %v_param_587: Tensor[(256), float32], %v_param_588: Tensor[(256), float32], %v_param_589: Tensor[(256, 256, 3, 3), float32], %v_param_590: Tensor[(256), float32], %v_param_591: Tensor[(256), float32], %v_param_592: Tensor[(256), float32], %v_param_593: Tensor[(256), float32], %v_param_594: Tensor[(256), float32], %v_param_595: Tensor[(1024, 256, 1, 1), float32], %v_param_596: Tensor[(1024), float32], %v_param_597: Tensor[(1024), float32], %v_param_598: Tensor[(1024), float32], %v_param_599: Tensor[(1024), float32], %v_param_600: Tensor[(1024), float32], %v_param_601: Tensor[(256, 1024, 1, 1), float32], %v_param_602: Tensor[(256), float32], %v_param_603: Tensor[(256), float32], %v_param_604: Tensor[(256), float32], %v_param_605: Tensor[(256), float32], %v_param_606: Tensor[(256), float32], %v_param_607: Tensor[(256, 256, 3, 3), float32], %v_param_608: Tensor[(256), float32], %v_param_609: Tensor[(256), float32], %v_param_610: Tensor[(256), float32], %v_param_611: Tensor[(256), float32], %v_param_612: Tensor[(256), float32], %v_param_613: Tensor[(1024, 256, 1, 1), float32], %v_param_614: Tensor[(1024), float32], %v_param_615: Tensor[(1024), float32], %v_param_616: Tensor[(1024), float32], %v_param_617: Tensor[(1024), float32], %v_param_618: Tensor[(1024), float32], %v_param_619: Tensor[(256, 1024, 1, 1), float32], %v_param_620: Tensor[(256), float32], %v_param_621: Tensor[(256), float32], %v_param_622: Tensor[(256), float32], %v_param_623: Tensor[(256), float32], %v_param_624: Tensor[(256), float32], %v_param_625: Tensor[(256, 256, 3, 3), float32], %v_param_626: Tensor[(256), float32], %v_param_627: Tensor[(256), float32], %v_param_628: Tensor[(256), float32], %v_param_629: Tensor[(256), float32], %v_param_630: Tensor[(256), float32], %v_param_631: Tensor[(1024, 256, 1, 1), float32], %v_param_632: Tensor[(1024), float32], %v_param_633: Tensor[(1024), float32], %v_param_634: Tensor[(1024), float32], %v_param_635: Tensor[(1024), float32], %v_param_636: Tensor[(1024), float32], %v_param_637: Tensor[(256, 1024, 1, 1), float32], %v_param_638: Tensor[(256), float32], %v_param_639: Tensor[(256), float32], %v_param_640: Tensor[(256), float32], %v_param_641: Tensor[(256), float32], %v_param_642: Tensor[(256), float32], %v_param_643: Tensor[(256, 256, 3, 3), float32], %v_param_644: Tensor[(256), float32], %v_param_645: Tensor[(256), float32], %v_param_646: Tensor[(256), float32], %v_param_647: Tensor[(256), float32], %v_param_648: Tensor[(256), float32], %v_param_649: Tensor[(1024, 256, 1, 1), float32], %v_param_650: Tensor[(1024), float32], %v_param_651: Tensor[(1024), float32], %v_param_652: Tensor[(1024), float32], %v_param_653: Tensor[(1024), float32], %v_param_654: Tensor[(1024), float32], %v_param_655: Tensor[(256, 1024, 1, 1), float32], %v_param_656: Tensor[(256), float32], %v_param_657: Tensor[(256), float32], %v_param_658: Tensor[(256), float32], %v_param_659: Tensor[(256), float32], %v_param_660: Tensor[(256), float32], %v_param_661: Tensor[(256, 256, 3, 3), float32], %v_param_662: Tensor[(256), float32], %v_param_663: Tensor[(256), float32], %v_param_664: Tensor[(256), float32], %v_param_665: Tensor[(256), float32], %v_param_666: Tensor[(256), float32], %v_param_667: Tensor[(1024, 256, 1, 1), float32], %v_param_668: Tensor[(1024), float32], %v_param_669: Tensor[(1024), float32], %v_param_670: Tensor[(1024), float32], %v_param_671: Tensor[(1024), float32], %v_param_672: Tensor[(1024), float32], %v_param_673: Tensor[(256, 1024, 1, 1), float32], %v_param_674: Tensor[(256), float32], %v_param_675: Tensor[(256), float32], %v_param_676: Tensor[(256), float32], %v_param_677: Tensor[(256), float32], %v_param_678: Tensor[(256), float32], %v_param_679: Tensor[(256, 256, 3, 3), float32], %v_param_680: Tensor[(256), float32], %v_param_681: Tensor[(256), float32], %v_param_682: Tensor[(256), float32], %v_param_683: Tensor[(256), float32], %v_param_684: Tensor[(256), float32], %v_param_685: Tensor[(1024, 256, 1, 1), float32], %v_param_686: Tensor[(1024), float32], %v_param_687: Tensor[(1024), float32], %v_param_688: Tensor[(1024), float32], %v_param_689: Tensor[(1024), float32], %v_param_690: Tensor[(1024), float32], %v_param_691: Tensor[(256, 1024, 1, 1), float32], %v_param_692: Tensor[(256), float32], %v_param_693: Tensor[(256), float32], %v_param_694: Tensor[(256), float32], %v_param_695: Tensor[(256), float32], %v_param_696: Tensor[(256), float32], %v_param_697: Tensor[(256, 256, 3, 3), float32], %v_param_698: Tensor[(256), float32], %v_param_699: Tensor[(256), float32], %v_param_700: Tensor[(256), float32], %v_param_701: Tensor[(256), float32], %v_param_702: Tensor[(256), float32], %v_param_703: Tensor[(1024, 256, 1, 1), float32], %v_param_704: Tensor[(1024), float32], %v_param_705: Tensor[(1024), float32], %v_param_706: Tensor[(1024), float32], %v_param_707: Tensor[(1024), float32], %v_param_708: Tensor[(1024), float32], %v_param_709: Tensor[(256, 1024, 1, 1), float32], %v_param_710: Tensor[(256), float32], %v_param_711: Tensor[(256), float32], %v_param_712: Tensor[(256), float32], %v_param_713: Tensor[(256), float32], %v_param_714: Tensor[(256), float32], %v_param_715: Tensor[(256, 256, 3, 3), float32], %v_param_716: Tensor[(256), float32], %v_param_717: Tensor[(256), float32], %v_param_718: Tensor[(256), float32], %v_param_719: Tensor[(256), float32], %v_param_720: Tensor[(256), float32], %v_param_721: Tensor[(1024, 256, 1, 1), float32], %v_param_722: Tensor[(1024), float32], %v_param_723: Tensor[(1024), float32], %v_param_724: Tensor[(1024), float32], %v_param_725: Tensor[(1024), float32], %v_param_726: Tensor[(1024), float32], %v_param_727: Tensor[(256, 1024, 1, 1), float32], %v_param_728: Tensor[(256), float32], %v_param_729: Tensor[(256), float32], %v_param_730: Tensor[(256), float32], %v_param_731: Tensor[(256), float32], %v_param_732: Tensor[(256), float32], %v_param_733: Tensor[(256, 256, 3, 3), float32], %v_param_734: Tensor[(256), float32], %v_param_735: Tensor[(256), float32], %v_param_736: Tensor[(256), float32], %v_param_737: Tensor[(256), float32], %v_param_738: Tensor[(256), float32], %v_param_739: Tensor[(1024, 256, 1, 1), float32], %v_param_740: Tensor[(1024), float32], %v_param_741: Tensor[(1024), float32], %v_param_742: Tensor[(1024), float32], %v_param_743: Tensor[(1024), float32], %v_param_744: Tensor[(1024), float32], %v_param_745: Tensor[(256, 1024, 1, 1), float32], %v_param_746: Tensor[(256), float32], %v_param_747: Tensor[(256), float32], %v_param_748: Tensor[(256), float32], %v_param_749: Tensor[(256), float32], %v_param_750: Tensor[(256), float32], %v_param_751: Tensor[(256, 256, 3, 3), float32], %v_param_752: Tensor[(256), float32], %v_param_753: Tensor[(256), float32], %v_param_754: Tensor[(256), float32], %v_param_755: Tensor[(256), float32], %v_param_756: Tensor[(256), float32], %v_param_757: Tensor[(1024, 256, 1, 1), float32], %v_param_758: Tensor[(1024), float32], %v_param_759: Tensor[(1024), float32], %v_param_760: Tensor[(1024), float32], %v_param_761: Tensor[(1024), float32], %v_param_762: Tensor[(1024), float32], %v_param_763: Tensor[(256, 1024, 1, 1), float32], %v_param_764: Tensor[(256), float32], %v_param_765: Tensor[(256), float32], %v_param_766: Tensor[(256), float32], %v_param_767: Tensor[(256), float32], %v_param_768: Tensor[(256), float32], %v_param_769: Tensor[(256, 256, 3, 3), float32], %v_param_770: Tensor[(256), float32], %v_param_771: Tensor[(256), float32], %v_param_772: Tensor[(256), float32], %v_param_773: Tensor[(256), float32], %v_param_774: Tensor[(256), float32], %v_param_775: Tensor[(1024, 256, 1, 1), float32], %v_param_776: Tensor[(1024), float32], %v_param_777: Tensor[(1024), float32], %v_param_778: Tensor[(1024), float32], %v_param_779: Tensor[(1024), float32], %v_param_780: Tensor[(1024), float32], %v_param_781: Tensor[(256, 1024, 1, 1), float32], %v_param_782: Tensor[(256), float32], %v_param_783: Tensor[(256), float32], %v_param_784: Tensor[(256), float32], %v_param_785: Tensor[(256), float32], %v_param_786: Tensor[(256), float32], %v_param_787: Tensor[(256, 256, 3, 3), float32], %v_param_788: Tensor[(256), float32], %v_param_789: Tensor[(256), float32], %v_param_790: Tensor[(256), float32], %v_param_791: Tensor[(256), float32], %v_param_792: Tensor[(256), float32], %v_param_793: Tensor[(1024, 256, 1, 1), float32], %v_param_794: Tensor[(1024), float32], %v_param_795: Tensor[(1024), float32], %v_param_796: Tensor[(1024), float32], %v_param_797: Tensor[(1024), float32], %v_param_798: Tensor[(1024), float32], %v_param_799: Tensor[(256, 1024, 1, 1), float32], %v_param_800: Tensor[(256), float32], %v_param_801: Tensor[(256), float32], %v_param_802: Tensor[(256), float32], %v_param_803: Tensor[(256), float32], %v_param_804: Tensor[(256), float32], %v_param_805: Tensor[(256, 256, 3, 3), float32], %v_param_806: Tensor[(256), float32], %v_param_807: Tensor[(256), float32], %v_param_808: Tensor[(256), float32], %v_param_809: Tensor[(256), float32], %v_param_810: Tensor[(256), float32], %v_param_811: Tensor[(1024, 256, 1, 1), float32], %v_param_812: Tensor[(1024), float32], %v_param_813: Tensor[(1024), float32], %v_param_814: Tensor[(1024), float32], %v_param_815: Tensor[(1024), float32], %v_param_816: Tensor[(1024), float32], %v_param_817: Tensor[(256, 1024, 1, 1), float32], %v_param_818: Tensor[(256), float32], %v_param_819: Tensor[(256), float32], %v_param_820: Tensor[(256), float32], %v_param_821: Tensor[(256), float32], %v_param_822: Tensor[(256), float32], %v_param_823: Tensor[(256, 256, 3, 3), float32], %v_param_824: Tensor[(256), float32], %v_param_825: Tensor[(256), float32], %v_param_826: Tensor[(256), float32], %v_param_827: Tensor[(256), float32], %v_param_828: Tensor[(256), float32], %v_param_829: Tensor[(1024, 256, 1, 1), float32], %v_param_830: Tensor[(1024), float32], %v_param_831: Tensor[(1024), float32], %v_param_832: Tensor[(1024), float32], %v_param_833: Tensor[(1024), float32], %v_param_834: Tensor[(1024), float32], %v_param_835: Tensor[(256, 1024, 1, 1), float32], %v_param_836: Tensor[(256), float32], %v_param_837: Tensor[(256), float32], %v_param_838: Tensor[(256), float32], %v_param_839: Tensor[(256), float32], %v_param_840: Tensor[(256), float32], %v_param_841: Tensor[(256, 256, 3, 3), float32], %v_param_842: Tensor[(256), float32], %v_param_843: Tensor[(256), float32], %v_param_844: Tensor[(256), float32], %v_param_845: Tensor[(256), float32], %v_param_846: Tensor[(256), float32], %v_param_847: Tensor[(1024, 256, 1, 1), float32], %v_param_848: Tensor[(1024), float32], %v_param_849: Tensor[(1024), float32], %v_param_850: Tensor[(1024), float32], %v_param_851: Tensor[(1024), float32], %v_param_852: Tensor[(1024), float32], %v_param_853: Tensor[(256, 1024, 1, 1), float32], %v_param_854: Tensor[(256), float32], %v_param_855: Tensor[(256), float32], %v_param_856: Tensor[(256), float32], %v_param_857: Tensor[(256), float32], %v_param_858: Tensor[(256), float32], %v_param_859: Tensor[(256, 256, 3, 3), float32], %v_param_860: Tensor[(256), float32], %v_param_861: Tensor[(256), float32], %v_param_862: Tensor[(256), float32], %v_param_863: Tensor[(256), float32], %v_param_864: Tensor[(256), float32], %v_param_865: Tensor[(1024, 256, 1, 1), float32], %v_param_866: Tensor[(1024), float32], %v_param_867: Tensor[(1024), float32], %v_param_868: Tensor[(1024), float32], %v_param_869: Tensor[(1024), float32], %v_param_870: Tensor[(1024), float32], %v_param_883: Tensor[(2048, 1024, 1, 1), float32], %v_param_884: Tensor[(2048), float32], %v_param_887: Tensor[(2048), float32], %v_param_888: Tensor[(2048), float32], %v_param_889: Tensor[(2048), float32], %v_param_890: Tensor[(2048), float32], %v_param_871: Tensor[(512, 1024, 1, 1), float32], %v_param_872: Tensor[(512), float32], %v_param_873: Tensor[(512), float32], %v_param_874: Tensor[(512), float32], %v_param_875: Tensor[(512), float32], %v_param_876: Tensor[(512), float32], %v_param_877: Tensor[(512, 512, 3, 3), float32], %v_param_878: Tensor[(512), float32], %v_param_879: Tensor[(512), float32], %v_param_880: Tensor[(512), float32], %v_param_881: Tensor[(512), float32], %v_param_882: Tensor[(512), float32], %v_param_885: Tensor[(2048, 512, 1, 1), float32], %v_param_886: Tensor[(2048), float32], %v_param_891: Tensor[(2048), float32], %v_param_892: Tensor[(2048), float32], %v_param_893: Tensor[(2048), float32], %v_param_894: Tensor[(2048), float32], %v_param_895: Tensor[(512, 2048, 1, 1), float32], %v_param_896: Tensor[(512), float32], %v_param_897: Tensor[(512), float32], %v_param_898: Tensor[(512), float32], %v_param_899: Tensor[(512), float32], %v_param_900: Tensor[(512), float32], %v_param_901: Tensor[(512, 512, 3, 3), float32], %v_param_902: Tensor[(512), float32], %v_param_903: Tensor[(512), float32], %v_param_904: Tensor[(512), float32], %v_param_905: Tensor[(512), float32], %v_param_906: Tensor[(512), float32], %v_param_907: Tensor[(2048, 512, 1, 1), float32], %v_param_908: Tensor[(2048), float32], %v_param_909: Tensor[(2048), float32], %v_param_910: Tensor[(2048), float32], %v_param_911: Tensor[(2048), float32], %v_param_912: Tensor[(2048), float32], %v_param_913: Tensor[(512, 2048, 1, 1), float32], %v_param_914: Tensor[(512), float32], %v_param_915: Tensor[(512), float32], %v_param_916: Tensor[(512), float32], %v_param_917: Tensor[(512), float32], %v_param_918: Tensor[(512), float32], %v_param_919: Tensor[(512, 512, 3, 3), float32], %v_param_920: Tensor[(512), float32], %v_param_921: Tensor[(512), float32], %v_param_922: Tensor[(512), float32], %v_param_923: Tensor[(512), float32], %v_param_924: Tensor[(512), float32], %v_param_925: Tensor[(2048, 512, 1, 1), float32], %v_param_926: Tensor[(2048), float32], %v_param_927: Tensor[(2048), float32], %v_param_928: Tensor[(2048), float32], %v_param_929: Tensor[(2048), float32], %v_param_930: Tensor[(2048), float32], %v_param_931: Tensor[(1000, 2048), float32], %v_param_932: Tensor[(1000), float32]) {\n",
      "  %0 = nn.pad(%input_1, 0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);\n",
      "  %1 = nn.conv2d(%0, %v_param_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7]);\n",
      "  %2 = nn.bias_add(%1, %v_param_2);\n",
      "  %3 = nn.batch_norm(%2, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=1.001e-05f);\n",
      "  %4 = %3.0;\n",
      "  %5 = nn.relu(%4);\n",
      "  %6 = nn.pad(%5, 0, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]);\n",
      "  %8 = nn.conv2d(%7, %v_param_19, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %9 = nn.bias_add(%8, %v_param_20);\n",
      "  %10 = nn.batch_norm(%9, %v_param_23, %v_param_24, %v_param_25, %v_param_26, epsilon=1.001e-05f);\n",
      "  %11 = nn.conv2d(%7, %v_param_7, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %12 = nn.bias_add(%11, %v_param_8);\n",
      "  %13 = nn.batch_norm(%12, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=1.001e-05f);\n",
      "  %14 = %13.0;\n",
      "  %15 = nn.relu(%14);\n",
      "  %16 = nn.conv2d(%15, %v_param_13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %17 = nn.bias_add(%16, %v_param_14);\n",
      "  %18 = nn.batch_norm(%17, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=1.001e-05f);\n",
      "  %19 = %18.0;\n",
      "  %20 = nn.relu(%19);\n",
      "  %21 = nn.conv2d(%20, %v_param_21, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %22 = nn.bias_add(%21, %v_param_22);\n",
      "  %23 = nn.batch_norm(%22, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=1.001e-05f);\n",
      "  %24 = %10.0;\n",
      "  %25 = %23.0;\n",
      "  %26 = add(%24, %25);\n",
      "  %27 = nn.relu(%26);\n",
      "  %28 = nn.conv2d(%27, %v_param_31, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %29 = nn.bias_add(%28, %v_param_32);\n",
      "  %30 = nn.batch_norm(%29, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=1.001e-05f);\n",
      "  %31 = %30.0;\n",
      "  %32 = nn.relu(%31);\n",
      "  %33 = nn.conv2d(%32, %v_param_37, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %34 = nn.bias_add(%33, %v_param_38);\n",
      "  %35 = nn.batch_norm(%34, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=1.001e-05f);\n",
      "  %36 = %35.0;\n",
      "  %37 = nn.relu(%36);\n",
      "  %38 = nn.conv2d(%37, %v_param_43, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %39 = nn.bias_add(%38, %v_param_44);\n",
      "  %40 = nn.batch_norm(%39, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=1.001e-05f);\n",
      "  %41 = %40.0;\n",
      "  %42 = add(%27, %41);\n",
      "  %43 = nn.relu(%42);\n",
      "  %44 = nn.conv2d(%43, %v_param_49, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);\n",
      "  %45 = nn.bias_add(%44, %v_param_50);\n",
      "  %46 = nn.batch_norm(%45, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=1.001e-05f);\n",
      "  %47 = %46.0;\n",
      "  %48 = nn.relu(%47);\n",
      "  %49 = nn.conv2d(%48, %v_param_55, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);\n",
      "  %50 = nn.bias_add(%49, %v_param_56);\n",
      "  %51 = nn.batch_norm(%50, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=1.001e-05f);\n",
      "  %52 = %51.0;\n",
      "  %53 = nn.relu(%52);\n",
      "  %54 = nn.conv2d(%53, %v_param_61, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %55 = nn.bias_add(%54, %v_param_62);\n",
      "  %56 = nn.batch_norm(%55, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=1.001e-05f);\n",
      "  %57 = %56.0;\n",
      "  %58 = add(%43, %57);\n",
      "  %59 = nn.relu(%58);\n",
      "  %60 = nn.conv2d(%59, %v_param_79, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %61 = nn.bias_add(%60, %v_param_80);\n",
      "  %62 = nn.batch_norm(%61, %v_param_83, %v_param_84, %v_param_85, %v_param_86, epsilon=1.001e-05f);\n",
      "  %63 = nn.conv2d(%59, %v_param_67, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %64 = nn.bias_add(%63, %v_param_68);\n",
      "  %65 = nn.batch_norm(%64, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=1.001e-05f);\n",
      "  %66 = %65.0;\n",
      "  %67 = nn.relu(%66);\n",
      "  %68 = nn.conv2d(%67, %v_param_73, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %69 = nn.bias_add(%68, %v_param_74);\n",
      "  %70 = nn.batch_norm(%69, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=1.001e-05f);\n",
      "  %71 = %70.0;\n",
      "  %72 = nn.relu(%71);\n",
      "  %73 = nn.conv2d(%72, %v_param_81, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %74 = nn.bias_add(%73, %v_param_82);\n",
      "  %75 = nn.batch_norm(%74, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=1.001e-05f);\n",
      "  %76 = %62.0;\n",
      "  %77 = %75.0;\n",
      "  %78 = add(%76, %77);\n",
      "  %79 = nn.relu(%78);\n",
      "  %80 = nn.conv2d(%79, %v_param_91, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %81 = nn.bias_add(%80, %v_param_92);\n",
      "  %82 = nn.batch_norm(%81, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=1.001e-05f);\n",
      "  %83 = %82.0;\n",
      "  %84 = nn.relu(%83);\n",
      "  %85 = nn.conv2d(%84, %v_param_97, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %86 = nn.bias_add(%85, %v_param_98);\n",
      "  %87 = nn.batch_norm(%86, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=1.001e-05f);\n",
      "  %88 = %87.0;\n",
      "  %89 = nn.relu(%88);\n",
      "  %90 = nn.conv2d(%89, %v_param_103, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %91 = nn.bias_add(%90, %v_param_104);\n",
      "  %92 = nn.batch_norm(%91, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=1.001e-05f);\n",
      "  %93 = %92.0;\n",
      "  %94 = add(%79, %93);\n",
      "  %95 = nn.relu(%94);\n",
      "  %96 = nn.conv2d(%95, %v_param_109, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %97 = nn.bias_add(%96, %v_param_110);\n",
      "  %98 = nn.batch_norm(%97, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=1.001e-05f);\n",
      "  %99 = %98.0;\n",
      "  %100 = nn.relu(%99);\n",
      "  %101 = nn.conv2d(%100, %v_param_115, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %102 = nn.bias_add(%101, %v_param_116);\n",
      "  %103 = nn.batch_norm(%102, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=1.001e-05f);\n",
      "  %104 = %103.0;\n",
      "  %105 = nn.relu(%104);\n",
      "  %106 = nn.conv2d(%105, %v_param_121, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %107 = nn.bias_add(%106, %v_param_122);\n",
      "  %108 = nn.batch_norm(%107, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=1.001e-05f);\n",
      "  %109 = %108.0;\n",
      "  %110 = add(%95, %109);\n",
      "  %111 = nn.relu(%110);\n",
      "  %112 = nn.conv2d(%111, %v_param_127, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %113 = nn.bias_add(%112, %v_param_128);\n",
      "  %114 = nn.batch_norm(%113, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=1.001e-05f);\n",
      "  %115 = %114.0;\n",
      "  %116 = nn.relu(%115);\n",
      "  %117 = nn.conv2d(%116, %v_param_133, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %118 = nn.bias_add(%117, %v_param_134);\n",
      "  %119 = nn.batch_norm(%118, %v_param_135, %v_param_136, %v_param_137, %v_param_138, epsilon=1.001e-05f);\n",
      "  %120 = %119.0;\n",
      "  %121 = nn.relu(%120);\n",
      "  %122 = nn.conv2d(%121, %v_param_139, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %123 = nn.bias_add(%122, %v_param_140);\n",
      "  %124 = nn.batch_norm(%123, %v_param_141, %v_param_142, %v_param_143, %v_param_144, epsilon=1.001e-05f);\n",
      "  %125 = %124.0;\n",
      "  %126 = add(%111, %125);\n",
      "  %127 = nn.relu(%126);\n",
      "  %128 = nn.conv2d(%127, %v_param_145, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %129 = nn.bias_add(%128, %v_param_146);\n",
      "  %130 = nn.batch_norm(%129, %v_param_147, %v_param_148, %v_param_149, %v_param_150, epsilon=1.001e-05f);\n",
      "  %131 = %130.0;\n",
      "  %132 = nn.relu(%131);\n",
      "  %133 = nn.conv2d(%132, %v_param_151, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %134 = nn.bias_add(%133, %v_param_152);\n",
      "  %135 = nn.batch_norm(%134, %v_param_153, %v_param_154, %v_param_155, %v_param_156, epsilon=1.001e-05f);\n",
      "  %136 = %135.0;\n",
      "  %137 = nn.relu(%136);\n",
      "  %138 = nn.conv2d(%137, %v_param_157, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %139 = nn.bias_add(%138, %v_param_158);\n",
      "  %140 = nn.batch_norm(%139, %v_param_159, %v_param_160, %v_param_161, %v_param_162, epsilon=1.001e-05f);\n",
      "  %141 = %140.0;\n",
      "  %142 = add(%127, %141);\n",
      "  %143 = nn.relu(%142);\n",
      "  %144 = nn.conv2d(%143, %v_param_163, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %145 = nn.bias_add(%144, %v_param_164);\n",
      "  %146 = nn.batch_norm(%145, %v_param_165, %v_param_166, %v_param_167, %v_param_168, epsilon=1.001e-05f);\n",
      "  %147 = %146.0;\n",
      "  %148 = nn.relu(%147);\n",
      "  %149 = nn.conv2d(%148, %v_param_169, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %150 = nn.bias_add(%149, %v_param_170);\n",
      "  %151 = nn.batch_norm(%150, %v_param_171, %v_param_172, %v_param_173, %v_param_174, epsilon=1.001e-05f);\n",
      "  %152 = %151.0;\n",
      "  %153 = nn.relu(%152);\n",
      "  %154 = nn.conv2d(%153, %v_param_175, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %155 = nn.bias_add(%154, %v_param_176);\n",
      "  %156 = nn.batch_norm(%155, %v_param_177, %v_param_178, %v_param_179, %v_param_180, epsilon=1.001e-05f);\n",
      "  %157 = %156.0;\n",
      "  %158 = add(%143, %157);\n",
      "  %159 = nn.relu(%158);\n",
      "  %160 = nn.conv2d(%159, %v_param_181, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %161 = nn.bias_add(%160, %v_param_182);\n",
      "  %162 = nn.batch_norm(%161, %v_param_183, %v_param_184, %v_param_185, %v_param_186, epsilon=1.001e-05f);\n",
      "  %163 = %162.0;\n",
      "  %164 = nn.relu(%163);\n",
      "  %165 = nn.conv2d(%164, %v_param_187, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %166 = nn.bias_add(%165, %v_param_188);\n",
      "  %167 = nn.batch_norm(%166, %v_param_189, %v_param_190, %v_param_191, %v_param_192, epsilon=1.001e-05f);\n",
      "  %168 = %167.0;\n",
      "  %169 = nn.relu(%168);\n",
      "  %170 = nn.conv2d(%169, %v_param_193, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %171 = nn.bias_add(%170, %v_param_194);\n",
      "  %172 = nn.batch_norm(%171, %v_param_195, %v_param_196, %v_param_197, %v_param_198, epsilon=1.001e-05f);\n",
      "  %173 = %172.0;\n",
      "  %174 = add(%159, %173);\n",
      "  %175 = nn.relu(%174);\n",
      "  %176 = nn.conv2d(%175, %v_param_199, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);\n",
      "  %177 = nn.bias_add(%176, %v_param_200);\n",
      "  %178 = nn.batch_norm(%177, %v_param_201, %v_param_202, %v_param_203, %v_param_204, epsilon=1.001e-05f);\n",
      "  %179 = %178.0;\n",
      "  %180 = nn.relu(%179);\n",
      "  %181 = nn.conv2d(%180, %v_param_205, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);\n",
      "  %182 = nn.bias_add(%181, %v_param_206);\n",
      "  %183 = nn.batch_norm(%182, %v_param_207, %v_param_208, %v_param_209, %v_param_210, epsilon=1.001e-05f);\n",
      "  %184 = %183.0;\n",
      "  %185 = nn.relu(%184);\n",
      "  %186 = nn.conv2d(%185, %v_param_211, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %187 = nn.bias_add(%186, %v_param_212);\n",
      "  %188 = nn.batch_norm(%187, %v_param_213, %v_param_214, %v_param_215, %v_param_216, epsilon=1.001e-05f);\n",
      "  %189 = %188.0;\n",
      "  %190 = add(%175, %189);\n",
      "  %191 = nn.relu(%190);\n",
      "  %192 = nn.conv2d(%191, %v_param_229, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %193 = nn.bias_add(%192, %v_param_230);\n",
      "  %194 = nn.batch_norm(%193, %v_param_233, %v_param_234, %v_param_235, %v_param_236, epsilon=1.001e-05f);\n",
      "  %195 = nn.conv2d(%191, %v_param_217, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %196 = nn.bias_add(%195, %v_param_218);\n",
      "  %197 = nn.batch_norm(%196, %v_param_219, %v_param_220, %v_param_221, %v_param_222, epsilon=1.001e-05f);\n",
      "  %198 = %197.0;\n",
      "  %199 = nn.relu(%198);\n",
      "  %200 = nn.conv2d(%199, %v_param_223, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %201 = nn.bias_add(%200, %v_param_224);\n",
      "  %202 = nn.batch_norm(%201, %v_param_225, %v_param_226, %v_param_227, %v_param_228, epsilon=1.001e-05f);\n",
      "  %203 = %202.0;\n",
      "  %204 = nn.relu(%203);\n",
      "  %205 = nn.conv2d(%204, %v_param_231, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %206 = nn.bias_add(%205, %v_param_232);\n",
      "  %207 = nn.batch_norm(%206, %v_param_237, %v_param_238, %v_param_239, %v_param_240, epsilon=1.001e-05f);\n",
      "  %208 = %194.0;\n",
      "  %209 = %207.0;\n",
      "  %210 = add(%208, %209);\n",
      "  %211 = nn.relu(%210);\n",
      "  %212 = nn.conv2d(%211, %v_param_241, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %213 = nn.bias_add(%212, %v_param_242);\n",
      "  %214 = nn.batch_norm(%213, %v_param_243, %v_param_244, %v_param_245, %v_param_246, epsilon=1.001e-05f);\n",
      "  %215 = %214.0;\n",
      "  %216 = nn.relu(%215);\n",
      "  %217 = nn.conv2d(%216, %v_param_247, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %218 = nn.bias_add(%217, %v_param_248);\n",
      "  %219 = nn.batch_norm(%218, %v_param_249, %v_param_250, %v_param_251, %v_param_252, epsilon=1.001e-05f);\n",
      "  %220 = %219.0;\n",
      "  %221 = nn.relu(%220);\n",
      "  %222 = nn.conv2d(%221, %v_param_253, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %223 = nn.bias_add(%222, %v_param_254);\n",
      "  %224 = nn.batch_norm(%223, %v_param_255, %v_param_256, %v_param_257, %v_param_258, epsilon=1.001e-05f);\n",
      "  %225 = %224.0;\n",
      "  %226 = add(%211, %225);\n",
      "  %227 = nn.relu(%226);\n",
      "  %228 = nn.conv2d(%227, %v_param_259, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %229 = nn.bias_add(%228, %v_param_260);\n",
      "  %230 = nn.batch_norm(%229, %v_param_261, %v_param_262, %v_param_263, %v_param_264, epsilon=1.001e-05f);\n",
      "  %231 = %230.0;\n",
      "  %232 = nn.relu(%231);\n",
      "  %233 = nn.conv2d(%232, %v_param_265, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %234 = nn.bias_add(%233, %v_param_266);\n",
      "  %235 = nn.batch_norm(%234, %v_param_267, %v_param_268, %v_param_269, %v_param_270, epsilon=1.001e-05f);\n",
      "  %236 = %235.0;\n",
      "  %237 = nn.relu(%236);\n",
      "  %238 = nn.conv2d(%237, %v_param_271, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %239 = nn.bias_add(%238, %v_param_272);\n",
      "  %240 = nn.batch_norm(%239, %v_param_273, %v_param_274, %v_param_275, %v_param_276, epsilon=1.001e-05f);\n",
      "  %241 = %240.0;\n",
      "  %242 = add(%227, %241);\n",
      "  %243 = nn.relu(%242);\n",
      "  %244 = nn.conv2d(%243, %v_param_277, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %245 = nn.bias_add(%244, %v_param_278);\n",
      "  %246 = nn.batch_norm(%245, %v_param_279, %v_param_280, %v_param_281, %v_param_282, epsilon=1.001e-05f);\n",
      "  %247 = %246.0;\n",
      "  %248 = nn.relu(%247);\n",
      "  %249 = nn.conv2d(%248, %v_param_283, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %250 = nn.bias_add(%249, %v_param_284);\n",
      "  %251 = nn.batch_norm(%250, %v_param_285, %v_param_286, %v_param_287, %v_param_288, epsilon=1.001e-05f);\n",
      "  %252 = %251.0;\n",
      "  %253 = nn.relu(%252);\n",
      "  %254 = nn.conv2d(%253, %v_param_289, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %255 = nn.bias_add(%254, %v_param_290);\n",
      "  %256 = nn.batch_norm(%255, %v_param_291, %v_param_292, %v_param_293, %v_param_294, epsilon=1.001e-05f);\n",
      "  %257 = %256.0;\n",
      "  %258 = add(%243, %257);\n",
      "  %259 = nn.relu(%258);\n",
      "  %260 = nn.conv2d(%259, %v_param_295, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %261 = nn.bias_add(%260, %v_param_296);\n",
      "  %262 = nn.batch_norm(%261, %v_param_297, %v_param_298, %v_param_299, %v_param_300, epsilon=1.001e-05f);\n",
      "  %263 = %262.0;\n",
      "  %264 = nn.relu(%263);\n",
      "  %265 = nn.conv2d(%264, %v_param_301, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %266 = nn.bias_add(%265, %v_param_302);\n",
      "  %267 = nn.batch_norm(%266, %v_param_303, %v_param_304, %v_param_305, %v_param_306, epsilon=1.001e-05f);\n",
      "  %268 = %267.0;\n",
      "  %269 = nn.relu(%268);\n",
      "  %270 = nn.conv2d(%269, %v_param_307, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %271 = nn.bias_add(%270, %v_param_308);\n",
      "  %272 = nn.batch_norm(%271, %v_param_309, %v_param_310, %v_param_311, %v_param_312, epsilon=1.001e-05f);\n",
      "  %273 = %272.0;\n",
      "  %274 = add(%259, %273);\n",
      "  %275 = nn.relu(%274);\n",
      "  %276 = nn.conv2d(%275, %v_param_313, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %277 = nn.bias_add(%276, %v_param_314);\n",
      "  %278 = nn.batch_norm(%277, %v_param_315, %v_param_316, %v_param_317, %v_param_318, epsilon=1.001e-05f);\n",
      "  %279 = %278.0;\n",
      "  %280 = nn.relu(%279);\n",
      "  %281 = nn.conv2d(%280, %v_param_319, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %282 = nn.bias_add(%281, %v_param_320);\n",
      "  %283 = nn.batch_norm(%282, %v_param_321, %v_param_322, %v_param_323, %v_param_324, epsilon=1.001e-05f);\n",
      "  %284 = %283.0;\n",
      "  %285 = nn.relu(%284);\n",
      "  %286 = nn.conv2d(%285, %v_param_325, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %287 = nn.bias_add(%286, %v_param_326);\n",
      "  %288 = nn.batch_norm(%287, %v_param_327, %v_param_328, %v_param_329, %v_param_330, epsilon=1.001e-05f);\n",
      "  %289 = %288.0;\n",
      "  %290 = add(%275, %289);\n",
      "  %291 = nn.relu(%290);\n",
      "  %292 = nn.conv2d(%291, %v_param_331, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %293 = nn.bias_add(%292, %v_param_332);\n",
      "  %294 = nn.batch_norm(%293, %v_param_333, %v_param_334, %v_param_335, %v_param_336, epsilon=1.001e-05f);\n",
      "  %295 = %294.0;\n",
      "  %296 = nn.relu(%295);\n",
      "  %297 = nn.conv2d(%296, %v_param_337, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %298 = nn.bias_add(%297, %v_param_338);\n",
      "  %299 = nn.batch_norm(%298, %v_param_339, %v_param_340, %v_param_341, %v_param_342, epsilon=1.001e-05f);\n",
      "  %300 = %299.0;\n",
      "  %301 = nn.relu(%300);\n",
      "  %302 = nn.conv2d(%301, %v_param_343, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %303 = nn.bias_add(%302, %v_param_344);\n",
      "  %304 = nn.batch_norm(%303, %v_param_345, %v_param_346, %v_param_347, %v_param_348, epsilon=1.001e-05f);\n",
      "  %305 = %304.0;\n",
      "  %306 = add(%291, %305);\n",
      "  %307 = nn.relu(%306);\n",
      "  %308 = nn.conv2d(%307, %v_param_349, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %309 = nn.bias_add(%308, %v_param_350);\n",
      "  %310 = nn.batch_norm(%309, %v_param_351, %v_param_352, %v_param_353, %v_param_354, epsilon=1.001e-05f);\n",
      "  %311 = %310.0;\n",
      "  %312 = nn.relu(%311);\n",
      "  %313 = nn.conv2d(%312, %v_param_355, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %314 = nn.bias_add(%313, %v_param_356);\n",
      "  %315 = nn.batch_norm(%314, %v_param_357, %v_param_358, %v_param_359, %v_param_360, epsilon=1.001e-05f);\n",
      "  %316 = %315.0;\n",
      "  %317 = nn.relu(%316);\n",
      "  %318 = nn.conv2d(%317, %v_param_361, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %319 = nn.bias_add(%318, %v_param_362);\n",
      "  %320 = nn.batch_norm(%319, %v_param_363, %v_param_364, %v_param_365, %v_param_366, epsilon=1.001e-05f);\n",
      "  %321 = %320.0;\n",
      "  %322 = add(%307, %321);\n",
      "  %323 = nn.relu(%322);\n",
      "  %324 = nn.conv2d(%323, %v_param_367, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %325 = nn.bias_add(%324, %v_param_368);\n",
      "  %326 = nn.batch_norm(%325, %v_param_369, %v_param_370, %v_param_371, %v_param_372, epsilon=1.001e-05f);\n",
      "  %327 = %326.0;\n",
      "  %328 = nn.relu(%327);\n",
      "  %329 = nn.conv2d(%328, %v_param_373, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %330 = nn.bias_add(%329, %v_param_374);\n",
      "  %331 = nn.batch_norm(%330, %v_param_375, %v_param_376, %v_param_377, %v_param_378, epsilon=1.001e-05f);\n",
      "  %332 = %331.0;\n",
      "  %333 = nn.relu(%332);\n",
      "  %334 = nn.conv2d(%333, %v_param_379, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %335 = nn.bias_add(%334, %v_param_380);\n",
      "  %336 = nn.batch_norm(%335, %v_param_381, %v_param_382, %v_param_383, %v_param_384, epsilon=1.001e-05f);\n",
      "  %337 = %336.0;\n",
      "  %338 = add(%323, %337);\n",
      "  %339 = nn.relu(%338);\n",
      "  %340 = nn.conv2d(%339, %v_param_385, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %341 = nn.bias_add(%340, %v_param_386);\n",
      "  %342 = nn.batch_norm(%341, %v_param_387, %v_param_388, %v_param_389, %v_param_390, epsilon=1.001e-05f);\n",
      "  %343 = %342.0;\n",
      "  %344 = nn.relu(%343);\n",
      "  %345 = nn.conv2d(%344, %v_param_391, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %346 = nn.bias_add(%345, %v_param_392);\n",
      "  %347 = nn.batch_norm(%346, %v_param_393, %v_param_394, %v_param_395, %v_param_396, epsilon=1.001e-05f);\n",
      "  %348 = %347.0;\n",
      "  %349 = nn.relu(%348);\n",
      "  %350 = nn.conv2d(%349, %v_param_397, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %351 = nn.bias_add(%350, %v_param_398);\n",
      "  %352 = nn.batch_norm(%351, %v_param_399, %v_param_400, %v_param_401, %v_param_402, epsilon=1.001e-05f);\n",
      "  %353 = %352.0;\n",
      "  %354 = add(%339, %353);\n",
      "  %355 = nn.relu(%354);\n",
      "  %356 = nn.conv2d(%355, %v_param_403, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %357 = nn.bias_add(%356, %v_param_404);\n",
      "  %358 = nn.batch_norm(%357, %v_param_405, %v_param_406, %v_param_407, %v_param_408, epsilon=1.001e-05f);\n",
      "  %359 = %358.0;\n",
      "  %360 = nn.relu(%359);\n",
      "  %361 = nn.conv2d(%360, %v_param_409, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %362 = nn.bias_add(%361, %v_param_410);\n",
      "  %363 = nn.batch_norm(%362, %v_param_411, %v_param_412, %v_param_413, %v_param_414, epsilon=1.001e-05f);\n",
      "  %364 = %363.0;\n",
      "  %365 = nn.relu(%364);\n",
      "  %366 = nn.conv2d(%365, %v_param_415, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %367 = nn.bias_add(%366, %v_param_416);\n",
      "  %368 = nn.batch_norm(%367, %v_param_417, %v_param_418, %v_param_419, %v_param_420, epsilon=1.001e-05f);\n",
      "  %369 = %368.0;\n",
      "  %370 = add(%355, %369);\n",
      "  %371 = nn.relu(%370);\n",
      "  %372 = nn.conv2d(%371, %v_param_421, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %373 = nn.bias_add(%372, %v_param_422);\n",
      "  %374 = nn.batch_norm(%373, %v_param_423, %v_param_424, %v_param_425, %v_param_426, epsilon=1.001e-05f);\n",
      "  %375 = %374.0;\n",
      "  %376 = nn.relu(%375);\n",
      "  %377 = nn.conv2d(%376, %v_param_427, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %378 = nn.bias_add(%377, %v_param_428);\n",
      "  %379 = nn.batch_norm(%378, %v_param_429, %v_param_430, %v_param_431, %v_param_432, epsilon=1.001e-05f);\n",
      "  %380 = %379.0;\n",
      "  %381 = nn.relu(%380);\n",
      "  %382 = nn.conv2d(%381, %v_param_433, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %383 = nn.bias_add(%382, %v_param_434);\n",
      "  %384 = nn.batch_norm(%383, %v_param_435, %v_param_436, %v_param_437, %v_param_438, epsilon=1.001e-05f);\n",
      "  %385 = %384.0;\n",
      "  %386 = add(%371, %385);\n",
      "  %387 = nn.relu(%386);\n",
      "  %388 = nn.conv2d(%387, %v_param_439, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %389 = nn.bias_add(%388, %v_param_440);\n",
      "  %390 = nn.batch_norm(%389, %v_param_441, %v_param_442, %v_param_443, %v_param_444, epsilon=1.001e-05f);\n",
      "  %391 = %390.0;\n",
      "  %392 = nn.relu(%391);\n",
      "  %393 = nn.conv2d(%392, %v_param_445, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %394 = nn.bias_add(%393, %v_param_446);\n",
      "  %395 = nn.batch_norm(%394, %v_param_447, %v_param_448, %v_param_449, %v_param_450, epsilon=1.001e-05f);\n",
      "  %396 = %395.0;\n",
      "  %397 = nn.relu(%396);\n",
      "  %398 = nn.conv2d(%397, %v_param_451, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %399 = nn.bias_add(%398, %v_param_452);\n",
      "  %400 = nn.batch_norm(%399, %v_param_453, %v_param_454, %v_param_455, %v_param_456, epsilon=1.001e-05f);\n",
      "  %401 = %400.0;\n",
      "  %402 = add(%387, %401);\n",
      "  %403 = nn.relu(%402);\n",
      "  %404 = nn.conv2d(%403, %v_param_457, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %405 = nn.bias_add(%404, %v_param_458);\n",
      "  %406 = nn.batch_norm(%405, %v_param_459, %v_param_460, %v_param_461, %v_param_462, epsilon=1.001e-05f);\n",
      "  %407 = %406.0;\n",
      "  %408 = nn.relu(%407);\n",
      "  %409 = nn.conv2d(%408, %v_param_463, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %410 = nn.bias_add(%409, %v_param_464);\n",
      "  %411 = nn.batch_norm(%410, %v_param_465, %v_param_466, %v_param_467, %v_param_468, epsilon=1.001e-05f);\n",
      "  %412 = %411.0;\n",
      "  %413 = nn.relu(%412);\n",
      "  %414 = nn.conv2d(%413, %v_param_469, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %415 = nn.bias_add(%414, %v_param_470);\n",
      "  %416 = nn.batch_norm(%415, %v_param_471, %v_param_472, %v_param_473, %v_param_474, epsilon=1.001e-05f);\n",
      "  %417 = %416.0;\n",
      "  %418 = add(%403, %417);\n",
      "  %419 = nn.relu(%418);\n",
      "  %420 = nn.conv2d(%419, %v_param_475, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %421 = nn.bias_add(%420, %v_param_476);\n",
      "  %422 = nn.batch_norm(%421, %v_param_477, %v_param_478, %v_param_479, %v_param_480, epsilon=1.001e-05f);\n",
      "  %423 = %422.0;\n",
      "  %424 = nn.relu(%423);\n",
      "  %425 = nn.conv2d(%424, %v_param_481, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %426 = nn.bias_add(%425, %v_param_482);\n",
      "  %427 = nn.batch_norm(%426, %v_param_483, %v_param_484, %v_param_485, %v_param_486, epsilon=1.001e-05f);\n",
      "  %428 = %427.0;\n",
      "  %429 = nn.relu(%428);\n",
      "  %430 = nn.conv2d(%429, %v_param_487, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %431 = nn.bias_add(%430, %v_param_488);\n",
      "  %432 = nn.batch_norm(%431, %v_param_489, %v_param_490, %v_param_491, %v_param_492, epsilon=1.001e-05f);\n",
      "  %433 = %432.0;\n",
      "  %434 = add(%419, %433);\n",
      "  %435 = nn.relu(%434);\n",
      "  %436 = nn.conv2d(%435, %v_param_493, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %437 = nn.bias_add(%436, %v_param_494);\n",
      "  %438 = nn.batch_norm(%437, %v_param_495, %v_param_496, %v_param_497, %v_param_498, epsilon=1.001e-05f);\n",
      "  %439 = %438.0;\n",
      "  %440 = nn.relu(%439);\n",
      "  %441 = nn.conv2d(%440, %v_param_499, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %442 = nn.bias_add(%441, %v_param_500);\n",
      "  %443 = nn.batch_norm(%442, %v_param_501, %v_param_502, %v_param_503, %v_param_504, epsilon=1.001e-05f);\n",
      "  %444 = %443.0;\n",
      "  %445 = nn.relu(%444);\n",
      "  %446 = nn.conv2d(%445, %v_param_505, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %447 = nn.bias_add(%446, %v_param_506);\n",
      "  %448 = nn.batch_norm(%447, %v_param_507, %v_param_508, %v_param_509, %v_param_510, epsilon=1.001e-05f);\n",
      "  %449 = %448.0;\n",
      "  %450 = add(%435, %449);\n",
      "  %451 = nn.relu(%450);\n",
      "  %452 = nn.conv2d(%451, %v_param_511, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %453 = nn.bias_add(%452, %v_param_512);\n",
      "  %454 = nn.batch_norm(%453, %v_param_513, %v_param_514, %v_param_515, %v_param_516, epsilon=1.001e-05f);\n",
      "  %455 = %454.0;\n",
      "  %456 = nn.relu(%455);\n",
      "  %457 = nn.conv2d(%456, %v_param_517, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %458 = nn.bias_add(%457, %v_param_518);\n",
      "  %459 = nn.batch_norm(%458, %v_param_519, %v_param_520, %v_param_521, %v_param_522, epsilon=1.001e-05f);\n",
      "  %460 = %459.0;\n",
      "  %461 = nn.relu(%460);\n",
      "  %462 = nn.conv2d(%461, %v_param_523, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %463 = nn.bias_add(%462, %v_param_524);\n",
      "  %464 = nn.batch_norm(%463, %v_param_525, %v_param_526, %v_param_527, %v_param_528, epsilon=1.001e-05f);\n",
      "  %465 = %464.0;\n",
      "  %466 = add(%451, %465);\n",
      "  %467 = nn.relu(%466);\n",
      "  %468 = nn.conv2d(%467, %v_param_529, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %469 = nn.bias_add(%468, %v_param_530);\n",
      "  %470 = nn.batch_norm(%469, %v_param_531, %v_param_532, %v_param_533, %v_param_534, epsilon=1.001e-05f);\n",
      "  %471 = %470.0;\n",
      "  %472 = nn.relu(%471);\n",
      "  %473 = nn.conv2d(%472, %v_param_535, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %474 = nn.bias_add(%473, %v_param_536);\n",
      "  %475 = nn.batch_norm(%474, %v_param_537, %v_param_538, %v_param_539, %v_param_540, epsilon=1.001e-05f);\n",
      "  %476 = %475.0;\n",
      "  %477 = nn.relu(%476);\n",
      "  %478 = nn.conv2d(%477, %v_param_541, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %479 = nn.bias_add(%478, %v_param_542);\n",
      "  %480 = nn.batch_norm(%479, %v_param_543, %v_param_544, %v_param_545, %v_param_546, epsilon=1.001e-05f);\n",
      "  %481 = %480.0;\n",
      "  %482 = add(%467, %481);\n",
      "  %483 = nn.relu(%482);\n",
      "  %484 = nn.conv2d(%483, %v_param_547, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %485 = nn.bias_add(%484, %v_param_548);\n",
      "  %486 = nn.batch_norm(%485, %v_param_549, %v_param_550, %v_param_551, %v_param_552, epsilon=1.001e-05f);\n",
      "  %487 = %486.0;\n",
      "  %488 = nn.relu(%487);\n",
      "  %489 = nn.conv2d(%488, %v_param_553, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %490 = nn.bias_add(%489, %v_param_554);\n",
      "  %491 = nn.batch_norm(%490, %v_param_555, %v_param_556, %v_param_557, %v_param_558, epsilon=1.001e-05f);\n",
      "  %492 = %491.0;\n",
      "  %493 = nn.relu(%492);\n",
      "  %494 = nn.conv2d(%493, %v_param_559, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %495 = nn.bias_add(%494, %v_param_560);\n",
      "  %496 = nn.batch_norm(%495, %v_param_561, %v_param_562, %v_param_563, %v_param_564, epsilon=1.001e-05f);\n",
      "  %497 = %496.0;\n",
      "  %498 = add(%483, %497);\n",
      "  %499 = nn.relu(%498);\n",
      "  %500 = nn.conv2d(%499, %v_param_565, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %501 = nn.bias_add(%500, %v_param_566);\n",
      "  %502 = nn.batch_norm(%501, %v_param_567, %v_param_568, %v_param_569, %v_param_570, epsilon=1.001e-05f);\n",
      "  %503 = %502.0;\n",
      "  %504 = nn.relu(%503);\n",
      "  %505 = nn.conv2d(%504, %v_param_571, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %506 = nn.bias_add(%505, %v_param_572);\n",
      "  %507 = nn.batch_norm(%506, %v_param_573, %v_param_574, %v_param_575, %v_param_576, epsilon=1.001e-05f);\n",
      "  %508 = %507.0;\n",
      "  %509 = nn.relu(%508);\n",
      "  %510 = nn.conv2d(%509, %v_param_577, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %511 = nn.bias_add(%510, %v_param_578);\n",
      "  %512 = nn.batch_norm(%511, %v_param_579, %v_param_580, %v_param_581, %v_param_582, epsilon=1.001e-05f);\n",
      "  %513 = %512.0;\n",
      "  %514 = add(%499, %513);\n",
      "  %515 = nn.relu(%514);\n",
      "  %516 = nn.conv2d(%515, %v_param_583, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %517 = nn.bias_add(%516, %v_param_584);\n",
      "  %518 = nn.batch_norm(%517, %v_param_585, %v_param_586, %v_param_587, %v_param_588, epsilon=1.001e-05f);\n",
      "  %519 = %518.0;\n",
      "  %520 = nn.relu(%519);\n",
      "  %521 = nn.conv2d(%520, %v_param_589, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %522 = nn.bias_add(%521, %v_param_590);\n",
      "  %523 = nn.batch_norm(%522, %v_param_591, %v_param_592, %v_param_593, %v_param_594, epsilon=1.001e-05f);\n",
      "  %524 = %523.0;\n",
      "  %525 = nn.relu(%524);\n",
      "  %526 = nn.conv2d(%525, %v_param_595, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %527 = nn.bias_add(%526, %v_param_596);\n",
      "  %528 = nn.batch_norm(%527, %v_param_597, %v_param_598, %v_param_599, %v_param_600, epsilon=1.001e-05f);\n",
      "  %529 = %528.0;\n",
      "  %530 = add(%515, %529);\n",
      "  %531 = nn.relu(%530);\n",
      "  %532 = nn.conv2d(%531, %v_param_601, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %533 = nn.bias_add(%532, %v_param_602);\n",
      "  %534 = nn.batch_norm(%533, %v_param_603, %v_param_604, %v_param_605, %v_param_606, epsilon=1.001e-05f);\n",
      "  %535 = %534.0;\n",
      "  %536 = nn.relu(%535);\n",
      "  %537 = nn.conv2d(%536, %v_param_607, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %538 = nn.bias_add(%537, %v_param_608);\n",
      "  %539 = nn.batch_norm(%538, %v_param_609, %v_param_610, %v_param_611, %v_param_612, epsilon=1.001e-05f);\n",
      "  %540 = %539.0;\n",
      "  %541 = nn.relu(%540);\n",
      "  %542 = nn.conv2d(%541, %v_param_613, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %543 = nn.bias_add(%542, %v_param_614);\n",
      "  %544 = nn.batch_norm(%543, %v_param_615, %v_param_616, %v_param_617, %v_param_618, epsilon=1.001e-05f);\n",
      "  %545 = %544.0;\n",
      "  %546 = add(%531, %545);\n",
      "  %547 = nn.relu(%546);\n",
      "  %548 = nn.conv2d(%547, %v_param_619, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %549 = nn.bias_add(%548, %v_param_620);\n",
      "  %550 = nn.batch_norm(%549, %v_param_621, %v_param_622, %v_param_623, %v_param_624, epsilon=1.001e-05f);\n",
      "  %551 = %550.0;\n",
      "  %552 = nn.relu(%551);\n",
      "  %553 = nn.conv2d(%552, %v_param_625, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %554 = nn.bias_add(%553, %v_param_626);\n",
      "  %555 = nn.batch_norm(%554, %v_param_627, %v_param_628, %v_param_629, %v_param_630, epsilon=1.001e-05f);\n",
      "  %556 = %555.0;\n",
      "  %557 = nn.relu(%556);\n",
      "  %558 = nn.conv2d(%557, %v_param_631, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %559 = nn.bias_add(%558, %v_param_632);\n",
      "  %560 = nn.batch_norm(%559, %v_param_633, %v_param_634, %v_param_635, %v_param_636, epsilon=1.001e-05f);\n",
      "  %561 = %560.0;\n",
      "  %562 = add(%547, %561);\n",
      "  %563 = nn.relu(%562);\n",
      "  %564 = nn.conv2d(%563, %v_param_637, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %565 = nn.bias_add(%564, %v_param_638);\n",
      "  %566 = nn.batch_norm(%565, %v_param_639, %v_param_640, %v_param_641, %v_param_642, epsilon=1.001e-05f);\n",
      "  %567 = %566.0;\n",
      "  %568 = nn.relu(%567);\n",
      "  %569 = nn.conv2d(%568, %v_param_643, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %570 = nn.bias_add(%569, %v_param_644);\n",
      "  %571 = nn.batch_norm(%570, %v_param_645, %v_param_646, %v_param_647, %v_param_648, epsilon=1.001e-05f);\n",
      "  %572 = %571.0;\n",
      "  %573 = nn.relu(%572);\n",
      "  %574 = nn.conv2d(%573, %v_param_649, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %575 = nn.bias_add(%574, %v_param_650);\n",
      "  %576 = nn.batch_norm(%575, %v_param_651, %v_param_652, %v_param_653, %v_param_654, epsilon=1.001e-05f);\n",
      "  %577 = %576.0;\n",
      "  %578 = add(%563, %577);\n",
      "  %579 = nn.relu(%578);\n",
      "  %580 = nn.conv2d(%579, %v_param_655, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %581 = nn.bias_add(%580, %v_param_656);\n",
      "  %582 = nn.batch_norm(%581, %v_param_657, %v_param_658, %v_param_659, %v_param_660, epsilon=1.001e-05f);\n",
      "  %583 = %582.0;\n",
      "  %584 = nn.relu(%583);\n",
      "  %585 = nn.conv2d(%584, %v_param_661, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %586 = nn.bias_add(%585, %v_param_662);\n",
      "  %587 = nn.batch_norm(%586, %v_param_663, %v_param_664, %v_param_665, %v_param_666, epsilon=1.001e-05f);\n",
      "  %588 = %587.0;\n",
      "  %589 = nn.relu(%588);\n",
      "  %590 = nn.conv2d(%589, %v_param_667, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %591 = nn.bias_add(%590, %v_param_668);\n",
      "  %592 = nn.batch_norm(%591, %v_param_669, %v_param_670, %v_param_671, %v_param_672, epsilon=1.001e-05f);\n",
      "  %593 = %592.0;\n",
      "  %594 = add(%579, %593);\n",
      "  %595 = nn.relu(%594);\n",
      "  %596 = nn.conv2d(%595, %v_param_673, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %597 = nn.bias_add(%596, %v_param_674);\n",
      "  %598 = nn.batch_norm(%597, %v_param_675, %v_param_676, %v_param_677, %v_param_678, epsilon=1.001e-05f);\n",
      "  %599 = %598.0;\n",
      "  %600 = nn.relu(%599);\n",
      "  %601 = nn.conv2d(%600, %v_param_679, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %602 = nn.bias_add(%601, %v_param_680);\n",
      "  %603 = nn.batch_norm(%602, %v_param_681, %v_param_682, %v_param_683, %v_param_684, epsilon=1.001e-05f);\n",
      "  %604 = %603.0;\n",
      "  %605 = nn.relu(%604);\n",
      "  %606 = nn.conv2d(%605, %v_param_685, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %607 = nn.bias_add(%606, %v_param_686);\n",
      "  %608 = nn.batch_norm(%607, %v_param_687, %v_param_688, %v_param_689, %v_param_690, epsilon=1.001e-05f);\n",
      "  %609 = %608.0;\n",
      "  %610 = add(%595, %609);\n",
      "  %611 = nn.relu(%610);\n",
      "  %612 = nn.conv2d(%611, %v_param_691, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %613 = nn.bias_add(%612, %v_param_692);\n",
      "  %614 = nn.batch_norm(%613, %v_param_693, %v_param_694, %v_param_695, %v_param_696, epsilon=1.001e-05f);\n",
      "  %615 = %614.0;\n",
      "  %616 = nn.relu(%615);\n",
      "  %617 = nn.conv2d(%616, %v_param_697, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %618 = nn.bias_add(%617, %v_param_698);\n",
      "  %619 = nn.batch_norm(%618, %v_param_699, %v_param_700, %v_param_701, %v_param_702, epsilon=1.001e-05f);\n",
      "  %620 = %619.0;\n",
      "  %621 = nn.relu(%620);\n",
      "  %622 = nn.conv2d(%621, %v_param_703, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %623 = nn.bias_add(%622, %v_param_704);\n",
      "  %624 = nn.batch_norm(%623, %v_param_705, %v_param_706, %v_param_707, %v_param_708, epsilon=1.001e-05f);\n",
      "  %625 = %624.0;\n",
      "  %626 = add(%611, %625);\n",
      "  %627 = nn.relu(%626);\n",
      "  %628 = nn.conv2d(%627, %v_param_709, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %629 = nn.bias_add(%628, %v_param_710);\n",
      "  %630 = nn.batch_norm(%629, %v_param_711, %v_param_712, %v_param_713, %v_param_714, epsilon=1.001e-05f);\n",
      "  %631 = %630.0;\n",
      "  %632 = nn.relu(%631);\n",
      "  %633 = nn.conv2d(%632, %v_param_715, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %634 = nn.bias_add(%633, %v_param_716);\n",
      "  %635 = nn.batch_norm(%634, %v_param_717, %v_param_718, %v_param_719, %v_param_720, epsilon=1.001e-05f);\n",
      "  %636 = %635.0;\n",
      "  %637 = nn.relu(%636);\n",
      "  %638 = nn.conv2d(%637, %v_param_721, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %639 = nn.bias_add(%638, %v_param_722);\n",
      "  %640 = nn.batch_norm(%639, %v_param_723, %v_param_724, %v_param_725, %v_param_726, epsilon=1.001e-05f);\n",
      "  %641 = %640.0;\n",
      "  %642 = add(%627, %641);\n",
      "  %643 = nn.relu(%642);\n",
      "  %644 = nn.conv2d(%643, %v_param_727, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %645 = nn.bias_add(%644, %v_param_728);\n",
      "  %646 = nn.batch_norm(%645, %v_param_729, %v_param_730, %v_param_731, %v_param_732, epsilon=1.001e-05f);\n",
      "  %647 = %646.0;\n",
      "  %648 = nn.relu(%647);\n",
      "  %649 = nn.conv2d(%648, %v_param_733, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %650 = nn.bias_add(%649, %v_param_734);\n",
      "  %651 = nn.batch_norm(%650, %v_param_735, %v_param_736, %v_param_737, %v_param_738, epsilon=1.001e-05f);\n",
      "  %652 = %651.0;\n",
      "  %653 = nn.relu(%652);\n",
      "  %654 = nn.conv2d(%653, %v_param_739, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %655 = nn.bias_add(%654, %v_param_740);\n",
      "  %656 = nn.batch_norm(%655, %v_param_741, %v_param_742, %v_param_743, %v_param_744, epsilon=1.001e-05f);\n",
      "  %657 = %656.0;\n",
      "  %658 = add(%643, %657);\n",
      "  %659 = nn.relu(%658);\n",
      "  %660 = nn.conv2d(%659, %v_param_745, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %661 = nn.bias_add(%660, %v_param_746);\n",
      "  %662 = nn.batch_norm(%661, %v_param_747, %v_param_748, %v_param_749, %v_param_750, epsilon=1.001e-05f);\n",
      "  %663 = %662.0;\n",
      "  %664 = nn.relu(%663);\n",
      "  %665 = nn.conv2d(%664, %v_param_751, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %666 = nn.bias_add(%665, %v_param_752);\n",
      "  %667 = nn.batch_norm(%666, %v_param_753, %v_param_754, %v_param_755, %v_param_756, epsilon=1.001e-05f);\n",
      "  %668 = %667.0;\n",
      "  %669 = nn.relu(%668);\n",
      "  %670 = nn.conv2d(%669, %v_param_757, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %671 = nn.bias_add(%670, %v_param_758);\n",
      "  %672 = nn.batch_norm(%671, %v_param_759, %v_param_760, %v_param_761, %v_param_762, epsilon=1.001e-05f);\n",
      "  %673 = %672.0;\n",
      "  %674 = add(%659, %673);\n",
      "  %675 = nn.relu(%674);\n",
      "  %676 = nn.conv2d(%675, %v_param_763, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %677 = nn.bias_add(%676, %v_param_764);\n",
      "  %678 = nn.batch_norm(%677, %v_param_765, %v_param_766, %v_param_767, %v_param_768, epsilon=1.001e-05f);\n",
      "  %679 = %678.0;\n",
      "  %680 = nn.relu(%679);\n",
      "  %681 = nn.conv2d(%680, %v_param_769, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %682 = nn.bias_add(%681, %v_param_770);\n",
      "  %683 = nn.batch_norm(%682, %v_param_771, %v_param_772, %v_param_773, %v_param_774, epsilon=1.001e-05f);\n",
      "  %684 = %683.0;\n",
      "  %685 = nn.relu(%684);\n",
      "  %686 = nn.conv2d(%685, %v_param_775, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %687 = nn.bias_add(%686, %v_param_776);\n",
      "  %688 = nn.batch_norm(%687, %v_param_777, %v_param_778, %v_param_779, %v_param_780, epsilon=1.001e-05f);\n",
      "  %689 = %688.0;\n",
      "  %690 = add(%675, %689);\n",
      "  %691 = nn.relu(%690);\n",
      "  %692 = nn.conv2d(%691, %v_param_781, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %693 = nn.bias_add(%692, %v_param_782);\n",
      "  %694 = nn.batch_norm(%693, %v_param_783, %v_param_784, %v_param_785, %v_param_786, epsilon=1.001e-05f);\n",
      "  %695 = %694.0;\n",
      "  %696 = nn.relu(%695);\n",
      "  %697 = nn.conv2d(%696, %v_param_787, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %698 = nn.bias_add(%697, %v_param_788);\n",
      "  %699 = nn.batch_norm(%698, %v_param_789, %v_param_790, %v_param_791, %v_param_792, epsilon=1.001e-05f);\n",
      "  %700 = %699.0;\n",
      "  %701 = nn.relu(%700);\n",
      "  %702 = nn.conv2d(%701, %v_param_793, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %703 = nn.bias_add(%702, %v_param_794);\n",
      "  %704 = nn.batch_norm(%703, %v_param_795, %v_param_796, %v_param_797, %v_param_798, epsilon=1.001e-05f);\n",
      "  %705 = %704.0;\n",
      "  %706 = add(%691, %705);\n",
      "  %707 = nn.relu(%706);\n",
      "  %708 = nn.conv2d(%707, %v_param_799, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %709 = nn.bias_add(%708, %v_param_800);\n",
      "  %710 = nn.batch_norm(%709, %v_param_801, %v_param_802, %v_param_803, %v_param_804, epsilon=1.001e-05f);\n",
      "  %711 = %710.0;\n",
      "  %712 = nn.relu(%711);\n",
      "  %713 = nn.conv2d(%712, %v_param_805, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %714 = nn.bias_add(%713, %v_param_806);\n",
      "  %715 = nn.batch_norm(%714, %v_param_807, %v_param_808, %v_param_809, %v_param_810, epsilon=1.001e-05f);\n",
      "  %716 = %715.0;\n",
      "  %717 = nn.relu(%716);\n",
      "  %718 = nn.conv2d(%717, %v_param_811, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %719 = nn.bias_add(%718, %v_param_812);\n",
      "  %720 = nn.batch_norm(%719, %v_param_813, %v_param_814, %v_param_815, %v_param_816, epsilon=1.001e-05f);\n",
      "  %721 = %720.0;\n",
      "  %722 = add(%707, %721);\n",
      "  %723 = nn.relu(%722);\n",
      "  %724 = nn.conv2d(%723, %v_param_817, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %725 = nn.bias_add(%724, %v_param_818);\n",
      "  %726 = nn.batch_norm(%725, %v_param_819, %v_param_820, %v_param_821, %v_param_822, epsilon=1.001e-05f);\n",
      "  %727 = %726.0;\n",
      "  %728 = nn.relu(%727);\n",
      "  %729 = nn.conv2d(%728, %v_param_823, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %730 = nn.bias_add(%729, %v_param_824);\n",
      "  %731 = nn.batch_norm(%730, %v_param_825, %v_param_826, %v_param_827, %v_param_828, epsilon=1.001e-05f);\n",
      "  %732 = %731.0;\n",
      "  %733 = nn.relu(%732);\n",
      "  %734 = nn.conv2d(%733, %v_param_829, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %735 = nn.bias_add(%734, %v_param_830);\n",
      "  %736 = nn.batch_norm(%735, %v_param_831, %v_param_832, %v_param_833, %v_param_834, epsilon=1.001e-05f);\n",
      "  %737 = %736.0;\n",
      "  %738 = add(%723, %737);\n",
      "  %739 = nn.relu(%738);\n",
      "  %740 = nn.conv2d(%739, %v_param_835, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %741 = nn.bias_add(%740, %v_param_836);\n",
      "  %742 = nn.batch_norm(%741, %v_param_837, %v_param_838, %v_param_839, %v_param_840, epsilon=1.001e-05f);\n",
      "  %743 = %742.0;\n",
      "  %744 = nn.relu(%743);\n",
      "  %745 = nn.conv2d(%744, %v_param_841, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %746 = nn.bias_add(%745, %v_param_842);\n",
      "  %747 = nn.batch_norm(%746, %v_param_843, %v_param_844, %v_param_845, %v_param_846, epsilon=1.001e-05f);\n",
      "  %748 = %747.0;\n",
      "  %749 = nn.relu(%748);\n",
      "  %750 = nn.conv2d(%749, %v_param_847, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %751 = nn.bias_add(%750, %v_param_848);\n",
      "  %752 = nn.batch_norm(%751, %v_param_849, %v_param_850, %v_param_851, %v_param_852, epsilon=1.001e-05f);\n",
      "  %753 = %752.0;\n",
      "  %754 = add(%739, %753);\n",
      "  %755 = nn.relu(%754);\n",
      "  %756 = nn.conv2d(%755, %v_param_853, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);\n",
      "  %757 = nn.bias_add(%756, %v_param_854);\n",
      "  %758 = nn.batch_norm(%757, %v_param_855, %v_param_856, %v_param_857, %v_param_858, epsilon=1.001e-05f);\n",
      "  %759 = %758.0;\n",
      "  %760 = nn.relu(%759);\n",
      "  %761 = nn.conv2d(%760, %v_param_859, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);\n",
      "  %762 = nn.bias_add(%761, %v_param_860);\n",
      "  %763 = nn.batch_norm(%762, %v_param_861, %v_param_862, %v_param_863, %v_param_864, epsilon=1.001e-05f);\n",
      "  %764 = %763.0;\n",
      "  %765 = nn.relu(%764);\n",
      "  %766 = nn.conv2d(%765, %v_param_865, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);\n",
      "  %767 = nn.bias_add(%766, %v_param_866);\n",
      "  %768 = nn.batch_norm(%767, %v_param_867, %v_param_868, %v_param_869, %v_param_870, epsilon=1.001e-05f);\n",
      "  %769 = %768.0;\n",
      "  %770 = add(%755, %769);\n",
      "  %771 = nn.relu(%770);\n",
      "  %772 = nn.conv2d(%771, %v_param_883, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %773 = nn.bias_add(%772, %v_param_884);\n",
      "  %774 = nn.batch_norm(%773, %v_param_887, %v_param_888, %v_param_889, %v_param_890, epsilon=1.001e-05f);\n",
      "  %775 = nn.conv2d(%771, %v_param_871, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %776 = nn.bias_add(%775, %v_param_872);\n",
      "  %777 = nn.batch_norm(%776, %v_param_873, %v_param_874, %v_param_875, %v_param_876, epsilon=1.001e-05f);\n",
      "  %778 = %777.0;\n",
      "  %779 = nn.relu(%778);\n",
      "  %780 = nn.conv2d(%779, %v_param_877, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %781 = nn.bias_add(%780, %v_param_878);\n",
      "  %782 = nn.batch_norm(%781, %v_param_879, %v_param_880, %v_param_881, %v_param_882, epsilon=1.001e-05f);\n",
      "  %783 = %782.0;\n",
      "  %784 = nn.relu(%783);\n",
      "  %785 = nn.conv2d(%784, %v_param_885, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %786 = nn.bias_add(%785, %v_param_886);\n",
      "  %787 = nn.batch_norm(%786, %v_param_891, %v_param_892, %v_param_893, %v_param_894, epsilon=1.001e-05f);\n",
      "  %788 = %774.0;\n",
      "  %789 = %787.0;\n",
      "  %790 = add(%788, %789);\n",
      "  %791 = nn.relu(%790);\n",
      "  %792 = nn.conv2d(%791, %v_param_895, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %793 = nn.bias_add(%792, %v_param_896);\n",
      "  %794 = nn.batch_norm(%793, %v_param_897, %v_param_898, %v_param_899, %v_param_900, epsilon=1.001e-05f);\n",
      "  %795 = %794.0;\n",
      "  %796 = nn.relu(%795);\n",
      "  %797 = nn.conv2d(%796, %v_param_901, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %798 = nn.bias_add(%797, %v_param_902);\n",
      "  %799 = nn.batch_norm(%798, %v_param_903, %v_param_904, %v_param_905, %v_param_906, epsilon=1.001e-05f);\n",
      "  %800 = %799.0;\n",
      "  %801 = nn.relu(%800);\n",
      "  %802 = nn.conv2d(%801, %v_param_907, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %803 = nn.bias_add(%802, %v_param_908);\n",
      "  %804 = nn.batch_norm(%803, %v_param_909, %v_param_910, %v_param_911, %v_param_912, epsilon=1.001e-05f);\n",
      "  %805 = %804.0;\n",
      "  %806 = add(%791, %805);\n",
      "  %807 = nn.relu(%806);\n",
      "  %808 = nn.conv2d(%807, %v_param_913, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);\n",
      "  %809 = nn.bias_add(%808, %v_param_914);\n",
      "  %810 = nn.batch_norm(%809, %v_param_915, %v_param_916, %v_param_917, %v_param_918, epsilon=1.001e-05f);\n",
      "  %811 = %810.0;\n",
      "  %812 = nn.relu(%811);\n",
      "  %813 = nn.conv2d(%812, %v_param_919, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);\n",
      "  %814 = nn.bias_add(%813, %v_param_920);\n",
      "  %815 = nn.batch_norm(%814, %v_param_921, %v_param_922, %v_param_923, %v_param_924, epsilon=1.001e-05f);\n",
      "  %816 = %815.0;\n",
      "  %817 = nn.relu(%816);\n",
      "  %818 = nn.conv2d(%817, %v_param_925, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);\n",
      "  %819 = nn.bias_add(%818, %v_param_926);\n",
      "  %820 = nn.batch_norm(%819, %v_param_927, %v_param_928, %v_param_929, %v_param_930, epsilon=1.001e-05f);\n",
      "  %821 = %820.0;\n",
      "  %822 = add(%807, %821);\n",
      "  %823 = nn.relu(%822);\n",
      "  %824 = nn.global_avg_pool2d(%823);\n",
      "  %825 = transpose(%824, axes=[0, 2, 3, 1]);\n",
      "  %826 = nn.batch_flatten(%825);\n",
      "  %827 = nn.dense(%826, %v_param_931, units=1000);\n",
      "  %828 = nn.bias_add(%827, %v_param_932);\n",
      "  nn.softmax(%828, axis=1)\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 512, 512), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32], %v_param_13: Tensor[(32, 16, 3, 3), float32], %v_param_14: Tensor[(32), float32], %v_param_15: Tensor[(32), float32], %v_param_16: Tensor[(32), float32], %v_param_17: Tensor[(32), float32], %v_param_18: Tensor[(32), float32], %v_param_19: Tensor[(32, 32, 3, 3), float32], %v_param_20: Tensor[(32), float32], %v_param_21: Tensor[(32), float32], %v_param_22: Tensor[(32), float32], %v_param_23: Tensor[(32), float32], %v_param_24: Tensor[(32), float32], %v_param_25: Tensor[(64, 32, 3, 3), float32], %v_param_26: Tensor[(64), float32], %v_param_27: Tensor[(64), float32], %v_param_28: Tensor[(64), float32], %v_param_29: Tensor[(64), float32], %v_param_30: Tensor[(64), float32], %v_param_31: Tensor[(64, 64, 3, 3), float32], %v_param_32: Tensor[(64), float32], %v_param_33: Tensor[(64), float32], %v_param_34: Tensor[(64), float32], %v_param_35: Tensor[(64), float32], %v_param_36: Tensor[(64), float32], %v_param_37: Tensor[(128, 64, 3, 3), float32], %v_param_38: Tensor[(128), float32], %v_param_39: Tensor[(128), float32], %v_param_40: Tensor[(128), float32], %v_param_41: Tensor[(128), float32], %v_param_42: Tensor[(128), float32], %v_param_43: Tensor[(128, 128, 3, 3), float32], %v_param_44: Tensor[(128), float32], %v_param_45: Tensor[(128), float32], %v_param_46: Tensor[(128), float32], %v_param_47: Tensor[(128), float32], %v_param_48: Tensor[(128), float32], %v_param_49: Tensor[(256, 128, 3, 3), float32], %v_param_50: Tensor[(256), float32], %v_param_51: Tensor[(256), float32], %v_param_52: Tensor[(256), float32], %v_param_53: Tensor[(256), float32], %v_param_54: Tensor[(256), float32], %v_param_55: Tensor[(256, 256, 3, 3), float32], %v_param_56: Tensor[(256), float32], %v_param_57: Tensor[(256), float32], %v_param_58: Tensor[(256), float32], %v_param_59: Tensor[(256), float32], %v_param_60: Tensor[(256), float32], %v_param_61: Tensor[(256, 128, 3, 3), float32], %v_param_62: Tensor[(128), float32], %v_param_63: Tensor[(128), float32], %v_param_64: Tensor[(128), float32], %v_param_65: Tensor[(128), float32], %v_param_66: Tensor[(128), float32], %v_param_67: Tensor[(128, 256, 3, 3), float32], %v_param_68: Tensor[(128), float32], %v_param_69: Tensor[(128), float32], %v_param_70: Tensor[(128), float32], %v_param_71: Tensor[(128), float32], %v_param_72: Tensor[(128), float32], %v_param_73: Tensor[(128, 128, 3, 3), float32], %v_param_74: Tensor[(128), float32], %v_param_75: Tensor[(128), float32], %v_param_76: Tensor[(128), float32], %v_param_77: Tensor[(128), float32], %v_param_78: Tensor[(128), float32], %v_param_79: Tensor[(128, 64, 3, 3), float32], %v_param_80: Tensor[(64), float32], %v_param_81: Tensor[(64), float32], %v_param_82: Tensor[(64), float32], %v_param_83: Tensor[(64), float32], %v_param_84: Tensor[(64), float32], %v_param_85: Tensor[(64, 128, 3, 3), float32], %v_param_86: Tensor[(64), float32], %v_param_87: Tensor[(64), float32], %v_param_88: Tensor[(64), float32], %v_param_89: Tensor[(64), float32], %v_param_90: Tensor[(64), float32], %v_param_91: Tensor[(64, 64, 3, 3), float32], %v_param_92: Tensor[(64), float32], %v_param_93: Tensor[(64), float32], %v_param_94: Tensor[(64), float32], %v_param_95: Tensor[(64), float32], %v_param_96: Tensor[(64), float32], %v_param_97: Tensor[(64, 32, 3, 3), float32], %v_param_98: Tensor[(32), float32], %v_param_99: Tensor[(32), float32], %v_param_100: Tensor[(32), float32], %v_param_101: Tensor[(32), float32], %v_param_102: Tensor[(32), float32], %v_param_103: Tensor[(32, 64, 3, 3), float32], %v_param_104: Tensor[(32), float32], %v_param_105: Tensor[(32), float32], %v_param_106: Tensor[(32), float32], %v_param_107: Tensor[(32), float32], %v_param_108: Tensor[(32), float32], %v_param_109: Tensor[(32, 32, 3, 3), float32], %v_param_110: Tensor[(32), float32], %v_param_111: Tensor[(32), float32], %v_param_112: Tensor[(32), float32], %v_param_113: Tensor[(32), float32], %v_param_114: Tensor[(32), float32], %v_param_115: Tensor[(32, 16, 3, 3), float32], %v_param_116: Tensor[(16), float32], %v_param_117: Tensor[(16), float32], %v_param_118: Tensor[(16), float32], %v_param_119: Tensor[(16), float32], %v_param_120: Tensor[(16), float32], %v_param_121: Tensor[(16, 32, 3, 3), float32], %v_param_122: Tensor[(16), float32], %v_param_123: Tensor[(16), float32], %v_param_124: Tensor[(16), float32], %v_param_125: Tensor[(16), float32], %v_param_126: Tensor[(16), float32], %v_param_127: Tensor[(16, 16, 3, 3), float32], %v_param_128: Tensor[(16), float32], %v_param_129: Tensor[(16), float32], %v_param_130: Tensor[(16), float32], %v_param_131: Tensor[(16), float32], %v_param_132: Tensor[(16), float32], %v_param_133: Tensor[(1, 16, 3, 3), float32], %v_param_134: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
       "  %3 = %2.0;\n",
       "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
       "  %5 = nn.conv2d(%4, %v_param_7, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %6 = nn.bias_add(%5, %v_param_8);\n",
       "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
       "  %8 = %7.0;\n",
       "  %9 = multiply(%8, 8f);\n",
       "  %10 = round(%9);\n",
       "  %11 = clip(%10, a_min=-127f, a_max=127f);\n",
       "  %12 = cast(%11, dtype=\"int8\");\n",
       "  %13 = annotation.stop_fusion(%12);\n",
       "  %14 = annotation.stop_fusion(%13);\n",
       "  %15 = cast(%14, dtype=\"float32\");\n",
       "  %16 = divide(%15, 8f);\n",
       "  %17 = nn.conv2d(%16, %v_param_121, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %18 = nn.bias_add(%17, %v_param_122);\n",
       "  %19 = nn.batch_norm(%18, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f);\n",
       "  %20 = %19.0;\n",
       "  %21 = nn.leaky_relu(%20, alpha=0.2f);\n",
       "  %22 = nn.conv2d(%21, %v_param_127, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]);\n",
       "  %23 = nn.bias_add(%22, %v_param_128);\n",
       "  %24 = nn.batch_norm(%23, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f);\n",
       "  %25 = %24.0;\n",
       "  %26 = nn.conv2d(%25, %v_param_133, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]);\n",
       "  %27 = nn.bias_add(%26, %v_param_134);\n",
       "  sigmoid(%27)\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cuda'\n",
    "dev = tvm.cuda()\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(out, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.export_library(\"./model/unet_cuda_try_quant.so\")\n",
    "# lib.export_library(\"./model/resnet152_cuda_try_quant.so\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(lib['get_graph_json'](), \"unet_insert_quant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph_partition(json_data, file_name=None):\n",
    "    if type(json_data) == str:\n",
    "        json_data = json.loads(json_data)\n",
    "    A = pgv.AGraph(directed=True)\n",
    "    for node_idx, node in enumerate(json_data['nodes']):\n",
    "        for src in node['inputs']:\n",
    "            A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]))\n",
    "    \n",
    "    for node_idx, node in enumerate(json_data['nodes']):\n",
    "        for src in node['inputs']:\n",
    "            dtype = json_data['attrs']['dltype'][1][src[0]]\n",
    "            if dtype == 'int8':\n",
    "                n = A.get_node(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]))\n",
    "                n.attr[\"color\"] = \"green\"\n",
    "\n",
    "    if file_name:\n",
    "        A.draw(file_name + '.png', format='png', prog='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph_partition(lib['get_graph_json'](), \"unet_insert_quant_colored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
