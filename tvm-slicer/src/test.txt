first prerequisite_optimize
def @main(%input_1: Tensor[(1, 3, 512, 512), float32]) -> Tensor[(1, 1, 512, 512), float32] {
  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %2 = multiply(%1, meta[relay.Constant][2] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %3 = add(%2, meta[relay.Constant][3] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %4 = nn.leaky_relu(%3, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %5 = nn.conv2d(%4, meta[relay.Constant][4] /* ty=Tensor[(16, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %6 = nn.bias_add(%5, meta[relay.Constant][5] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %7 = multiply(%6, meta[relay.Constant][6] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %8 = add(%7, meta[relay.Constant][7] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %9 = nn.max_pool2d(%8, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 16, 256, 256), float32] */;
  %10 = nn.conv2d(%9, meta[relay.Constant][8] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %11 = nn.bias_add(%10, meta[relay.Constant][9] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %12 = multiply(%11, meta[relay.Constant][10] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %13 = add(%12, meta[relay.Constant][11] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %14 = nn.leaky_relu(%13, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %15 = nn.conv2d(%14, meta[relay.Constant][12] /* ty=Tensor[(32, 32, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %16 = nn.bias_add(%15, meta[relay.Constant][13] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %17 = multiply(%16, meta[relay.Constant][14] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %18 = add(%17, meta[relay.Constant][15] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %19 = nn.max_pool2d(%18, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 32, 128, 128), float32] */;
  %20 = nn.conv2d(%19, meta[relay.Constant][16] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %21 = nn.bias_add(%20, meta[relay.Constant][17] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %22 = multiply(%21, meta[relay.Constant][18] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %23 = add(%22, meta[relay.Constant][19] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %24 = nn.leaky_relu(%23, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %25 = nn.conv2d(%24, meta[relay.Constant][20] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %26 = nn.bias_add(%25, meta[relay.Constant][21] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %27 = multiply(%26, meta[relay.Constant][22] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %28 = add(%27, meta[relay.Constant][23] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %29 = nn.max_pool2d(%28, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 64, 64), float32] */;
  %30 = nn.conv2d(%29, meta[relay.Constant][24] /* ty=Tensor[(128, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %31 = nn.bias_add(%30, meta[relay.Constant][25] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %32 = multiply(%31, meta[relay.Constant][26] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %33 = add(%32, meta[relay.Constant][27] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %34 = nn.leaky_relu(%33, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %35 = nn.conv2d(%34, meta[relay.Constant][28] /* ty=Tensor[(128, 128, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %36 = nn.bias_add(%35, meta[relay.Constant][29] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %37 = multiply(%36, meta[relay.Constant][30] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %38 = add(%37, meta[relay.Constant][31] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %39 = nn.max_pool2d(%38, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 32, 32), float32] */;
  %40 = nn.conv2d(%39, meta[relay.Constant][32] /* ty=Tensor[(256, 128, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %41 = nn.bias_add(%40, meta[relay.Constant][33] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %42 = multiply(%41, meta[relay.Constant][34] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %43 = add(%42, meta[relay.Constant][35] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %44 = nn.leaky_relu(%43, alpha=0.2f) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %45 = nn.conv2d(%44, meta[relay.Constant][36] /* ty=Tensor[(256, 256, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %46 = nn.bias_add(%45, meta[relay.Constant][37] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %47 = multiply(%46, meta[relay.Constant][38] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %48 = add(%47, meta[relay.Constant][39] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %49 = nn.conv2d_transpose(%48, meta[relay.Constant][40] /* ty=Tensor[(256, 128, 3, 3), float32] */, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %50 = nn.bias_add(%49, meta[relay.Constant][41] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %51 = multiply(%50, meta[relay.Constant][42] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %52 = add(%51, meta[relay.Constant][43] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %53 = nn.leaky_relu(%52, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %54 = (%53, %38);
  %55 = concatenate(%54, axis=1) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %56 = nn.conv2d(%55, meta[relay.Constant][44] /* ty=Tensor[(128, 256, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %57 = nn.bias_add(%56, meta[relay.Constant][45] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %58 = multiply(%57, meta[relay.Constant][46] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %59 = add(%58, meta[relay.Constant][47] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %60 = nn.leaky_relu(%59, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %61 = nn.conv2d(%60, meta[relay.Constant][48] /* ty=Tensor[(128, 128, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %62 = nn.bias_add(%61, meta[relay.Constant][49] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %63 = multiply(%62, meta[relay.Constant][50] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %64 = add(%63, meta[relay.Constant][51] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %65 = nn.conv2d_transpose(%64, meta[relay.Constant][52] /* ty=Tensor[(128, 64, 3, 3), float32] */, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %66 = nn.bias_add(%65, meta[relay.Constant][53] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %67 = multiply(%66, meta[relay.Constant][54] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %68 = add(%67, meta[relay.Constant][55] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %69 = nn.leaky_relu(%68, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %70 = (%69, %28);
  %71 = concatenate(%70, axis=1) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %72 = nn.conv2d(%71, meta[relay.Constant][56] /* ty=Tensor[(64, 128, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %73 = nn.bias_add(%72, meta[relay.Constant][57] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %74 = multiply(%73, meta[relay.Constant][58] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %75 = add(%74, meta[relay.Constant][59] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %76 = nn.leaky_relu(%75, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %77 = nn.conv2d(%76, meta[relay.Constant][60] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %78 = nn.bias_add(%77, meta[relay.Constant][61] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %79 = multiply(%78, meta[relay.Constant][62] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %80 = add(%79, meta[relay.Constant][63] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %81 = nn.conv2d_transpose(%80, meta[relay.Constant][64] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %82 = nn.bias_add(%81, meta[relay.Constant][65] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %83 = multiply(%82, meta[relay.Constant][66] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %84 = add(%83, meta[relay.Constant][67] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %85 = nn.leaky_relu(%84, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %86 = (%85, %18);
  %87 = concatenate(%86, axis=1) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %88 = nn.conv2d(%87, meta[relay.Constant][68] /* ty=Tensor[(32, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %89 = nn.bias_add(%88, meta[relay.Constant][69] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %90 = multiply(%89, meta[relay.Constant][70] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %91 = add(%90, meta[relay.Constant][71] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %92 = nn.leaky_relu(%91, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %93 = nn.conv2d(%92, meta[relay.Constant][72] /* ty=Tensor[(32, 32, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %94 = nn.bias_add(%93, meta[relay.Constant][73] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %95 = multiply(%94, meta[relay.Constant][74] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %96 = add(%95, meta[relay.Constant][75] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %97 = nn.conv2d_transpose(%96, meta[relay.Constant][76] /* ty=Tensor[(32, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %98 = nn.bias_add(%97, meta[relay.Constant][77] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %99 = multiply(%98, meta[relay.Constant][78] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %100 = add(%99, meta[relay.Constant][79] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %101 = nn.leaky_relu(%100, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %102 = (%101, %8);
  %103 = concatenate(%102, axis=1) /* ty=Tensor[(1, 32, 512, 512), float32] */;
  %104 = nn.conv2d(%103, meta[relay.Constant][80] /* ty=Tensor[(16, 32, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %105 = nn.bias_add(%104, meta[relay.Constant][81] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %106 = multiply(%105, meta[relay.Constant][82] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %107 = add(%106, meta[relay.Constant][83] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %108 = nn.leaky_relu(%107, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %109 = nn.conv2d(%108, meta[relay.Constant][84] /* ty=Tensor[(16, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %110 = nn.bias_add(%109, meta[relay.Constant][85] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %111 = multiply(%110, meta[relay.Constant][86] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %112 = add(%111, meta[relay.Constant][87] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %113 = nn.conv2d(%112, meta[relay.Constant][88] /* ty=Tensor[(1, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3]) /* ty=Tensor[(1, 1, 512, 512), float32] */;
  %114 = nn.bias_add(%113, meta[relay.Constant][89] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 512, 512), float32] */;
  sigmoid(%114) /* ty=Tensor[(1, 1, 512, 512), float32] */
}


===========================
second quantize_context
def @main(%input_1: Tensor[(1, 3, 512, 512), float32]) -> Tensor[(1, 1, 512, 512), float32] {
  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %1 = annotation.stop_fusion(%0) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %3 = multiply(%2, meta[relay.Constant][2] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %4 = add(%3, meta[relay.Constant][3] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %5 = nn.leaky_relu(%4, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %6 = multiply(%5, 16f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %7 = round(%6) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %8 = clip(%7, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %9 = cast(%8, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %10 = nn.conv2d(%9, meta[relay.Constant][4] /* ty=Tensor[(16, 16, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %11 = add(%10, 256 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %12 = right_shift(%11, 9 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %13 = clip(%12, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %14 = cast(%13, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %15 = annotation.stop_fusion(%14) /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %16 = cast(%15, dtype="float32") /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %17 = multiply(%16, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %18 = nn.bias_add(%17, meta[relay.Constant][5] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %19 = multiply(%18, meta[relay.Constant][6] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %20 = add(%19, meta[relay.Constant][7] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %21 = nn.max_pool2d(%20, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 16, 256, 256), float32] */;
  %22 = multiply(%21, 16f /* ty=float32 */) /* ty=Tensor[(1, 16, 256, 256), float32] */;
  %23 = round(%22) /* ty=Tensor[(1, 16, 256, 256), float32] */;
  %24 = clip(%23, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 256, 256), float32] */;
  %25 = cast(%24, dtype="int8") /* ty=Tensor[(1, 16, 256, 256), int8] */;
  %26 = nn.conv2d(%25, meta[relay.Constant][8] /* ty=Tensor[(32, 16, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %27 = add(%26, 256 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %28 = right_shift(%27, 9 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %29 = clip(%28, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %30 = cast(%29, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %31 = annotation.stop_fusion(%30) /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %32 = cast(%31, dtype="float32") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %33 = multiply(%32, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %34 = nn.bias_add(%33, meta[relay.Constant][9] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %35 = multiply(%34, meta[relay.Constant][10] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %36 = add(%35, meta[relay.Constant][11] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %37 = nn.leaky_relu(%36, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %38 = multiply(%37, 16f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %39 = round(%38) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %40 = clip(%39, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %41 = cast(%40, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %42 = nn.conv2d(%41, meta[relay.Constant][12] /* ty=Tensor[(32, 32, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %43 = add(%42, 512 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %44 = right_shift(%43, 10 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %45 = clip(%44, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %46 = cast(%45, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %47 = annotation.stop_fusion(%46) /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %48 = cast(%47, dtype="float32") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %49 = multiply(%48, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %50 = nn.bias_add(%49, meta[relay.Constant][13] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %51 = multiply(%50, meta[relay.Constant][14] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %52 = add(%51, meta[relay.Constant][15] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %53 = nn.max_pool2d(%52, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 32, 128, 128), float32] */;
  %54 = multiply(%53, 16f /* ty=float32 */) /* ty=Tensor[(1, 32, 128, 128), float32] */;
  %55 = round(%54) /* ty=Tensor[(1, 32, 128, 128), float32] */;
  %56 = clip(%55, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 128, 128), float32] */;
  %57 = cast(%56, dtype="int8") /* ty=Tensor[(1, 32, 128, 128), int8] */;
  %58 = nn.conv2d(%57, meta[relay.Constant][16] /* ty=Tensor[(64, 32, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %59 = add(%58, 512 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %60 = right_shift(%59, 10 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %61 = clip(%60, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %62 = cast(%61, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %63 = annotation.stop_fusion(%62) /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %64 = cast(%63, dtype="float32") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %65 = multiply(%64, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %66 = nn.bias_add(%65, meta[relay.Constant][17] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %67 = multiply(%66, meta[relay.Constant][18] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %68 = add(%67, meta[relay.Constant][19] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %69 = nn.leaky_relu(%68, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %70 = multiply(%69, 16f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %71 = round(%70) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %72 = clip(%71, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %73 = cast(%72, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %74 = nn.conv2d(%73, meta[relay.Constant][20] /* ty=Tensor[(64, 64, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %75 = add(%74, 512 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %76 = right_shift(%75, 10 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %77 = clip(%76, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %78 = cast(%77, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %79 = annotation.stop_fusion(%78) /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %80 = cast(%79, dtype="float32") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %81 = multiply(%80, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %82 = nn.bias_add(%81, meta[relay.Constant][21] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %83 = multiply(%82, meta[relay.Constant][22] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %84 = add(%83, meta[relay.Constant][23] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %85 = nn.max_pool2d(%84, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 64, 64), float32] */;
  %86 = multiply(%85, 16f /* ty=float32 */) /* ty=Tensor[(1, 64, 64, 64), float32] */;
  %87 = round(%86) /* ty=Tensor[(1, 64, 64, 64), float32] */;
  %88 = clip(%87, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 64, 64), float32] */;
  %89 = cast(%88, dtype="int8") /* ty=Tensor[(1, 64, 64, 64), int8] */;
  %90 = nn.conv2d(%89, meta[relay.Constant][24] /* ty=Tensor[(128, 64, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %91 = add(%90, 512 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %92 = right_shift(%91, 10 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %93 = clip(%92, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %94 = cast(%93, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %95 = annotation.stop_fusion(%94) /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %96 = cast(%95, dtype="float32") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %97 = multiply(%96, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %98 = nn.bias_add(%97, meta[relay.Constant][25] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %99 = multiply(%98, meta[relay.Constant][26] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %100 = add(%99, meta[relay.Constant][27] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %101 = nn.leaky_relu(%100, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %102 = multiply(%101, 16f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %103 = round(%102) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %104 = clip(%103, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %105 = cast(%104, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %106 = nn.conv2d(%105, meta[relay.Constant][28] /* ty=Tensor[(128, 128, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %107 = add(%106, 512 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %108 = right_shift(%107, 10 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %109 = clip(%108, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %110 = cast(%109, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %111 = annotation.stop_fusion(%110) /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %112 = cast(%111, dtype="float32") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %113 = multiply(%112, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %114 = nn.bias_add(%113, meta[relay.Constant][29] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %115 = multiply(%114, meta[relay.Constant][30] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %116 = add(%115, meta[relay.Constant][31] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %117 = nn.max_pool2d(%116, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 32, 32), float32] */;
  %118 = multiply(%117, 16f /* ty=float32 */) /* ty=Tensor[(1, 128, 32, 32), float32] */;
  %119 = round(%118) /* ty=Tensor[(1, 128, 32, 32), float32] */;
  %120 = clip(%119, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 32, 32), float32] */;
  %121 = cast(%120, dtype="int8") /* ty=Tensor[(1, 128, 32, 32), int8] */;
  %122 = nn.conv2d(%121, meta[relay.Constant][32] /* ty=Tensor[(256, 128, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %123 = add(%122, 512 /* ty=int32 */) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %124 = right_shift(%123, 10 /* ty=int32 */) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %125 = clip(%124, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %126 = cast(%125, dtype="int8") /* ty=Tensor[(1, 256, 32, 32), int8] */;
  %127 = annotation.stop_fusion(%126) /* ty=Tensor[(1, 256, 32, 32), int8] */;
  %128 = cast(%127, dtype="float32") /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %129 = multiply(%128, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %130 = nn.bias_add(%129, meta[relay.Constant][33] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %131 = multiply(%130, meta[relay.Constant][34] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %132 = add(%131, meta[relay.Constant][35] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %133 = nn.leaky_relu(%132, alpha=0.2f) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %134 = multiply(%133, 16f /* ty=float32 */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %135 = round(%134) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %136 = clip(%135, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %137 = cast(%136, dtype="int8") /* ty=Tensor[(1, 256, 32, 32), int8] */;
  %138 = nn.conv2d(%137, meta[relay.Constant][36] /* ty=Tensor[(256, 256, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %139 = add(%138, 1024 /* ty=int32 */) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %140 = right_shift(%139, 11 /* ty=int32 */) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %141 = clip(%140, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 32, 32), int32] */;
  %142 = cast(%141, dtype="int8") /* ty=Tensor[(1, 256, 32, 32), int8] */;
  %143 = annotation.stop_fusion(%142) /* ty=Tensor[(1, 256, 32, 32), int8] */;
  %144 = cast(%143, dtype="float32") /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %145 = multiply(%144, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %146 = nn.bias_add(%145, meta[relay.Constant][37] /* ty=Tensor[(256), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %147 = multiply(%146, meta[relay.Constant][38] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %148 = add(%147, meta[relay.Constant][39] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 32, 32), float32] */;
  %149 = nn.conv2d_transpose(%148, meta[relay.Constant][40] /* ty=Tensor[(256, 128, 3, 3), float32] */, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %150 = nn.bias_add(%149, meta[relay.Constant][41] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %151 = multiply(%150, meta[relay.Constant][42] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %152 = add(%151, meta[relay.Constant][43] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %153 = nn.leaky_relu(%152, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %154 = (%153, %116);
  %155 = concatenate(%154, axis=1) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %156 = multiply(%155, 16f /* ty=float32 */) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %157 = round(%156) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %158 = clip(%157, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;
  %159 = cast(%158, dtype="int8") /* ty=Tensor[(1, 256, 64, 64), int8] */;
  %160 = nn.conv2d(%159, meta[relay.Constant][44] /* ty=Tensor[(128, 256, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %161 = add(%160, 512 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %162 = right_shift(%161, 10 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %163 = clip(%162, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %164 = cast(%163, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %165 = annotation.stop_fusion(%164) /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %166 = cast(%165, dtype="float32") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %167 = multiply(%166, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %168 = nn.bias_add(%167, meta[relay.Constant][45] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %169 = multiply(%168, meta[relay.Constant][46] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %170 = add(%169, meta[relay.Constant][47] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %171 = nn.leaky_relu(%170, alpha=0.2f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %172 = multiply(%171, 16f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %173 = round(%172) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %174 = clip(%173, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %175 = cast(%174, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %176 = nn.conv2d(%175, meta[relay.Constant][48] /* ty=Tensor[(128, 128, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %177 = add(%176, 512 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %178 = right_shift(%177, 10 /* ty=int32 */) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %179 = clip(%178, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64, 64), int32] */;
  %180 = cast(%179, dtype="int8") /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %181 = annotation.stop_fusion(%180) /* ty=Tensor[(1, 128, 64, 64), int8] */;
  %182 = cast(%181, dtype="float32") /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %183 = multiply(%182, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %184 = nn.bias_add(%183, meta[relay.Constant][49] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %185 = multiply(%184, meta[relay.Constant][50] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %186 = add(%185, meta[relay.Constant][51] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 64, 64), float32] */;
  %187 = nn.conv2d_transpose(%186, meta[relay.Constant][52] /* ty=Tensor[(128, 64, 3, 3), float32] */, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %188 = nn.bias_add(%187, meta[relay.Constant][53] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %189 = multiply(%188, meta[relay.Constant][54] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %190 = add(%189, meta[relay.Constant][55] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %191 = nn.leaky_relu(%190, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %192 = (%191, %84);
  %193 = concatenate(%192, axis=1) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %194 = multiply(%193, 16f /* ty=float32 */) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %195 = round(%194) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %196 = clip(%195, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;
  %197 = cast(%196, dtype="int8") /* ty=Tensor[(1, 128, 128, 128), int8] */;
  %198 = nn.conv2d(%197, meta[relay.Constant][56] /* ty=Tensor[(64, 128, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %199 = add(%198, 512 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %200 = right_shift(%199, 10 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %201 = clip(%200, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %202 = cast(%201, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %203 = annotation.stop_fusion(%202) /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %204 = cast(%203, dtype="float32") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %205 = multiply(%204, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %206 = nn.bias_add(%205, meta[relay.Constant][57] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %207 = multiply(%206, meta[relay.Constant][58] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %208 = add(%207, meta[relay.Constant][59] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %209 = nn.leaky_relu(%208, alpha=0.2f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %210 = multiply(%209, 16f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %211 = round(%210) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %212 = clip(%211, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %213 = cast(%212, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %214 = nn.conv2d(%213, meta[relay.Constant][60] /* ty=Tensor[(64, 64, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %215 = add(%214, 512 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %216 = right_shift(%215, 10 /* ty=int32 */) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %217 = clip(%216, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128, 128), int32] */;
  %218 = cast(%217, dtype="int8") /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %219 = annotation.stop_fusion(%218) /* ty=Tensor[(1, 64, 128, 128), int8] */;
  %220 = cast(%219, dtype="float32") /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %221 = multiply(%220, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %222 = nn.bias_add(%221, meta[relay.Constant][61] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %223 = multiply(%222, meta[relay.Constant][62] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %224 = add(%223, meta[relay.Constant][63] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 128, 128), float32] */;
  %225 = nn.conv2d_transpose(%224, meta[relay.Constant][64] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %226 = nn.bias_add(%225, meta[relay.Constant][65] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %227 = multiply(%226, meta[relay.Constant][66] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %228 = add(%227, meta[relay.Constant][67] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %229 = nn.leaky_relu(%228, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %230 = (%229, %52);
  %231 = concatenate(%230, axis=1) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %232 = multiply(%231, 16f /* ty=float32 */) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %233 = round(%232) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %234 = clip(%233, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;
  %235 = cast(%234, dtype="int8") /* ty=Tensor[(1, 64, 256, 256), int8] */;
  %236 = nn.conv2d(%235, meta[relay.Constant][68] /* ty=Tensor[(32, 64, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %237 = add(%236, 512 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %238 = right_shift(%237, 10 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %239 = clip(%238, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %240 = cast(%239, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %241 = annotation.stop_fusion(%240) /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %242 = cast(%241, dtype="float32") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %243 = multiply(%242, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %244 = nn.bias_add(%243, meta[relay.Constant][69] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %245 = multiply(%244, meta[relay.Constant][70] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %246 = add(%245, meta[relay.Constant][71] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %247 = nn.leaky_relu(%246, alpha=0.2f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %248 = multiply(%247, 16f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %249 = round(%248) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %250 = clip(%249, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %251 = cast(%250, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %252 = nn.conv2d(%251, meta[relay.Constant][72] /* ty=Tensor[(32, 32, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %253 = add(%252, 512 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %254 = right_shift(%253, 10 /* ty=int32 */) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %255 = clip(%254, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 256, 256), int32] */;
  %256 = cast(%255, dtype="int8") /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %257 = annotation.stop_fusion(%256) /* ty=Tensor[(1, 32, 256, 256), int8] */;
  %258 = cast(%257, dtype="float32") /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %259 = multiply(%258, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %260 = nn.bias_add(%259, meta[relay.Constant][73] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %261 = multiply(%260, meta[relay.Constant][74] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %262 = add(%261, meta[relay.Constant][75] /* ty=Tensor[(32, 1, 1), float32] */) /* ty=Tensor[(1, 32, 256, 256), float32] */;
  %263 = nn.conv2d_transpose(%262, meta[relay.Constant][76] /* ty=Tensor[(32, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], kernel_layout="IOHW") /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %264 = nn.bias_add(%263, meta[relay.Constant][77] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %265 = multiply(%264, meta[relay.Constant][78] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %266 = add(%265, meta[relay.Constant][79] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %267 = nn.leaky_relu(%266, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %268 = (%267, %20);
  %269 = concatenate(%268, axis=1) /* ty=Tensor[(1, 32, 512, 512), float32] */;
  %270 = multiply(%269, 16f /* ty=float32 */) /* ty=Tensor[(1, 32, 512, 512), float32] */;
  %271 = round(%270) /* ty=Tensor[(1, 32, 512, 512), float32] */;
  %272 = clip(%271, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 32, 512, 512), float32] */;
  %273 = cast(%272, dtype="int8") /* ty=Tensor[(1, 32, 512, 512), int8] */;
  %274 = nn.conv2d(%273, meta[relay.Constant][80] /* ty=Tensor[(16, 32, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %275 = add(%274, 256 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %276 = right_shift(%275, 9 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %277 = clip(%276, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %278 = cast(%277, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %279 = annotation.stop_fusion(%278) /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %280 = cast(%279, dtype="float32") /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %281 = multiply(%280, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %282 = nn.bias_add(%281, meta[relay.Constant][81] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %283 = multiply(%282, meta[relay.Constant][82] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %284 = add(%283, meta[relay.Constant][83] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %285 = nn.leaky_relu(%284, alpha=0.2f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %286 = multiply(%285, 16f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %287 = round(%286) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %288 = clip(%287, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %289 = cast(%288, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %290 = nn.conv2d(%289, meta[relay.Constant][84] /* ty=Tensor[(16, 16, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %291 = add(%290, 256 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %292 = right_shift(%291, 9 /* ty=int32 */) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %293 = clip(%292, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), int32] */;
  %294 = cast(%293, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %295 = annotation.stop_fusion(%294) /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %296 = cast(%295, dtype="float32") /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %297 = multiply(%296, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %298 = nn.bias_add(%297, meta[relay.Constant][85] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %299 = multiply(%298, meta[relay.Constant][86] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %300 = add(%299, meta[relay.Constant][87] /* ty=Tensor[(16, 1, 1), float32] */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %301 = multiply(%300, 16f /* ty=float32 */) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %302 = round(%301) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %303 = clip(%302, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 16, 512, 512), float32] */;
  %304 = cast(%303, dtype="int8") /* ty=Tensor[(1, 16, 512, 512), int8] */;
  %305 = nn.conv2d(%304, meta[relay.Constant][88] /* ty=Tensor[(1, 16, 3, 3), int8] */, padding=[1, 1, 1, 1], channels=1, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1, 512, 512), int32] */;
  %306 = add(%305, 128 /* ty=int32 */) /* ty=Tensor[(1, 1, 512, 512), int32] */;
  %307 = right_shift(%306, 8 /* ty=int32 */) /* ty=Tensor[(1, 1, 512, 512), int32] */;
  %308 = clip(%307, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1, 512, 512), int32] */;
  %309 = cast(%308, dtype="int8") /* ty=Tensor[(1, 1, 512, 512), int8] */;
  %310 = annotation.stop_fusion(%309) /* ty=Tensor[(1, 1, 512, 512), int8] */;
  %311 = cast(%310, dtype="float32") /* ty=Tensor[(1, 1, 512, 512), float32] */;
  %312 = multiply(%311, 0.0625f /* ty=float32 */) /* ty=Tensor[(1, 1, 512, 512), float32] */;
  %313 = nn.bias_add(%312, meta[relay.Constant][89] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 512, 512), float32] */;
  sigmoid(%313) /* ty=Tensor[(1, 1, 512, 512), float32] */
}


===========================
